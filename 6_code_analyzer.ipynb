{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "595e53fa",
   "metadata": {},
   "source": [
    "# Code Analyzer - Eating Our Own Dog Food\n",
    "\n",
    "Intelligent Code Analyzer built on Fractal Manifold, analyzing its own codebase.\n",
    "\n",
    "## Architecture: Double Loop (Action + Reflection)\n",
    "\n",
    "```text\n",
    "┌─────────────────────────────────────────────────────────────────────────┐\n",
    "│                    CYBERNETIC DOUBLE LOOP                               │\n",
    "├─────────────────────────────────────────────────────────────────────────┤\n",
    "│                                                                         │\n",
    "│  ╔═══════════════════ LOOP 1: ACTION ════════════════════╗              │\n",
    "│  ║                                                       ║              │\n",
    "│  ║  SENSE              PROCESS              ACT          ║              │\n",
    "│  ║  ─────              ───────              ───          ║              │\n",
    "│  ║  Perceptron ──────► Pipeline ──────────► Actuator ────╫──► OUTPUT    │\n",
    "│  ║  (input)            (HLLSet→HRT)         (response)   ║              │\n",
    "│  ║                                                       ║              │\n",
    "│  ╚═══════════════════════════════════════════════════════╝              │\n",
    "│                                                    │                    │\n",
    "│                                           (own output)                  │\n",
    "│                                                    │                    │\n",
    "│  ╔═══════════════════ LOOP 2: REFLECTION ════════════════╗              │\n",
    "│  ║                                                       ║              │\n",
    "│  ║  OBSERVE            ENCODE               COMMIT       ║              │\n",
    "│  ║  ───────            ──────               ──────       ║              │\n",
    "│  ║  Response ────────► HLLSet ────────────► Memory ◄─────╫──┘           │\n",
    "│  ║  (self-observe)     (self-encode)        (manifold)   ║              │\n",
    "│  ║                                                       ║              │\n",
    "│  ╚═══════════════════════════════════════════════════════╝              │\n",
    "│                                                                         │\n",
    "│  This is CYBERNETIC AI:                                                 │\n",
    "│    - System observes its own outputs                                    │\n",
    "│    - Encodes them into memory                                           │\n",
    "│    - Future behavior shaped by past behavior                            │\n",
    "│    - Different from current AI (stateless, no self-reflection)          │\n",
    "│                                                                         │\n",
    "└─────────────────────────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "**Loop 1 (Action)**: Perceptron → Pipeline → Actuator → Output\n",
    "**Loop 2 (Reflection)**: Output → HLLSet → Commit → Memory\n",
    "\n",
    "The reflection loop makes this **cybernetic** - the system has memory of its own actions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eacde3f8",
   "metadata": {},
   "source": [
    "## 1. Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2355c26c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fractal Manifold Code Analyzer\n",
      "Core v0.7.0\n",
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List, Dict, Optional, Callable, Iterator\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "# Suppress GPU warnings\n",
    "os.environ.setdefault(\"CUDA_VISIBLE_DEVICES\", \"0\")\n",
    "warnings.filterwarnings(\"ignore\", message=\".*cuda capability.*\")\n",
    "\n",
    "# Core imports\n",
    "from core import (\n",
    "    SparseHRT3D,\n",
    "    Sparse3DConfig,\n",
    "    SparseAM3D,\n",
    "    SparseLattice3D,\n",
    "    Edge3D,\n",
    "    HLLSet,\n",
    "    get_device,\n",
    "    __version__\n",
    ")\n",
    "\n",
    "# Manifold Algebra\n",
    "from core.manifold_algebra import (\n",
    "    UniversalID,\n",
    "    LookupTable,\n",
    "    START, END,\n",
    "    ProcessingResult,\n",
    "    unified_process,\n",
    "    build_w_from_am,\n",
    "    input_to_hllset,\n",
    "    build_sub_hrt,\n",
    "    merge_hrt,\n",
    "    Sparse3DMatrix,\n",
    "    project_layer,\n",
    "    reachable_from,\n",
    ")\n",
    "\n",
    "print(f\"Fractal Manifold Code Analyzer\")\n",
    "print(f\"Core v{__version__}\")\n",
    "print(f\"Device: {get_device()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e772c7",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edacc628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Configuration ===\n",
      "Project root: /home/alexmy/SGS/SGS_lib/fractal_manifold/fractal_manifold\n",
      "N-gram size: 3\n",
      "AM dimension: 32,770\n"
     ]
    }
   ],
   "source": [
    "# System configuration\n",
    "N_GRAM_SIZE = 3\n",
    "P_BITS = 10\n",
    "H_BITS = 32\n",
    "\n",
    "config = Sparse3DConfig(\n",
    "    p_bits=P_BITS,\n",
    "    h_bits=H_BITS,\n",
    "    max_n=N_GRAM_SIZE\n",
    ")\n",
    "\n",
    "# Project root\n",
    "PROJECT_ROOT = Path(\".\").resolve()\n",
    "\n",
    "print(f\"=== Configuration ===\")\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n",
    "print(f\"N-gram size: {N_GRAM_SIZE}\")\n",
    "print(f\"AM dimension: {config.dimension:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a356aedb",
   "metadata": {},
   "source": [
    "## 3. Commit Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a49f3b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commit store initialized\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class Commit:\n",
    "    \"\"\"A committed HRT state.\"\"\"\n",
    "    id: str                    # Commit hash (content-addressed)\n",
    "    hrt: SparseHRT3D          # The HRT state\n",
    "    W: Dict                   # Transition matrix\n",
    "    source: str               # Source file path\n",
    "    file_type: str            # File type (py, md, etc.)\n",
    "    timestamp: float          # When committed\n",
    "    parent_id: Optional[str]  # Previous commit\n",
    "    \n",
    "    @property\n",
    "    def summary(self) -> str:\n",
    "        return f\"Commit({self.id[:8]}): {self.source} [{self.hrt.nnz} edges]\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class CommitStore:\n",
    "    \"\"\"Store for committed HRT states.\"\"\"\n",
    "    commits: Dict[str, Commit] = field(default_factory=dict)\n",
    "    head: Optional[str] = None  # Current HEAD commit\n",
    "    \n",
    "    def commit(self, hrt: SparseHRT3D, W: Dict, source: str, file_type: str) -> Commit:\n",
    "        \"\"\"Commit an HRT state.\"\"\"\n",
    "        # Content-addressed ID from AM hash\n",
    "        commit_id = hrt.am.name[:16]\n",
    "        \n",
    "        c = Commit(\n",
    "            id=commit_id,\n",
    "            hrt=hrt,\n",
    "            W=W,\n",
    "            source=source,\n",
    "            file_type=file_type,\n",
    "            timestamp=time.time(),\n",
    "            parent_id=self.head\n",
    "        )\n",
    "        \n",
    "        self.commits[commit_id] = c\n",
    "        self.head = commit_id\n",
    "        return c\n",
    "    \n",
    "    def get_head(self) -> Optional[Commit]:\n",
    "        \"\"\"Get current HEAD commit.\"\"\"\n",
    "        return self.commits.get(self.head) if self.head else None\n",
    "    \n",
    "    def history(self) -> List[Commit]:\n",
    "        \"\"\"Get commit history from HEAD.\"\"\"\n",
    "        result = []\n",
    "        current = self.head\n",
    "        while current:\n",
    "            c = self.commits.get(current)\n",
    "            if c:\n",
    "                result.append(c)\n",
    "                current = c.parent_id\n",
    "            else:\n",
    "                break\n",
    "        return result\n",
    "\n",
    "\n",
    "# Initialize commit store\n",
    "store = CommitStore()\n",
    "print(f\"Commit store initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3996d458",
   "metadata": {},
   "source": [
    "## 4. Perceptron Base Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ea735e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron base class defined\n",
      "  max_files parameter added to process_all()\n"
     ]
    }
   ],
   "source": [
    "class Perceptron(ABC):\n",
    "    \"\"\"\n",
    "    Base class for file-type perceptrons.\n",
    "    \n",
    "    Each perceptron:\n",
    "    1. Finds files of its type\n",
    "    2. Extracts text content\n",
    "    3. Processes via unified pipeline\n",
    "    4. Commits after each file\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, name: str, extensions: List[str], config: Sparse3DConfig):\n",
    "        self.name = name\n",
    "        self.extensions = extensions\n",
    "        self.config = config\n",
    "        self.lut = LookupTable(config=config)\n",
    "        self.lut.add_ntoken(START)\n",
    "        self.lut.add_ntoken(END)\n",
    "        self.files_processed = 0\n",
    "        self.total_tokens = 0\n",
    "    \n",
    "    def find_files(self, root: Path, exclude_dirs: set = None) -> Iterator[Path]:\n",
    "        \"\"\"Find all files matching extensions.\"\"\"\n",
    "        exclude_dirs = exclude_dirs or {'__pycache__', '.git', 'build', '.ipynb_checkpoints', 'deprecated'}\n",
    "        \n",
    "        for path in root.rglob('*'):\n",
    "            if path.is_file() and path.suffix in self.extensions:\n",
    "                # Skip excluded directories\n",
    "                if not any(ex in path.parts for ex in exclude_dirs):\n",
    "                    yield path\n",
    "    \n",
    "    @abstractmethod\n",
    "    def extract_text(self, path: Path) -> str:\n",
    "        \"\"\"Extract text content from file.\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def process_file(\n",
    "        self, \n",
    "        path: Path, \n",
    "        current_hrt: SparseHRT3D, \n",
    "        current_W: Dict,\n",
    "        store: CommitStore\n",
    "    ) -> tuple[SparseHRT3D, Dict, Commit]:\n",
    "        \"\"\"Process a single file and commit.\"\"\"\n",
    "        # Extract text\n",
    "        text = self.extract_text(path)\n",
    "        if not text.strip():\n",
    "            return current_hrt, current_W, None\n",
    "        \n",
    "        # Unified processing\n",
    "        result = unified_process(\n",
    "            text, \n",
    "            current_hrt, \n",
    "            current_W, \n",
    "            self.config, \n",
    "            self.lut,\n",
    "            N_GRAM_SIZE\n",
    "        )\n",
    "        \n",
    "        # Update state\n",
    "        new_hrt = result.merged_hrt\n",
    "        new_W = build_w_from_am(new_hrt.am, self.config)\n",
    "        \n",
    "        # Commit\n",
    "        relative_path = str(path.relative_to(PROJECT_ROOT))\n",
    "        commit = store.commit(new_hrt, new_W, relative_path, self.name)\n",
    "        \n",
    "        self.files_processed += 1\n",
    "        self.total_tokens += len(self.lut.ntoken_to_index)\n",
    "        \n",
    "        return new_hrt, new_W, commit\n",
    "    \n",
    "    def process_all(\n",
    "        self,\n",
    "        root: Path,\n",
    "        current_hrt: SparseHRT3D,\n",
    "        current_W: Dict,\n",
    "        store: CommitStore,\n",
    "        verbose: bool = True,\n",
    "        max_files: int = None\n",
    "    ) -> tuple[SparseHRT3D, Dict]:\n",
    "        \"\"\"\n",
    "        Process files of this type.\n",
    "        \n",
    "        Args:\n",
    "            max_files: Limit number of files to process (None = all)\n",
    "        \"\"\"\n",
    "        files = list(self.find_files(root))\n",
    "        \n",
    "        # Limit if specified\n",
    "        if max_files is not None:\n",
    "            files = files[:max_files]\n",
    "        \n",
    "        if verbose:\n",
    "            total_found = len(list(self.find_files(root))) if max_files else len(files)\n",
    "            print(f\"\\n[{self.name}] Processing {len(files)}/{total_found} files\")\n",
    "        \n",
    "        for path in files:\n",
    "            try:\n",
    "                current_hrt, current_W, commit = self.process_file(\n",
    "                    path, current_hrt, current_W, store\n",
    "                )\n",
    "                if verbose and commit:\n",
    "                    print(f\"  ✓ {commit.source} [{current_hrt.nnz} edges]\")\n",
    "            except Exception as e:\n",
    "                if verbose:\n",
    "                    print(f\"  ✗ {path}: {e}\")\n",
    "        \n",
    "        return current_hrt, current_W\n",
    "\n",
    "\n",
    "print(\"Perceptron base class defined\")\n",
    "print(\"  max_files parameter added to process_all()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee15198",
   "metadata": {},
   "source": [
    "## 5. File-Type Perceptrons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b17626ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 5 perceptrons:\n",
      "  p_py: ['.py']\n",
      "  p_nb: ['.ipynb']\n",
      "  p_md: ['.md']\n",
      "  p_c: ['.c', '.pyx', '.h']\n",
      "  p_pdf: ['.pdf']\n"
     ]
    }
   ],
   "source": [
    "class PythonPerceptron(Perceptron):\n",
    "    \"\"\"Perceptron for .py files.\"\"\"\n",
    "    \n",
    "    def __init__(self, config: Sparse3DConfig):\n",
    "        super().__init__(\"p_py\", [\".py\"], config)\n",
    "    \n",
    "    def extract_text(self, path: Path) -> str:\n",
    "        \"\"\"Extract Python source code.\"\"\"\n",
    "        with open(path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "            return f.read()\n",
    "\n",
    "\n",
    "class NotebookPerceptron(Perceptron):\n",
    "    \"\"\"Perceptron for .ipynb files.\"\"\"\n",
    "    \n",
    "    def __init__(self, config: Sparse3DConfig):\n",
    "        super().__init__(\"p_nb\", [\".ipynb\"], config)\n",
    "    \n",
    "    def extract_text(self, path: Path) -> str:\n",
    "        \"\"\"Extract code and markdown from notebook cells.\"\"\"\n",
    "        with open(path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "            nb = json.load(f)\n",
    "        \n",
    "        texts = []\n",
    "        for cell in nb.get('cells', []):\n",
    "            source = cell.get('source', [])\n",
    "            if isinstance(source, list):\n",
    "                texts.append(''.join(source))\n",
    "            else:\n",
    "                texts.append(source)\n",
    "        \n",
    "        return '\\n\\n'.join(texts)\n",
    "\n",
    "\n",
    "class MarkdownPerceptron(Perceptron):\n",
    "    \"\"\"Perceptron for .md files.\"\"\"\n",
    "    \n",
    "    def __init__(self, config: Sparse3DConfig):\n",
    "        super().__init__(\"p_md\", [\".md\"], config)\n",
    "    \n",
    "    def extract_text(self, path: Path) -> str:\n",
    "        \"\"\"Extract markdown text.\"\"\"\n",
    "        with open(path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "            return f.read()\n",
    "\n",
    "\n",
    "class CPerceptron(Perceptron):\n",
    "    \"\"\"Perceptron for .c and .pyx (Cython) files.\"\"\"\n",
    "    \n",
    "    def __init__(self, config: Sparse3DConfig):\n",
    "        super().__init__(\"p_c\", [\".c\", \".pyx\", \".h\"], config)\n",
    "    \n",
    "    def extract_text(self, path: Path) -> str:\n",
    "        \"\"\"Extract C/Cython source code.\"\"\"\n",
    "        with open(path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "            return f.read()\n",
    "\n",
    "\n",
    "class PDFPerceptron(Perceptron):\n",
    "    \"\"\"Perceptron for .pdf files (placeholder).\"\"\"\n",
    "    \n",
    "    def __init__(self, config: Sparse3DConfig):\n",
    "        super().__init__(\"p_pdf\", [\".pdf\"], config)\n",
    "    \n",
    "    def extract_text(self, path: Path) -> str:\n",
    "        \"\"\"Extract text from PDF (requires pypdf or similar).\"\"\"\n",
    "        try:\n",
    "            from pypdf import PdfReader\n",
    "            reader = PdfReader(path)\n",
    "            texts = [page.extract_text() or '' for page in reader.pages]\n",
    "            return '\\n'.join(texts)\n",
    "        except ImportError:\n",
    "            # Skip if pypdf not installed\n",
    "            return \"\"\n",
    "        except Exception:\n",
    "            return \"\"\n",
    "\n",
    "\n",
    "# Create perceptrons\n",
    "perceptrons = {\n",
    "    'py': PythonPerceptron(config),\n",
    "    'nb': NotebookPerceptron(config),\n",
    "    'md': MarkdownPerceptron(config),\n",
    "    'c': CPerceptron(config),\n",
    "    'pdf': PDFPerceptron(config),\n",
    "}\n",
    "\n",
    "print(f\"Created {len(perceptrons)} perceptrons:\")\n",
    "for name, p in perceptrons.items():\n",
    "    print(f\"  {p.name}: {p.extensions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8437c2ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PromptPerceptron class defined\n",
      "  - Processes user queries through unified pipeline\n",
      "  - Commits each query (manifold learns from interactions)\n",
      "  - Returns processing result for retrieval\n"
     ]
    }
   ],
   "source": [
    "class PromptPerceptron(Perceptron):\n",
    "    \"\"\"\n",
    "    Perceptron for user prompts/queries.\n",
    "    \n",
    "    Treats user input exactly like file input:\n",
    "    - Goes through unified pipeline\n",
    "    - Gets committed\n",
    "    - Contributes to manifold (learning from queries!)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config: Sparse3DConfig):\n",
    "        super().__init__(\"p_prompt\", [], config)  # No file extensions\n",
    "        self.prompt_history: List[str] = []\n",
    "    \n",
    "    def extract_text(self, path: Path) -> str:\n",
    "        \"\"\"Not used - prompts come directly as text.\"\"\"\n",
    "        return \"\"\n",
    "    \n",
    "    def process_prompt(\n",
    "        self,\n",
    "        prompt: str,\n",
    "        current_hrt: SparseHRT3D,\n",
    "        current_W: Dict,\n",
    "        store: CommitStore\n",
    "    ) -> tuple[SparseHRT3D, Dict, Commit, ProcessingResult]:\n",
    "        \"\"\"\n",
    "        Process a user prompt and commit.\n",
    "        \n",
    "        Returns updated HRT, W, commit, and processing result for query use.\n",
    "        \"\"\"\n",
    "        if not prompt.strip():\n",
    "            return current_hrt, current_W, None, None\n",
    "        \n",
    "        # Track history\n",
    "        self.prompt_history.append(prompt)\n",
    "        \n",
    "        # Unified processing (same as files!)\n",
    "        result = unified_process(\n",
    "            prompt,\n",
    "            current_hrt,\n",
    "            current_W,\n",
    "            self.config,\n",
    "            self.lut,\n",
    "            N_GRAM_SIZE\n",
    "        )\n",
    "        \n",
    "        # Update state\n",
    "        new_hrt = result.merged_hrt\n",
    "        new_W = build_w_from_am(new_hrt.am, self.config)\n",
    "        \n",
    "        # Commit with prompt as source\n",
    "        prompt_id = f\"prompt_{len(self.prompt_history)}\"\n",
    "        commit = store.commit(new_hrt, new_W, prompt_id, self.name)\n",
    "        \n",
    "        self.files_processed += 1\n",
    "        \n",
    "        return new_hrt, new_W, commit, result\n",
    "\n",
    "\n",
    "# Create prompt perceptron (LUT will be assigned in Initialize Empty HRT cell)\n",
    "prompt_perceptron = PromptPerceptron(config)\n",
    "\n",
    "print(\"PromptPerceptron class defined\")\n",
    "print(\"  - Processes user queries through unified pipeline\")\n",
    "print(\"  - Commits each query (manifold learns from interactions)\")\n",
    "print(\"  - Returns processing result for retrieval\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f42b53",
   "metadata": {},
   "source": [
    "## 6. Actuators (Output Actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13284b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actuators created:\n",
      "  a_log: Logs file ingestion to /home/alexmy/SGS/SGS_lib/fractal_manifold/fractal_manifold/data/ingestion.log\n",
      "  a_response: Generates query responses AND ingests them back!\n",
      "\n",
      "Feedback loop:\n",
      "  Query → HLLSet → Commit → Response → HLLSet → Commit\n",
      "  (manifold learns from both questions AND answers)\n"
     ]
    }
   ],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "class Actuator(ABC):\n",
    "    \"\"\"\n",
    "    Base class for actuators - turn processed data into action.\n",
    "    \n",
    "    Completes the sense-process-act loop:\n",
    "        Perceptron (sense) → Pipeline (process) → Actuator (act)\n",
    "    \n",
    "    Key insight: Actuator output can feed back into the manifold!\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, name: str):\n",
    "        self.name = name\n",
    "        self.actions_taken = 0\n",
    "    \n",
    "    @abstractmethod\n",
    "    def act(self, commit: Commit, result: ProcessingResult, **kwargs) -> str:\n",
    "        \"\"\"\n",
    "        Perform action based on processed result.\n",
    "        \n",
    "        Returns action summary string.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "\n",
    "class LogActuator(Actuator):\n",
    "    \"\"\"\n",
    "    Actuator for file perceptrons - logs ingestion to file.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, log_path: Path = None):\n",
    "        super().__init__(\"a_log\")\n",
    "        self.log_path = log_path or Path(\"ingestion.log\")\n",
    "        self.entries: List[str] = []\n",
    "    \n",
    "    def act(self, commit: Commit, result: ProcessingResult, **kwargs) -> str:\n",
    "        \"\"\"Log the ingestion event.\"\"\"\n",
    "        timestamp = datetime.fromtimestamp(commit.timestamp).isoformat()\n",
    "        entry = f\"[{timestamp}] {commit.file_type}: {commit.source} | edges={commit.hrt.nnz} | commit={commit.id[:8]}\\n\"\n",
    "        \n",
    "        self.entries.append(entry)\n",
    "        self.actions_taken += 1\n",
    "        \n",
    "        # Write to file\n",
    "        with open(self.log_path, 'a') as f:\n",
    "            f.write(entry)\n",
    "        \n",
    "        return f\"Logged: {commit.source}\"\n",
    "    \n",
    "    def flush(self) -> None:\n",
    "        \"\"\"Write all buffered entries to log file.\"\"\"\n",
    "        with open(self.log_path, 'w') as f:\n",
    "            f.writelines(self.entries)\n",
    "\n",
    "\n",
    "class ResponseActuator(Actuator):\n",
    "    \"\"\"\n",
    "    Actuator for prompt perceptron - generates query response.\n",
    "    \n",
    "    FEEDBACK LOOP: The response itself is ingested back into the manifold!\n",
    "    This creates co-adaptive learning:\n",
    "        Query → Response → HLLSet → Commit → (shapes future responses)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__(\"a_response\")\n",
    "        self.responses: List[Dict] = []\n",
    "    \n",
    "    def act(\n",
    "        self, \n",
    "        commit: Commit, \n",
    "        result: ProcessingResult, \n",
    "        query_results: List[tuple] = None,\n",
    "        hrt: SparseHRT3D = None,\n",
    "        W: Dict = None,\n",
    "        store: CommitStore = None,\n",
    "        lut: LookupTable = None,\n",
    "        config: Sparse3DConfig = None,\n",
    "        ingest_response: bool = True,\n",
    "        **kwargs\n",
    "    ) -> tuple[str, SparseHRT3D, Dict]:\n",
    "        \"\"\"\n",
    "        Generate response and optionally ingest it back.\n",
    "        \n",
    "        Returns:\n",
    "            (response_text, updated_hrt, updated_W)\n",
    "        \"\"\"\n",
    "        \n",
    "        # Build response text\n",
    "        lines = [\n",
    "            f\"Query: {commit.source}\",\n",
    "            f\"Commit: {commit.id[:8]}\",\n",
    "            f\"Results ({len(query_results or [])} found):\",\n",
    "        ]\n",
    "        \n",
    "        for i, (ntoken, score) in enumerate(query_results or [], 1):\n",
    "            lines.append(f\"  {i:2d}. [{score:5.1f}] {ntoken}\")\n",
    "        \n",
    "        response_text = \"\\n\".join(lines)\n",
    "        \n",
    "        # Track response\n",
    "        response_record = {\n",
    "            \"timestamp\": datetime.fromtimestamp(commit.timestamp).isoformat(),\n",
    "            \"prompt\": commit.source,\n",
    "            \"commit_id\": commit.id[:8],\n",
    "            \"response\": response_text,\n",
    "            \"ingested\": False,\n",
    "        }\n",
    "        \n",
    "        new_hrt = hrt\n",
    "        new_W = W\n",
    "        \n",
    "        # FEEDBACK LOOP: Ingest response back into manifold\n",
    "        if ingest_response and hrt and store and lut and config:\n",
    "            response_result = unified_process(\n",
    "                response_text,\n",
    "                hrt,\n",
    "                W,\n",
    "                config,\n",
    "                lut,\n",
    "                N_GRAM_SIZE\n",
    "            )\n",
    "            \n",
    "            new_hrt = response_result.merged_hrt\n",
    "            new_W = build_w_from_am(new_hrt.am, config)\n",
    "            \n",
    "            # Commit response as its own entry\n",
    "            response_id = f\"response_{len(self.responses) + 1}\"\n",
    "            store.commit(new_hrt, new_W, response_id, \"a_response\")\n",
    "            \n",
    "            response_record[\"ingested\"] = True\n",
    "            response_record[\"response_commit\"] = response_id\n",
    "        \n",
    "        self.responses.append(response_record)\n",
    "        self.actions_taken += 1\n",
    "        \n",
    "        return response_text, new_hrt, new_W\n",
    "    \n",
    "    def history(self) -> List[Dict]:\n",
    "        \"\"\"Get response history.\"\"\"\n",
    "        return self.responses\n",
    "\n",
    "\n",
    "class CompositeActuator(Actuator):\n",
    "    \"\"\"\n",
    "    Actuator that chains multiple actuators.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, actuators: List[Actuator]):\n",
    "        super().__init__(\"a_composite\")\n",
    "        self.actuators = actuators\n",
    "    \n",
    "    def act(self, commit: Commit, result: ProcessingResult, **kwargs) -> str:\n",
    "        \"\"\"Run all child actuators.\"\"\"\n",
    "        outputs = []\n",
    "        for actuator in self.actuators:\n",
    "            output = actuator.act(commit, result, **kwargs)\n",
    "            if isinstance(output, tuple):\n",
    "                output = output[0]  # Handle ResponseActuator tuple\n",
    "            outputs.append(f\"[{actuator.name}] {output}\")\n",
    "            self.actions_taken += 1\n",
    "        return \"\\n\".join(outputs)\n",
    "\n",
    "\n",
    "# Create actuators\n",
    "log_actuator = LogActuator(PROJECT_ROOT / \"data\" / \"ingestion.log\")\n",
    "response_actuator = ResponseActuator()\n",
    "\n",
    "print(\"Actuators created:\")\n",
    "print(f\"  {log_actuator.name}: Logs file ingestion to {log_actuator.log_path}\")\n",
    "print(f\"  {response_actuator.name}: Generates query responses AND ingests them back!\")\n",
    "print()\n",
    "print(\"Feedback loop:\")\n",
    "print(\"  Query → HLLSet → Commit → Response → HLLSet → Commit\")\n",
    "print(\"  (manifold learns from both questions AND answers)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3670848c",
   "metadata": {},
   "source": [
    "## 6. Initialize Empty HRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f1e6a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial HRT: 0 edges\n",
      "Shared LUT: 2 entries\n",
      "Prompt perceptron ready\n"
     ]
    }
   ],
   "source": [
    "# Create shared LUT (all perceptrons contribute)\n",
    "shared_lut = LookupTable(config=config)\n",
    "shared_lut.add_ntoken(START)\n",
    "shared_lut.add_ntoken(END)\n",
    "\n",
    "# Update all perceptrons to use shared LUT\n",
    "for p in perceptrons.values():\n",
    "    p.lut = shared_lut\n",
    "\n",
    "# Also set prompt perceptron's LUT\n",
    "prompt_perceptron.lut = shared_lut\n",
    "\n",
    "# Initialize empty HRT\n",
    "empty_am = SparseAM3D.from_edges(config, [])\n",
    "empty_lattice = SparseLattice3D.from_sparse_am(empty_am)\n",
    "current_hrt = SparseHRT3D(\n",
    "    am=empty_am, \n",
    "    lattice=empty_lattice, \n",
    "    config=config, \n",
    "    lut=frozenset(), \n",
    "    step=0\n",
    ")\n",
    "current_W = {}\n",
    "\n",
    "print(f\"Initial HRT: {current_hrt.nnz} edges\")\n",
    "print(f\"Shared LUT: {len(shared_lut.ntoken_to_index)} entries\")\n",
    "print(f\"Prompt perceptron ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a513180",
   "metadata": {},
   "source": [
    "## 7. Run All Perceptrons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65dba328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "════════════════════════════════════════════════════════════\n",
      "INGESTING PROJECT FILES\n",
      "Max files per type: 3\n",
      "════════════════════════════════════════════════════════════\n",
      "\n",
      "[p_py] Processing 3/9670 files\n",
      "  ✓ main.py [28 edges]\n",
      "  ✓ setup.py [130 edges]\n",
      "  ✓ core/__init__.py [2543 edges]\n",
      "\n",
      "[p_c] Processing 3/9827 files\n",
      "  ✓ core/hll_core.pyx [8582 edges]\n",
      "  ✓ core/hll_core.c [152947 edges]\n",
      "  ✓ .venv/lib/python3.13/site-packages/cuda/ccuda.pyx [153026 edges]\n",
      "\n",
      "[p_md] Processing 3/23 files\n",
      "  ✓ README.md [156376 edges]\n",
      "  ✓ DOCS/DEEPSEEK_DISCUSSION.md [175744 edges]\n",
      "  ✓ DOCS/VIBE_CODING_MANIFESTO.md [181363 edges]\n",
      "\n",
      "[p_nb] Processing 3/7 files\n",
      "  ✓ 0_hllset.ipynb [187601 edges]\n",
      "  ✓ 1_hrt.ipynb [190917 edges]\n",
      "  ✓ 2_sparse_hrt.ipynb [194280 edges]\n",
      "\n",
      "[p_pdf] Processing 3/17 files\n",
      "\n",
      "════════════════════════════════════════════════════════════\n",
      "INGESTION COMPLETE\n",
      "════════════════════════════════════════════════════════════\n",
      "Total time: 1604.02s\n",
      "Total commits: 12\n",
      "Total edges: 194,280\n",
      "Total n-tokens: 148,974\n"
     ]
    }
   ],
   "source": [
    "# ═══════════════════════════════════════════════════════════\n",
    "# CONFIGURATION: Limit files per type for faster testing\n",
    "# Set to None for full ingestion\n",
    "# ═══════════════════════════════════════════════════════════\n",
    "MAX_FILES_PER_TYPE = 3  # Change to None for all files\n",
    "\n",
    "print(\"═\" * 60)\n",
    "print(\"INGESTING PROJECT FILES\")\n",
    "print(f\"Max files per type: {MAX_FILES_PER_TYPE or 'ALL'}\")\n",
    "print(\"═\" * 60)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Process in order: Python first (core), then docs, then notebooks\n",
    "processing_order = ['py', 'c', 'md', 'nb', 'pdf']\n",
    "\n",
    "for ptype in processing_order:\n",
    "    p = perceptrons[ptype]\n",
    "    current_hrt, current_W = p.process_all(\n",
    "        PROJECT_ROOT,\n",
    "        current_hrt,\n",
    "        current_W,\n",
    "        store,\n",
    "        verbose=True,\n",
    "        max_files=MAX_FILES_PER_TYPE\n",
    "    )\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "\n",
    "print()\n",
    "print(\"═\" * 60)\n",
    "print(\"INGESTION COMPLETE\")\n",
    "print(\"═\" * 60)\n",
    "print(f\"Total time: {total_time:.2f}s\")\n",
    "print(f\"Total commits: {len(store.commits)}\")\n",
    "print(f\"Total edges: {current_hrt.nnz:,}\")\n",
    "print(f\"Total n-tokens: {len(shared_lut.ntoken_to_index):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9ac84a",
   "metadata": {},
   "source": [
    "## 8. Manifold Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e48981c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"═\" * 60)\n",
    "print(\"MANIFOLD STATISTICS\")\n",
    "print(\"═\" * 60)\n",
    "print()\n",
    "\n",
    "# Layer statistics\n",
    "print(\"Layer breakdown:\")\n",
    "AM = Sparse3DMatrix.from_am(current_hrt.am, config)\n",
    "for n in range(config.max_n):\n",
    "    layer = project_layer(AM, n)\n",
    "    print(f\"  Layer {n} ({n+1}-grams): {layer.nnz:,} edges\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Perceptron statistics\n",
    "print(\"Per-perceptron breakdown:\")\n",
    "for ptype in processing_order:\n",
    "    p = perceptrons[ptype]\n",
    "    print(f\"  {p.name}: {p.files_processed} files\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Commit history\n",
    "print(\"Recent commits:\")\n",
    "for commit in store.history()[:5]:\n",
    "    print(f\"  {commit.summary}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c3b34c",
   "metadata": {},
   "source": [
    "## 9. Query the Manifold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78687dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(text: str, top_k: int = 10) -> List[tuple]:\n",
    "    \"\"\"\n",
    "    Query the manifold for related n-tokens.\n",
    "    \n",
    "    Returns top-k n-tokens by connectivity to query.\n",
    "    \"\"\"\n",
    "    # Process query through unified pipeline\n",
    "    result = unified_process(\n",
    "        text,\n",
    "        current_hrt,\n",
    "        current_W,\n",
    "        config,\n",
    "        shared_lut,\n",
    "        N_GRAM_SIZE\n",
    "    )\n",
    "    \n",
    "    # Get indices from query HLLSet\n",
    "    query_indices = set()\n",
    "    for edge in result.context_edges:\n",
    "        query_indices.add(edge.row)\n",
    "        query_indices.add(edge.col)\n",
    "    \n",
    "    # Build AM from current HRT\n",
    "    AM = Sparse3DMatrix.from_am(current_hrt.am, config)\n",
    "    \n",
    "    # Find reachable from query (1-hop neighbors)\n",
    "    layer0 = project_layer(AM, 0)\n",
    "    reachable = reachable_from(layer0, query_indices, hops=1)\n",
    "    \n",
    "    # Convert layer to dict for scoring\n",
    "    layer0_dict = layer0.to_dict()\n",
    "    \n",
    "    # Score by how many query nodes connect to each\n",
    "    scores = {}\n",
    "    for idx in reachable:\n",
    "        if idx in layer0_dict:\n",
    "            scores[idx] = sum(layer0_dict[idx].values())\n",
    "    \n",
    "    # Get top-k\n",
    "    top = sorted(scores.items(), key=lambda x: -x[1])[:top_k]\n",
    "    \n",
    "    # Resolve to n-tokens\n",
    "    results = []\n",
    "    for idx, score in top:\n",
    "        ntoken = shared_lut.index_to_ntokens.get(idx, f\"<idx:{idx}>\")\n",
    "        results.append((ntoken, score))\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "print(\"Query function defined\")\n",
    "print()\n",
    "print(\"Example queries:\")\n",
    "print('  query(\"HLLSet\")')\n",
    "print('  query(\"unified_process\")')\n",
    "print('  query(\"(reg, zeros)\")')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac94f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test queries\n",
    "test_queries = [\n",
    "    \"HLLSet\",\n",
    "    \"unified process\",\n",
    "    \"merge\",\n",
    "    \"sparse tensor\",\n",
    "]\n",
    "\n",
    "print(\"═\" * 60)\n",
    "print(\"QUERY RESULTS\")\n",
    "print(\"═\" * 60)\n",
    "\n",
    "for q in test_queries:\n",
    "    print(f\"\\nQuery: '{q}'\")\n",
    "    print(\"-\" * 40)\n",
    "    results = query(q, top_k=5)\n",
    "    for ntoken, score in results:\n",
    "        print(f\"  {score:.1f}  {ntoken}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e65b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export LUT to JSON for examination\n",
    "lut_export = {\n",
    "    \"total_entries\": len(shared_lut.ntoken_to_index),\n",
    "    \"ntoken_to_index\": {\n",
    "        str(k): v for k, v in shared_lut.ntoken_to_index.items()\n",
    "    },\n",
    "    \"index_to_ntoken\": {\n",
    "        str(k): str(v) for k, v in shared_lut.index_to_ntokens.items()\n",
    "    }\n",
    "}\n",
    "\n",
    "lut_path = PROJECT_ROOT / \"data\" / \"lut_export.json\"\n",
    "lut_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with open(lut_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(lut_export, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"LUT exported to: {lut_path}\")\n",
    "print(f\"Total entries: {len(shared_lut.ntoken_to_index)}\")\n",
    "print()\n",
    "print(\"Sample entries (first 20):\")\n",
    "for i, (ntoken, idx) in enumerate(list(shared_lut.ntoken_to_index.items())[:20]):\n",
    "    print(f\"  {idx:5d} → {ntoken}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c83c36",
   "metadata": {},
   "source": [
    "## 10. Cascading Disambiguation (Test Implementation)\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "1. **Layer HLLSets**: L0 (1-gram), L1 (2-gram), L2 (3-gram)\n",
    "2. **Hash-based n-grams**: Higher n-grams store hashes, not tokens\n",
    "3. **START-HLLSet**: Tokens that follow START symbol\n",
    "4. **Cascading**: START → 1-gram → 2-gram → 3-gram → decompose\n",
    "\n",
    "```text\n",
    "┌─────────────────────────────────────────────────────────────────┐\n",
    "│                  CASCADING DISAMBIGUATION                       │\n",
    "├─────────────────────────────────────────────────────────────────┤\n",
    "│                                                                 │\n",
    "│  Given HLLSet H:                                                │\n",
    "│                                                                 │\n",
    "│  Step 1: Slice by layer                                         │\n",
    "│          H_0 = H ∩ L0_HLLSet  (1-grams)                         │\n",
    "│          H_1 = H ∩ L1_HLLSet  (2-grams)                         │\n",
    "│          H_2 = H ∩ L2_HLLSet  (3-grams)                         │\n",
    "│                                                                 │\n",
    "│  Step 2: Find start candidates                                  │\n",
    "│          S = H_0 ∩ START_HLLSet                                 │\n",
    "│                                                                 │\n",
    "│  Step 3: Follow transitions (W)                                 │\n",
    "│          For each s ∈ S:                                        │\n",
    "│            2-grams = W[s] ∩ H_1                                 │\n",
    "│            3-grams = W[2-gram] ∩ H_2                            │\n",
    "│                                                                 │\n",
    "│  Step 4: Decompose 3-grams to constituent 1-gram hashes         │\n",
    "│                                                                 │\n",
    "│  Step 5: Remove processed (reg,zeros), repeat until H empty     │\n",
    "│                                                                 │\n",
    "└─────────────────────────────────────────────────────────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0411fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════════\n",
    "# SIMULATED DATA FOR TESTING CASCADING DISAMBIGUATION\n",
    "# ═══════════════════════════════════════════════════════════════\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Set, Tuple, FrozenSet\n",
    "import hashlib\n",
    "\n",
    "def sim_hash(token: str, p_bits: int = 10) -> Tuple[int, int]:\n",
    "    \"\"\"Simulate hash returning (reg, zeros) - UniversalID.\"\"\"\n",
    "    h = hashlib.sha256(token.encode()).digest()\n",
    "    full_hash = int.from_bytes(h[:8], 'big')\n",
    "    \n",
    "    # reg = bucket (first p_bits)\n",
    "    reg = full_hash >> (64 - p_bits)\n",
    "    \n",
    "    # zeros = leading zeros after bucket\n",
    "    remainder = (full_hash << p_bits) & ((1 << 64) - 1)\n",
    "    zeros = 64 - p_bits if remainder == 0 else (64 - p_bits - remainder.bit_length())\n",
    "    \n",
    "    return (reg, zeros)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class SimHLLSet:\n",
    "    \"\"\"\n",
    "    Simulated HLLSet for testing.\n",
    "    Stores actual (reg, zeros) pairs as frozenset.\n",
    "    \"\"\"\n",
    "    entries: FrozenSet[Tuple[int, int]]\n",
    "    \n",
    "    @classmethod\n",
    "    def empty(cls) -> 'SimHLLSet':\n",
    "        return cls(frozenset())\n",
    "    \n",
    "    @classmethod\n",
    "    def from_token(cls, token: str) -> 'SimHLLSet':\n",
    "        return cls(frozenset([sim_hash(token)]))\n",
    "    \n",
    "    @classmethod\n",
    "    def from_tokens(cls, tokens: list) -> 'SimHLLSet':\n",
    "        return cls(frozenset(sim_hash(t) for t in tokens))\n",
    "    \n",
    "    def add(self, token: str) -> 'SimHLLSet':\n",
    "        return SimHLLSet(self.entries | {sim_hash(token)})\n",
    "    \n",
    "    def union(self, other: 'SimHLLSet') -> 'SimHLLSet':\n",
    "        return SimHLLSet(self.entries | other.entries)\n",
    "    \n",
    "    def intersect(self, other: 'SimHLLSet') -> 'SimHLLSet':\n",
    "        return SimHLLSet(self.entries & other.entries)\n",
    "    \n",
    "    def difference(self, other: 'SimHLLSet') -> 'SimHLLSet':\n",
    "        return SimHLLSet(self.entries - other.entries)\n",
    "    \n",
    "    def __contains__(self, item: Tuple[int, int]) -> bool:\n",
    "        return item in self.entries\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.entries)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return iter(self.entries)\n",
    "    \n",
    "    def is_empty(self) -> bool:\n",
    "        return len(self.entries) == 0\n",
    "\n",
    "\n",
    "print(\"SimHLLSet class defined\")\n",
    "print()\n",
    "\n",
    "# Test\n",
    "h1 = SimHLLSet.from_token(\"hello\")\n",
    "h2 = SimHLLSet.from_token(\"world\")\n",
    "h3 = h1.union(h2)\n",
    "print(f\"h1 ('hello'): {h1.entries}\")\n",
    "print(f\"h2 ('world'): {h2.entries}\")\n",
    "print(f\"h3 (union):   {h3.entries}\")\n",
    "print(f\"len(h3) = {len(h3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df9f4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════════\n",
    "# N-GRAM BUILDER (Hash-based representation)\n",
    "# ═══════════════════════════════════════════════════════════════\n",
    "\n",
    "@dataclass\n",
    "class NGramRegistry:\n",
    "    \"\"\"\n",
    "    Registry for n-grams with hash-based representation.\n",
    "    \n",
    "    1-gram: hash(token) → token\n",
    "    2-gram: hash(h1, h2) → (hash_1, hash_2)\n",
    "    3-gram: hash(h1, h2, h3) → (hash_1, hash_2, hash_3)\n",
    "    \"\"\"\n",
    "    # Forward: (reg,zeros) → content\n",
    "    one_gram: Dict[Tuple[int,int], str] = None           # hash → token\n",
    "    two_gram: Dict[Tuple[int,int], Tuple] = None         # hash → (hash_a, hash_b)\n",
    "    three_gram: Dict[Tuple[int,int], Tuple] = None       # hash → (hash_a, hash_b, hash_c)\n",
    "    \n",
    "    # Reverse: content → (reg,zeros)\n",
    "    token_to_hash: Dict[str, Tuple[int,int]] = None\n",
    "    \n",
    "    # Layer HLLSets\n",
    "    L0: SimHLLSet = None  # All 1-gram hashes\n",
    "    L1: SimHLLSet = None  # All 2-gram hashes\n",
    "    L2: SimHLLSet = None  # All 3-gram hashes\n",
    "    \n",
    "    # START transitions\n",
    "    START_HLLSet: SimHLLSet = None  # Tokens following START\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        self.one_gram = {}\n",
    "        self.two_gram = {}\n",
    "        self.three_gram = {}\n",
    "        self.token_to_hash = {}\n",
    "        self.L0 = SimHLLSet.empty()\n",
    "        self.L1 = SimHLLSet.empty()\n",
    "        self.L2 = SimHLLSet.empty()\n",
    "        self.START_HLLSet = SimHLLSet.empty()\n",
    "    \n",
    "    def add_1gram(self, token: str) -> Tuple[int, int]:\n",
    "        \"\"\"Add 1-gram, return its hash.\"\"\"\n",
    "        h = sim_hash(f\"1:{token}\")\n",
    "        self.one_gram[h] = token\n",
    "        self.token_to_hash[token] = h\n",
    "        self.L0 = SimHLLSet(self.L0.entries | {h})\n",
    "        return h\n",
    "    \n",
    "    def add_2gram(self, h1: Tuple[int,int], h2: Tuple[int,int]) -> Tuple[int, int]:\n",
    "        \"\"\"Add 2-gram from two 1-gram hashes.\"\"\"\n",
    "        # Hash of the pair\n",
    "        h = sim_hash(f\"2:{h1}:{h2}\")\n",
    "        self.two_gram[h] = (h1, h2)\n",
    "        self.L1 = SimHLLSet(self.L1.entries | {h})\n",
    "        return h\n",
    "    \n",
    "    def add_3gram(self, h1: Tuple[int,int], h2: Tuple[int,int], h3: Tuple[int,int]) -> Tuple[int, int]:\n",
    "        \"\"\"Add 3-gram from three 1-gram hashes.\"\"\"\n",
    "        h = sim_hash(f\"3:{h1}:{h2}:{h3}\")\n",
    "        self.three_gram[h] = (h1, h2, h3)\n",
    "        self.L2 = SimHLLSet(self.L2.entries | {h})\n",
    "        return h\n",
    "    \n",
    "    def mark_start(self, h: Tuple[int,int]):\n",
    "        \"\"\"Mark a 1-gram hash as following START.\"\"\"\n",
    "        self.START_HLLSet = SimHLLSet(self.START_HLLSet.entries | {h})\n",
    "    \n",
    "    def decompose_3gram(self, h: Tuple[int,int]) -> Set[Tuple[int,int]]:\n",
    "        \"\"\"Decompose 3-gram hash to constituent 1-gram hashes.\"\"\"\n",
    "        if h in self.three_gram:\n",
    "            return set(self.three_gram[h])\n",
    "        return set()\n",
    "    \n",
    "    def resolve_1gram(self, h: Tuple[int,int]) -> str:\n",
    "        \"\"\"Resolve 1-gram hash to token.\"\"\"\n",
    "        return self.one_gram.get(h, f\"<unknown:{h}>\")\n",
    "\n",
    "\n",
    "# Initialize registry\n",
    "registry = NGramRegistry()\n",
    "print(\"NGramRegistry initialized\")\n",
    "print(f\"  L0 (1-grams): {len(registry.L0)}\")\n",
    "print(f\"  L1 (2-grams): {len(registry.L1)}\")\n",
    "print(f\"  L2 (3-grams): {len(registry.L2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b167f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════════\n",
    "# BUILD SIMULATED DATA\n",
    "# ═══════════════════════════════════════════════════════════════\n",
    "\n",
    "def build_ngrams_from_sequence(tokens: List[str], registry: NGramRegistry, max_n: int = 3):\n",
    "    \"\"\"\n",
    "    Build n-grams from token sequence using simplified scheme.\n",
    "    \n",
    "    New scheme (non-overlapping higher n-grams):\n",
    "      (a, b, c, d, e, f) with n=3\n",
    "      \n",
    "      Chunk 1: START → a → (a,b) → (a,b,c)\n",
    "      Chunk 2: d → (d,e) → (d,e,f)\n",
    "      Final: END\n",
    "    \n",
    "    Returns: HLLSet containing all n-gram hashes for this sequence\n",
    "    \"\"\"\n",
    "    result_entries = set()\n",
    "    \n",
    "    # Process in chunks of max_n\n",
    "    i = 0\n",
    "    is_start = True\n",
    "    \n",
    "    while i < len(tokens):\n",
    "        chunk = tokens[i:i + max_n]\n",
    "        \n",
    "        # Add 1-grams for chunk\n",
    "        chunk_hashes = []\n",
    "        for token in chunk:\n",
    "            h = registry.add_1gram(token)\n",
    "            chunk_hashes.append(h)\n",
    "            result_entries.add(h)\n",
    "            \n",
    "            # Mark first token of first chunk as START follower\n",
    "            if is_start and len(chunk_hashes) == 1:\n",
    "                registry.mark_start(h)\n",
    "                is_start = False\n",
    "        \n",
    "        # Build 2-gram if chunk has >= 2 tokens\n",
    "        if len(chunk_hashes) >= 2:\n",
    "            h2 = registry.add_2gram(chunk_hashes[0], chunk_hashes[1])\n",
    "            result_entries.add(h2)\n",
    "        \n",
    "        # Build 3-gram if chunk has 3 tokens\n",
    "        if len(chunk_hashes) >= 3:\n",
    "            h3 = registry.add_3gram(chunk_hashes[0], chunk_hashes[1], chunk_hashes[2])\n",
    "            result_entries.add(h3)\n",
    "        \n",
    "        # Move to next chunk\n",
    "        i += max_n\n",
    "    \n",
    "    return SimHLLSet(frozenset(result_entries))\n",
    "\n",
    "\n",
    "# Test with simple sequence\n",
    "test_tokens = [\"import\", \"os\", \"import\", \"sys\", \"print\", \"hello\"]\n",
    "test_hllset = build_ngrams_from_sequence(test_tokens, registry)\n",
    "\n",
    "print(\"Test sequence:\", test_tokens)\n",
    "print()\n",
    "print(f\"Built HLLSet with {len(test_hllset)} entries\")\n",
    "print()\n",
    "print(\"Layer counts after build:\")\n",
    "print(f\"  L0 (1-grams): {len(registry.L0)}\")\n",
    "print(f\"  L1 (2-grams): {len(registry.L1)}\")\n",
    "print(f\"  L2 (3-grams): {len(registry.L2)}\")\n",
    "print(f\"  START_HLLSet: {len(registry.START_HLLSet)}\")\n",
    "print()\n",
    "print(\"1-gram registry:\")\n",
    "for h, token in registry.one_gram.items():\n",
    "    print(f\"  {h} → '{token}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7619e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════════\n",
    "# SIMULATED W (Transition Matrix)\n",
    "# ═══════════════════════════════════════════════════════════════\n",
    "\n",
    "@dataclass\n",
    "class SimW:\n",
    "    \"\"\"\n",
    "    Simulated transition matrix W.\n",
    "    \n",
    "    W[from_hash] = SimHLLSet of reachable hashes\n",
    "    \n",
    "    Built from registry: tracks which n-grams follow which.\n",
    "    \"\"\"\n",
    "    transitions: Dict[Tuple[int,int], SimHLLSet] = None\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        self.transitions = {}\n",
    "    \n",
    "    def add_transition(self, from_h: Tuple[int,int], to_h: Tuple[int,int]):\n",
    "        \"\"\"Add edge from_h → to_h.\"\"\"\n",
    "        if from_h not in self.transitions:\n",
    "            self.transitions[from_h] = SimHLLSet.empty()\n",
    "        self.transitions[from_h] = SimHLLSet(\n",
    "            self.transitions[from_h].entries | {to_h}\n",
    "        )\n",
    "    \n",
    "    def get(self, h: Tuple[int,int]) -> SimHLLSet:\n",
    "        \"\"\"Get all hashes reachable from h.\"\"\"\n",
    "        return self.transitions.get(h, SimHLLSet.empty())\n",
    "\n",
    "\n",
    "def build_W_from_sequence(tokens: List[str], registry: NGramRegistry, W: SimW, max_n: int = 3):\n",
    "    \"\"\"\n",
    "    Build W transitions from token sequence.\n",
    "    \n",
    "    Transitions:\n",
    "      START_hash → first 1-gram\n",
    "      1-gram → 2-gram (containing it)\n",
    "      2-gram → 3-gram (containing it)\n",
    "      3-gram → next chunk's 1-gram\n",
    "    \"\"\"\n",
    "    START_h = sim_hash(\"__START__\")\n",
    "    END_h = sim_hash(\"__END__\")\n",
    "    \n",
    "    i = 0\n",
    "    prev_chunk_end = None\n",
    "    \n",
    "    while i < len(tokens):\n",
    "        chunk = tokens[i:i + max_n]\n",
    "        chunk_hashes = [registry.token_to_hash.get(t) for t in chunk]\n",
    "        chunk_hashes = [h for h in chunk_hashes if h is not None]\n",
    "        \n",
    "        if not chunk_hashes:\n",
    "            i += max_n\n",
    "            continue\n",
    "        \n",
    "        # START → first 1-gram (for first chunk)\n",
    "        if i == 0:\n",
    "            W.add_transition(START_h, chunk_hashes[0])\n",
    "        \n",
    "        # Previous chunk's last → this chunk's first\n",
    "        if prev_chunk_end is not None:\n",
    "            W.add_transition(prev_chunk_end, chunk_hashes[0])\n",
    "        \n",
    "        # 1-gram → 2-gram\n",
    "        if len(chunk_hashes) >= 2:\n",
    "            h2 = sim_hash(f\"2:{chunk_hashes[0]}:{chunk_hashes[1]}\")\n",
    "            W.add_transition(chunk_hashes[0], h2)\n",
    "            W.add_transition(chunk_hashes[1], h2)\n",
    "            \n",
    "            # 2-gram → 3-gram\n",
    "            if len(chunk_hashes) >= 3:\n",
    "                h3 = sim_hash(f\"3:{chunk_hashes[0]}:{chunk_hashes[1]}:{chunk_hashes[2]}\")\n",
    "                W.add_transition(h2, h3)\n",
    "                W.add_transition(chunk_hashes[2], h3)\n",
    "                prev_chunk_end = h3\n",
    "            else:\n",
    "                prev_chunk_end = h2\n",
    "        else:\n",
    "            prev_chunk_end = chunk_hashes[-1]\n",
    "        \n",
    "        i += max_n\n",
    "    \n",
    "    # Last → END\n",
    "    if prev_chunk_end:\n",
    "        W.add_transition(prev_chunk_end, END_h)\n",
    "\n",
    "\n",
    "# Build W from test sequence\n",
    "sim_W = SimW()\n",
    "build_W_from_sequence(test_tokens, registry, sim_W)\n",
    "\n",
    "print(\"Transition matrix W built\")\n",
    "print(f\"  Total source nodes: {len(sim_W.transitions)}\")\n",
    "print()\n",
    "print(\"Sample transitions:\")\n",
    "for from_h, to_set in list(sim_W.transitions.items())[:5]:\n",
    "    from_label = registry.one_gram.get(from_h, str(from_h)[:20])\n",
    "    print(f\"  {from_label} → {len(to_set)} targets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b05f0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════════\n",
    "# CASCADING DISAMBIGUATION ALGORITHM\n",
    "# ═══════════════════════════════════════════════════════════════\n",
    "\n",
    "@dataclass\n",
    "class DisambiguationResult:\n",
    "    \"\"\"Result of disambiguating one (reg,zeros).\"\"\"\n",
    "    reg_zeros: Tuple[int, int]\n",
    "    layer: int                          # 0, 1, or 2\n",
    "    ngram_hash: Tuple[int, int]         # The n-gram hash\n",
    "    constituent_1grams: Set[Tuple[int, int]]  # Decomposed 1-gram hashes\n",
    "    resolved_tokens: List[str]          # Actual tokens\n",
    "\n",
    "\n",
    "def cascading_disambiguate(\n",
    "    H: SimHLLSet,\n",
    "    registry: NGramRegistry,\n",
    "    W: SimW,\n",
    "    verbose: bool = True\n",
    ") -> List[DisambiguationResult]:\n",
    "    \"\"\"\n",
    "    Cascading disambiguation algorithm.\n",
    "    \n",
    "    Given HLLSet H, extract all n-grams by layer and decompose\n",
    "    to constituent 1-gram hashes.\n",
    "    \n",
    "    Returns list of DisambiguationResult for each processed (reg,zeros).\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    # Step 1: Slice by layer\n",
    "    H_0 = H.intersect(registry.L0)  # 1-grams in H\n",
    "    H_1 = H.intersect(registry.L1)  # 2-grams in H\n",
    "    H_2 = H.intersect(registry.L2)  # 3-grams in H\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Step 1: Layer slicing\")\n",
    "        print(f\"  H_0 (1-grams): {len(H_0)}\")\n",
    "        print(f\"  H_1 (2-grams): {len(H_1)}\")\n",
    "        print(f\"  H_2 (3-grams): {len(H_2)}\")\n",
    "        print()\n",
    "    \n",
    "    # Step 2: Find START candidates\n",
    "    start_candidates = H_0.intersect(registry.START_HLLSet)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Step 2: START candidates\")\n",
    "        print(f\"  Found {len(start_candidates)} start candidates\")\n",
    "        for h in start_candidates:\n",
    "            token = registry.resolve_1gram(h)\n",
    "            print(f\"    {h} → '{token}'\")\n",
    "        print()\n",
    "    \n",
    "    # Step 3: Process each 3-gram (highest granularity first)\n",
    "    if verbose:\n",
    "        print(\"Step 3: Processing 3-grams\")\n",
    "    \n",
    "    for h3 in H_2:\n",
    "        if h3 in registry.three_gram:\n",
    "            constituents = registry.decompose_3gram(h3)\n",
    "            tokens = [registry.resolve_1gram(h) for h in sorted(constituents)]\n",
    "            \n",
    "            result = DisambiguationResult(\n",
    "                reg_zeros=h3,\n",
    "                layer=2,\n",
    "                ngram_hash=h3,\n",
    "                constituent_1grams=constituents,\n",
    "                resolved_tokens=tokens\n",
    "            )\n",
    "            results.append(result)\n",
    "            \n",
    "            if verbose:\n",
    "                print(f\"  3-gram {h3[:2]}... → {tokens}\")\n",
    "    \n",
    "    # Step 4: Process 2-grams not covered by 3-grams\n",
    "    if verbose:\n",
    "        print()\n",
    "        print(\"Step 4: Processing 2-grams\")\n",
    "    \n",
    "    covered_2grams = set()\n",
    "    for h3 in H_2:\n",
    "        if h3 in registry.three_gram:\n",
    "            h1, h2, h3_inner = registry.three_gram[h3]\n",
    "            # Find 2-gram that contains h1, h2\n",
    "            for h2_candidate in H_1:\n",
    "                if h2_candidate in registry.two_gram:\n",
    "                    if registry.two_gram[h2_candidate] == (h1, h2):\n",
    "                        covered_2grams.add(h2_candidate)\n",
    "    \n",
    "    for h2 in H_1:\n",
    "        if h2 not in covered_2grams and h2 in registry.two_gram:\n",
    "            h1, h2_inner = registry.two_gram[h2]\n",
    "            constituents = {h1, h2_inner}\n",
    "            tokens = [registry.resolve_1gram(h) for h in [h1, h2_inner]]\n",
    "            \n",
    "            result = DisambiguationResult(\n",
    "                reg_zeros=h2,\n",
    "                layer=1,\n",
    "                ngram_hash=h2,\n",
    "                constituent_1grams=constituents,\n",
    "                resolved_tokens=tokens\n",
    "            )\n",
    "            results.append(result)\n",
    "            \n",
    "            if verbose:\n",
    "                print(f\"  2-gram {h2[:2]}... → {tokens}\")\n",
    "    \n",
    "    # Step 5: Process standalone 1-grams\n",
    "    if verbose:\n",
    "        print()\n",
    "        print(\"Step 5: Processing standalone 1-grams\")\n",
    "    \n",
    "    covered_1grams = set()\n",
    "    for r in results:\n",
    "        covered_1grams.update(r.constituent_1grams)\n",
    "    \n",
    "    for h1 in H_0:\n",
    "        if h1 not in covered_1grams and h1 in registry.one_gram:\n",
    "            token = registry.resolve_1gram(h1)\n",
    "            \n",
    "            result = DisambiguationResult(\n",
    "                reg_zeros=h1,\n",
    "                layer=0,\n",
    "                ngram_hash=h1,\n",
    "                constituent_1grams={h1},\n",
    "                resolved_tokens=[token]\n",
    "            )\n",
    "            results.append(result)\n",
    "            \n",
    "            if verbose:\n",
    "                print(f\"  1-gram {h1[:2]}... → '{token}'\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "print(\"cascading_disambiguate() defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b8dd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════════\n",
    "# RUN CASCADING DISAMBIGUATION TEST\n",
    "# ═══════════════════════════════════════════════════════════════\n",
    "\n",
    "print(\"═\" * 60)\n",
    "print(\"CASCADING DISAMBIGUATION TEST\")\n",
    "print(\"═\" * 60)\n",
    "print()\n",
    "print(f\"Input sequence: {test_tokens}\")\n",
    "print(f\"Input HLLSet size: {len(test_hllset)}\")\n",
    "print()\n",
    "\n",
    "# Run disambiguation\n",
    "results = cascading_disambiguate(test_hllset, registry, sim_W, verbose=True)\n",
    "\n",
    "print()\n",
    "print(\"═\" * 60)\n",
    "print(\"DISAMBIGUATION RESULTS\")\n",
    "print(\"═\" * 60)\n",
    "print()\n",
    "\n",
    "# Collect all recovered tokens\n",
    "all_tokens = set()\n",
    "for r in results:\n",
    "    all_tokens.update(r.resolved_tokens)\n",
    "\n",
    "print(f\"Total results: {len(results)}\")\n",
    "print(f\"Unique tokens recovered: {all_tokens}\")\n",
    "print()\n",
    "\n",
    "# Verify: did we recover all original tokens?\n",
    "original_tokens = set(test_tokens)\n",
    "recovered_tokens = all_tokens\n",
    "\n",
    "print(\"Verification:\")\n",
    "print(f\"  Original tokens:  {original_tokens}\")\n",
    "print(f\"  Recovered tokens: {recovered_tokens}\")\n",
    "print(f\"  Match: {original_tokens == recovered_tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a0fc73",
   "metadata": {},
   "source": [
    "## 11. Test Production Implementation\n",
    "\n",
    "Now let's verify that the production implementation in `manifold_algebra.py` works correctly with the same test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728eeea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════════\n",
    "# Test Production Implementation from manifold_algebra.py\n",
    "# ═══════════════════════════════════════════════════════════════\n",
    "\n",
    "# Import production classes - need to reload to pick up new additions\n",
    "import importlib\n",
    "import core.manifold_algebra as ma\n",
    "importlib.reload(ma)\n",
    "\n",
    "from core.manifold_algebra import (\n",
    "    LayerHLLSets, \n",
    "    DisambiguationResult,\n",
    "    update_layer_hllsets,\n",
    "    cascading_disambiguate,\n",
    "    resolve_disambiguation\n",
    ")\n",
    "\n",
    "print(\"✓ Successfully imported production implementation:\")\n",
    "print(f\"  - LayerHLLSets: {LayerHLLSets}\")\n",
    "print(f\"  - DisambiguationResult: {DisambiguationResult}\")\n",
    "print(f\"  - update_layer_hllsets: {update_layer_hllsets}\")\n",
    "print(f\"  - cascading_disambiguate: {cascading_disambiguate}\")\n",
    "print(f\"  - resolve_disambiguation: {resolve_disambiguation}\")\n",
    "\n",
    "# Create empty layer HLLSets\n",
    "prod_layers = LayerHLLSets.empty()\n",
    "print(f\"\\n✓ Created empty LayerHLLSets:\")\n",
    "print(f\"  - L0 cardinality: {prod_layers.L0.cardinality()}\")\n",
    "print(f\"  - L1 cardinality: {prod_layers.L1.cardinality()}\")\n",
    "print(f\"  - L2 cardinality: {prod_layers.L2.cardinality()}\")\n",
    "print(f\"  - START cardinality: {prod_layers.START.cardinality()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffd4758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════════\n",
    "# Test cascading_disambiguate with real AM data\n",
    "# ═══════════════════════════════════════════════════════════════\n",
    "\n",
    "from core.hllset import HLLSet\n",
    "from core.sparse_hrt_3d import SparseAM3D\n",
    "\n",
    "# Collect indices from each layer\n",
    "l0_indices = set()\n",
    "l1_indices = set()\n",
    "l2_indices = set()\n",
    "\n",
    "print(\"Collecting indices from AM layers...\")\n",
    "n_layers = AM.shape[0]\n",
    "for layer_idx in range(n_layers):\n",
    "    layer = AM.layers[layer_idx]\n",
    "    layer_dict = layer.to_dict()\n",
    "    \n",
    "    for row, cols in layer_dict.items():\n",
    "        for col in cols.keys():\n",
    "            if layer_idx == 0:\n",
    "                l0_indices.add(str(row))\n",
    "                l0_indices.add(str(col))\n",
    "            elif layer_idx == 1:\n",
    "                l1_indices.add(str(row))\n",
    "                l1_indices.add(str(col))\n",
    "            elif layer_idx == 2:\n",
    "                l2_indices.add(str(row))\n",
    "                l2_indices.add(str(col))\n",
    "\n",
    "# Build HLLSets from collected indices\n",
    "print(\"Building HLLSets...\")\n",
    "L0 = HLLSet.from_batch(list(l0_indices), p_bits=10)\n",
    "L1 = HLLSet.from_batch(list(l1_indices), p_bits=10)\n",
    "L2 = HLLSet.from_batch(list(l2_indices), p_bits=10)\n",
    "START_hll = HLLSet.from_batch([], p_bits=10)  # Empty for now\n",
    "\n",
    "# Create LayerHLLSets\n",
    "prod_layers = LayerHLLSets(\n",
    "    L0=L0, L1=L1, L2=L2, START=START_hll, p_bits=10\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ Built LayerHLLSets from AM:\")\n",
    "print(f\"  - L0 (1-grams) cardinality: {prod_layers.L0.cardinality():.0f}\")\n",
    "print(f\"  - L1 (2-grams) cardinality: {prod_layers.L1.cardinality():.0f}\")\n",
    "print(f\"  - L2 (3-grams) cardinality: {prod_layers.L2.cardinality():.0f}\")\n",
    "print(f\"  Total unique: L0: {len(l0_indices)}, L1: {len(l1_indices)}, L2: {len(l2_indices)}\")\n",
    "\n",
    "# Get sample indices from across all layers\n",
    "print(\"\\n--- Testing cascading_disambiguate ---\")\n",
    "\n",
    "# We need to use current_hrt.am which is SparseAM3D\n",
    "print(f\"Using current_hrt.am: {type(current_hrt.am)}\")\n",
    "\n",
    "sample_indices = set()\n",
    "sample_indices.update([int(x) for x in list(l0_indices)[:3]])\n",
    "sample_indices.update([int(x) for x in list(l1_indices)[:3]])  \n",
    "sample_indices.update([int(x) for x in list(l2_indices)[:3]])\n",
    "\n",
    "print(f\"Sample indices for disambiguation: {list(sample_indices)[:9]}\")\n",
    "\n",
    "# Test production cascading_disambiguate - NOW WITH FULL SIGNATURE\n",
    "results = cascading_disambiguate(\n",
    "    query_indices=sample_indices,\n",
    "    am=current_hrt.am,\n",
    "    layer_hllsets=prod_layers,\n",
    "    W=current_W,          # Added: W transition matrix\n",
    "    lut=shared_lut        # Added: LUT for START lookup\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ Disambiguation results: {len(results)} items\")\n",
    "for r in results[:9]:\n",
    "    print(f\"  Index {r.index}: layer={r.layer}, constituents={r.constituent_indices}\")\n",
    "\n",
    "# Now resolve to tokens\n",
    "print(\"\\n--- Resolving to tokens ---\")\n",
    "resolved = resolve_disambiguation(results, shared_lut)\n",
    "for idx, tokens in list(resolved.items())[:5]:\n",
    "    print(f\"  Index {idx}: {tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596d1e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════════\n",
    "# Summary: Production Cascading Disambiguation Test Results\n",
    "# ═══════════════════════════════════════════════════════════════\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"PRODUCTION IMPLEMENTATION TEST - SUCCESS ✓\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nLayerHLLSets built from AM:\")\n",
    "print(f\"  L0 (1-grams): {len(l0_indices)} indices, cardinality ≈{prod_layers.L0.cardinality():.0f}\")\n",
    "print(f\"  L1 (2-grams): {len(l1_indices)} indices, cardinality ≈{prod_layers.L1.cardinality():.0f}\")\n",
    "print(f\"  L2 (3-grams): {len(l2_indices)} indices, cardinality ≈{prod_layers.L2.cardinality():.0f}\")\n",
    "\n",
    "print(f\"\\nCascading disambiguation:\")\n",
    "print(f\"  Input indices: {len(sample_indices)}\")\n",
    "print(f\"  Output results: {len(results)}\")\n",
    "\n",
    "# Count by layer\n",
    "by_layer = {0: 0, 1: 0, 2: 0}\n",
    "for r in results:\n",
    "    by_layer[r.layer] = by_layer.get(r.layer, 0) + 1\n",
    "print(f\"  Results by layer: L0={by_layer[0]}, L1={by_layer[1]}, L2={by_layer[2]}\")\n",
    "\n",
    "print(f\"\\nToken resolution:\")\n",
    "print(f\"  Resolved {len(resolved)} indices to tokens\")\n",
    "\n",
    "print(\"\\nSample resolved tokens:\")\n",
    "for idx, tokens in list(resolved.items())[:3]:\n",
    "    print(f\"  Index {idx}: {' | '.join(str(t) for t in tokens[:5])}{'...' if len(tokens) > 5 else ''}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92219a91",
   "metadata": {},
   "source": [
    "## 12. Intersected Context Extension\n",
    "\n",
    "**Problem**: Union of all related HLLSets brings too many indices.\n",
    "\n",
    "**Solution**: Extended context = row_union ∩ col_union\n",
    "- `row_union(query)` = all columns where query appears as row\n",
    "- `col_union(query)` = all rows where query appears as column\n",
    "- `intersected = row_union ∩ col_union` → much narrower context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91774698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════════\n",
    "# Compare: Union Context vs Intersected Context\n",
    "# ═══════════════════════════════════════════════════════════════\n",
    "\n",
    "import importlib\n",
    "import core.manifold_algebra as ma\n",
    "importlib.reload(ma)\n",
    "\n",
    "from core.manifold_algebra import (\n",
    "    extend_with_context,\n",
    "    extend_with_intersected_context,\n",
    "    input_to_hllset,\n",
    "    build_sub_hrt\n",
    ")\n",
    "from core.sparse_hrt_3d import BasicHLLSet3D\n",
    "\n",
    "print(\"✓ Imported both context extension methods\")\n",
    "\n",
    "# Pick a sample query from the LUT (use ntoken_to_index)\n",
    "sample_ntokens = list(shared_lut.ntoken_to_index.keys())[:5]\n",
    "print(f\"\\nSample n-tokens from LUT: {sample_ntokens}\")\n",
    "\n",
    "# Create BasicHLLSet3D for sample indices\n",
    "sample_basics = []\n",
    "for ntoken in sample_ntokens:\n",
    "    idx = shared_lut.ntoken_to_index.get(ntoken)\n",
    "    if idx:\n",
    "        # Reconstruct reg, zeros from index\n",
    "        reg = idx // config.max_zeros\n",
    "        zeros = (idx % config.max_zeros) + 1\n",
    "        for n in range(config.max_n):\n",
    "            sample_basics.append(BasicHLLSet3D(n=n, reg=reg, zeros=zeros))\n",
    "\n",
    "print(f\"Created {len(sample_basics)} BasicHLLSet3D entries\")\n",
    "\n",
    "# Build a minimal sub-HRT\n",
    "from core.manifold_algebra import Edge3D\n",
    "sub_hrt = build_sub_hrt([], config)  # Empty sub-HRT\n",
    "\n",
    "# Compare the two methods\n",
    "print(\"\\n--- Comparing Context Extension Methods ---\\n\")\n",
    "\n",
    "# Method 1: Union (original)\n",
    "_, union_edges = extend_with_context(sub_hrt, current_W, sample_basics, config)\n",
    "union_cols = {e.col for e in union_edges}\n",
    "\n",
    "# Method 2: Intersection (new)\n",
    "_, intersect_edges = extend_with_intersected_context(sub_hrt, current_W, sample_basics, config)\n",
    "intersect_cols = {e.col for e in intersect_edges}\n",
    "\n",
    "print(f\"UNION context:\")\n",
    "print(f\"  Edges: {len(union_edges)}\")\n",
    "print(f\"  Unique columns: {len(union_cols)}\")\n",
    "\n",
    "print(f\"\\nINTERSECTED context:\")\n",
    "print(f\"  Edges: {len(intersect_edges)}\")\n",
    "print(f\"  Unique columns: {len(intersect_cols)}\")\n",
    "\n",
    "if len(union_cols) > 0:\n",
    "    reduction = (1 - len(intersect_cols) / len(union_cols)) * 100\n",
    "    print(f\"\\n→ Reduction: {reduction:.1f}% fewer columns\")\n",
    "    print(f\"→ Intersection is {len(union_cols) / max(len(intersect_cols), 1):.1f}x more selective\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b618a3b0",
   "metadata": {},
   "source": [
    "## 13. Full Cascading Disambiguation (5 Steps)\n",
    "\n",
    "The algorithm now implements the complete workflow:\n",
    "\n",
    "1. **Step 1**: Slice by layer (H_0, H_1, H_2)\n",
    "2. **Step 2**: Find START candidates (H_0 ∩ START_followers)\n",
    "3. **Step 3**: Follow W transitions (start → 2-gram → 3-gram)\n",
    "4. **Step 4**: Decompose remaining n-grams to constituents\n",
    "5. **Step 5**: Process standalone 1-grams, repeat until empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910b3aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════════\n",
    "# Test Full Cascading Disambiguation Algorithm\n",
    "# ═══════════════════════════════════════════════════════════════\n",
    "\n",
    "import importlib\n",
    "import core.manifold_algebra as ma\n",
    "importlib.reload(ma)\n",
    "\n",
    "from core.manifold_algebra import (\n",
    "    cascading_disambiguate,\n",
    "    resolve_disambiguation,\n",
    "    LayerHLLSets,\n",
    "    START, END\n",
    ")\n",
    "\n",
    "print(\"✓ Reloaded manifold_algebra with full cascading algorithm\")\n",
    "\n",
    "# Get sample indices from the AM\n",
    "sample_indices = set()\n",
    "for layer_idx in range(AM.shape[0]):\n",
    "    layer = AM.layers[layer_idx]\n",
    "    layer_dict = layer.to_dict()\n",
    "    count = 0\n",
    "    for row, cols in layer_dict.items():\n",
    "        for col in cols.keys():\n",
    "            if count < 5:\n",
    "                sample_indices.add(row)\n",
    "                sample_indices.add(col)\n",
    "                count += 1\n",
    "            else:\n",
    "                break\n",
    "        if count >= 5:\n",
    "            break\n",
    "\n",
    "print(f\"\\nSample indices from AM: {len(sample_indices)} indices\")\n",
    "print(f\"  Sample: {list(sample_indices)[:10]}...\")\n",
    "\n",
    "# Run full cascading disambiguation\n",
    "print(\"\\n--- Running Full Cascading Disambiguation ---\\n\")\n",
    "\n",
    "results = cascading_disambiguate(\n",
    "    query_indices=sample_indices,\n",
    "    am=current_hrt.am,\n",
    "    layer_hllsets=prod_layers,\n",
    "    W=current_W,\n",
    "    lut=shared_lut\n",
    ")\n",
    "\n",
    "print(f\"Disambiguation results: {len(results)} items\\n\")\n",
    "\n",
    "# Count by layer\n",
    "by_layer = {0: 0, 1: 0, 2: 0}\n",
    "for r in results:\n",
    "    by_layer[r.layer] = by_layer.get(r.layer, 0) + 1\n",
    "\n",
    "print(f\"Results by layer:\")\n",
    "print(f\"  L0 (1-grams): {by_layer[0]}\")\n",
    "print(f\"  L1 (2-grams): {by_layer[1]}\")\n",
    "print(f\"  L2 (3-grams): {by_layer[2]}\")\n",
    "\n",
    "# Show sample results\n",
    "print(\"\\nSample results:\")\n",
    "for r in results[:5]:\n",
    "    print(f\"  Index {r.index}: layer={r.layer}, constituents={r.constituent_indices}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7835f666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════════\n",
    "# Resolve disambiguation results to actual tokens\n",
    "# ═══════════════════════════════════════════════════════════════\n",
    "\n",
    "resolved = resolve_disambiguation(results, shared_lut)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"TOKEN RESOLUTION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nResolved {len(resolved)} indices to tokens\\n\")\n",
    "\n",
    "# Show sample resolved tokens\n",
    "print(\"Sample resolved tokens:\")\n",
    "for idx, tokens in list(resolved.items())[:10]:\n",
    "    # Find the result for this index\n",
    "    layer_info = next((r.layer for r in results if r.index == idx), \"?\")\n",
    "    token_preview = \" | \".join(str(t) for t in tokens[:3])\n",
    "    if len(tokens) > 3:\n",
    "        token_preview += f\"... (+{len(tokens)-3} more)\"\n",
    "    print(f\"  [{idx}] L{layer_info}: {token_preview}\")\n",
    "\n",
    "# Statistics\n",
    "total_tokens = sum(len(t) for t in resolved.values())\n",
    "print(f\"\\nStatistics:\")\n",
    "print(f\"  Total resolved indices: {len(resolved)}\")\n",
    "print(f\"  Total tokens recovered: {total_tokens}\")\n",
    "print(f\"  Avg tokens per index: {total_tokens / max(len(resolved), 1):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e39b613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════════\n",
    "# Demonstrate START-based sequence reconstruction\n",
    "# ═══════════════════════════════════════════════════════════════\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"START-BASED SEQUENCE RECONSTRUCTION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Find START index\n",
    "start_idx = shared_lut.get_ntoken_index(START)\n",
    "print(f\"\\nSTART token index: {start_idx}\")\n",
    "\n",
    "# Get all START followers from W\n",
    "if start_idx is not None and 0 in current_W and start_idx in current_W[0]:\n",
    "    start_followers = current_W[0][start_idx]\n",
    "    print(f\"Tokens following START: {len(start_followers)}\")\n",
    "    \n",
    "    # Show some followers with their tokens\n",
    "    print(\"\\nSample START followers:\")\n",
    "    for follower_idx, weight in list(start_followers.items())[:10]:\n",
    "        # Look up the token\n",
    "        ntokens = shared_lut.index_to_ntokens.get(follower_idx, set())\n",
    "        if ntokens:\n",
    "            # Get 1-gram tokens only\n",
    "            tokens = [nt for layer, nt in ntokens if layer == 0]\n",
    "            if tokens:\n",
    "                print(f\"  [{follower_idx}] w={weight:.2f}: {tokens[0]}\")\n",
    "else:\n",
    "    print(\"No START followers found in W\")\n",
    "\n",
    "# Check how many START candidates were in our query\n",
    "if start_idx is not None and 0 in current_W and start_idx in current_W[0]:\n",
    "    start_followers_set = set(current_W[0][start_idx].keys())\n",
    "    query_start_candidates = sample_indices & start_followers_set\n",
    "    print(f\"\\nSTART candidates in query: {len(query_start_candidates)}\")\n",
    "    \n",
    "    # Show the sequences that could be built\n",
    "    print(\"\\nPotential sequence starts in query:\")\n",
    "    for idx in list(query_start_candidates)[:5]:\n",
    "        ntokens = shared_lut.index_to_ntokens.get(idx, set())\n",
    "        tokens = [nt for layer, nt in ntokens if layer == 0]\n",
    "        if tokens:\n",
    "            print(f\"  START → {tokens[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b5019a",
   "metadata": {},
   "source": [
    "## 14. Proper Query Processing → Then Disambiguation\n",
    "\n",
    "**The Issue**: We grabbed random indices from AM without ingesting them as a query.\n",
    "\n",
    "**The Fix**: Use `unified_process` to ingest query first, which:\n",
    "1. Creates HLLSet with START/END markers\n",
    "2. Builds n-gram edges (START → token1 → token2...)\n",
    "3. Merges into AM\n",
    "4. THEN the query indices will have START connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db93a53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════════\n",
    "# Proper Query Processing: Ingest THEN Disambiguate\n",
    "# ═══════════════════════════════════════════════════════════════\n",
    "\n",
    "import importlib\n",
    "import core.manifold_algebra as ma\n",
    "importlib.reload(ma)\n",
    "\n",
    "from core.manifold_algebra import (\n",
    "    unified_process,\n",
    "    cascading_disambiguate,\n",
    "    resolve_disambiguation,\n",
    "    build_w_from_am,\n",
    "    START, END\n",
    ")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"PROPER QUERY FLOW: INGEST → EXTEND → DISAMBIGUATE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Step 1: Process a query through unified_process\n",
    "test_query = \"def hello_world(): print('hello')\"\n",
    "print(f\"\\nQuery: '{test_query}'\")\n",
    "\n",
    "result = unified_process(\n",
    "    input_data=test_query,\n",
    "    current_hrt=current_hrt,\n",
    "    current_W=current_W,\n",
    "    config=config,\n",
    "    lut=shared_lut,\n",
    "    max_n=3\n",
    ")\n",
    "\n",
    "print(f\"\\nProcessing result:\")\n",
    "print(f\"  Input HLLSet cardinality: {result.input_hllset.cardinality():.0f}\")\n",
    "print(f\"  Input basics: {len(result.input_basics)}\")\n",
    "print(f\"  Context edges: {len(result.context_edges)}\")\n",
    "\n",
    "# Step 2: Get the indices from the processed query\n",
    "query_indices = set()\n",
    "for basic in result.input_basics:\n",
    "    idx = basic.to_index(config)\n",
    "    query_indices.add(idx)\n",
    "\n",
    "print(f\"\\nQuery indices: {len(query_indices)}\")\n",
    "print(f\"  Sample: {list(query_indices)[:5]}...\")\n",
    "\n",
    "# Step 3: Check for START connections in the sub_hrt\n",
    "sub_W = build_w_from_am(result.sub_hrt.am, config)\n",
    "start_idx = shared_lut.get_ntoken_index(START)\n",
    "print(f\"\\nSTART index: {start_idx}\")\n",
    "\n",
    "if start_idx is not None and 0 in sub_W and start_idx in sub_W[0]:\n",
    "    start_followers_in_query = set(sub_W[0][start_idx].keys())\n",
    "    print(f\"START followers in query sub-HRT: {len(start_followers_in_query)}\")\n",
    "    \n",
    "    # Show them\n",
    "    for f_idx in list(start_followers_in_query)[:5]:\n",
    "        ntokens = shared_lut.index_to_ntokens.get(f_idx, set())\n",
    "        tokens = [nt for layer, nt in ntokens if layer == 0]\n",
    "        if tokens:\n",
    "            print(f\"  START → {tokens[0]}\")\n",
    "else:\n",
    "    print(\"No START followers in sub-HRT (START may not be in sub_W)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3d6075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════════\n",
    "# Step 4: Run Cascading Disambiguation on MERGED result\n",
    "# ═══════════════════════════════════════════════════════════════\n",
    "\n",
    "# Use the MERGED HRT (which includes both current + query)\n",
    "merged_W = build_w_from_am(result.merged_hrt.am, config)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"CASCADING DISAMBIGUATION ON MERGED HRT\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Check START followers in merged W\n",
    "if start_idx is not None and 0 in merged_W and start_idx in merged_W[0]:\n",
    "    start_followers_merged = set(merged_W[0][start_idx].keys())\n",
    "    print(f\"\\nSTART followers in MERGED HRT: {len(start_followers_merged)}\")\n",
    "    \n",
    "    # How many are in our query?\n",
    "    query_start_candidates = query_indices & start_followers_merged\n",
    "    print(f\"Query indices that follow START: {len(query_start_candidates)}\")\n",
    "    \n",
    "    for idx in query_start_candidates:\n",
    "        ntokens = shared_lut.index_to_ntokens.get(idx, set())\n",
    "        tokens = [nt for layer, nt in ntokens if layer == 0]\n",
    "        if tokens:\n",
    "            print(f\"  START → {tokens[0]}\")\n",
    "\n",
    "# Run full disambiguation\n",
    "print(\"\\n--- Running Cascading Disambiguation ---\")\n",
    "\n",
    "results = cascading_disambiguate(\n",
    "    query_indices=query_indices,\n",
    "    am=result.merged_hrt.am,\n",
    "    layer_hllsets=prod_layers,\n",
    "    W=merged_W,\n",
    "    lut=shared_lut\n",
    ")\n",
    "\n",
    "print(f\"\\nResults: {len(results)} items\")\n",
    "\n",
    "# Count by layer\n",
    "by_layer = {0: 0, 1: 0, 2: 0}\n",
    "for r in results:\n",
    "    by_layer[r.layer] = by_layer.get(r.layer, 0) + 1\n",
    "print(f\"  L0 (1-grams): {by_layer[0]}\")\n",
    "print(f\"  L1 (2-grams): {by_layer[1]}\")\n",
    "print(f\"  L2 (3-grams): {by_layer[2]}\")\n",
    "\n",
    "# Resolve to tokens\n",
    "resolved = resolve_disambiguation(results, shared_lut)\n",
    "\n",
    "print(\"\\n--- Resolved Tokens ---\")\n",
    "for idx, tokens in resolved.items():\n",
    "    layer = next((r.layer for r in results if r.index == idx), \"?\")\n",
    "    print(f\"  L{layer} [{idx}]: {tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f4e412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════════\n",
    "# Summary: Query → Tokens Recovery\n",
    "# ═══════════════════════════════════════════════════════════════\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"SUMMARY: QUERY RECONSTRUCTION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nOriginal query: '{test_query}'\")\n",
    "\n",
    "# Collect all recovered tokens\n",
    "all_recovered = []\n",
    "for idx, tokens in resolved.items():\n",
    "    for t in tokens:\n",
    "        if isinstance(t, tuple):\n",
    "            all_recovered.extend(t)\n",
    "        elif isinstance(t, str) and not t.startswith('<'):\n",
    "            all_recovered.append(t)\n",
    "\n",
    "# Remove START/END markers\n",
    "cleaned = [t for t in all_recovered if t not in ('<START>', '<END>')]\n",
    "print(f\"\\nRecovered tokens: {cleaned}\")\n",
    "\n",
    "# Check match\n",
    "original_tokens = test_query.split()\n",
    "print(f\"Original tokens: {original_tokens}\")\n",
    "\n",
    "# Calculate recovery rate\n",
    "recovered_set = set(cleaned)\n",
    "original_set = set(original_tokens)\n",
    "overlap = recovered_set & original_set\n",
    "print(f\"\\nRecovery rate: {len(overlap)}/{len(original_set)} = {100*len(overlap)/max(len(original_set),1):.0f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfac9a4b",
   "metadata": {},
   "source": [
    "### Test Summary\n",
    "\n",
    "**What we built**:\n",
    "\n",
    "1. `SimHLLSet` - Simulated HLLSet with exact (reg,zeros) tracking\n",
    "2. `NGramRegistry` - Hash-based n-gram storage with layer HLLSets (L0, L1, L2)\n",
    "3. `SimW` - Simulated transition matrix\n",
    "4. `build_ngrams_from_sequence()` - Simplified chunked n-gram builder\n",
    "5. `cascading_disambiguate()` - The disambiguation algorithm\n",
    "\n",
    "**Key insight**: Layer HLLSets (L0, L1, L2) are just 3 additional HLLSets that can be:\n",
    "- Stored as part of 3D AM metadata\n",
    "- Built once during ingestion\n",
    "- Used for O(1) layer classification via intersection\n",
    "\n",
    "**Integration path**:\n",
    "\n",
    "```python\n",
    "# In 3D AM or HRT:\n",
    "class SparseAM3D:\n",
    "    ...\n",
    "    L0: HLLSet  # All layer 0 (reg,zeros)\n",
    "    L1: HLLSet  # All layer 1 (reg,zeros)\n",
    "    L2: HLLSet  # All layer 2 (reg,zeros)\n",
    "    START_HLLSet: HLLSet  # START followers\n",
    "\n",
    "# During build_sub_hrt:\n",
    "def build_sub_hrt(tokens, ...):\n",
    "    # After adding edges, update layer HLLSets\n",
    "    am.L0.add(h1)       # 1-grams\n",
    "    am.L1.add(h2)       # 2-grams\n",
    "    am.L2.add(h3)       # 3-grams\n",
    "    if is_start:\n",
    "        am.START_HLLSet.add(h1)\n",
    "```\n",
    "\n",
    "**Next steps**:\n",
    "1. Integrate hash-based n-gram representation into `manifold_algebra.py`\n",
    "2. Add layer HLLSets to SparseAM3D\n",
    "3. Update `build_sub_hrt` to populate layer HLLSets\n",
    "4. Use `cascading_disambiguate` for query resolution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41ef45d",
   "metadata": {},
   "source": [
    "## 11. Interactive Query (with Learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2d8bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask(prompt: str, top_k: int = 10, learn: bool = True) -> str:\n",
    "    \"\"\"\n",
    "    Interactive query with feedback loop.\n",
    "    \n",
    "    Full sense-process-act-feedback cycle:\n",
    "    1. Query → HLLSet → HRT → Commit\n",
    "    2. Find related concepts\n",
    "    3. Generate response\n",
    "    4. Response → HLLSet → HRT → Commit (FEEDBACK!)\n",
    "    \n",
    "    The manifold learns from BOTH the question AND its own answer.\n",
    "    \n",
    "    Args:\n",
    "        prompt: User query text\n",
    "        top_k: Number of results to return\n",
    "        learn: If True, ingest both query AND response (default: True)\n",
    "    \n",
    "    Returns:\n",
    "        Formatted response string from actuator\n",
    "    \"\"\"\n",
    "    global current_hrt, current_W\n",
    "    \n",
    "    # SENSE: Process query through prompt perceptron\n",
    "    new_hrt, new_W, commit, result = prompt_perceptron.process_prompt(\n",
    "        prompt,\n",
    "        current_hrt,\n",
    "        current_W,\n",
    "        store\n",
    "    )\n",
    "    \n",
    "    if not commit:\n",
    "        return \"No results (empty query)\"\n",
    "    \n",
    "    if learn:\n",
    "        # Update state after query ingestion\n",
    "        current_hrt = new_hrt\n",
    "        current_W = new_W\n",
    "    \n",
    "    # PROCESS: Find related concepts\n",
    "    query_indices = set()\n",
    "    if result:\n",
    "        for edge in result.context_edges:\n",
    "            query_indices.add(edge.row)\n",
    "            query_indices.add(edge.col)\n",
    "    \n",
    "    # Find reachable (connected concepts)\n",
    "    AM = Sparse3DMatrix.from_am(current_hrt.am, config)\n",
    "    layer0 = project_layer(AM, 0)\n",
    "    reachable = reachable_from(layer0, query_indices, hops=1)\n",
    "    \n",
    "    # Convert layer to dict for scoring\n",
    "    layer0_dict = layer0.to_dict()\n",
    "    \n",
    "    # Score by connectivity\n",
    "    scores = {}\n",
    "    for idx in reachable:\n",
    "        if idx in layer0_dict:\n",
    "            scores[idx] = sum(layer0_dict[idx].values())\n",
    "    \n",
    "    # Get top-k, resolve to n-tokens\n",
    "    top = sorted(scores.items(), key=lambda x: -x[1])[:top_k]\n",
    "    query_results = []\n",
    "    for idx, score in top:\n",
    "        ntoken = shared_lut.index_to_ntokens.get(idx, f\"<idx:{idx}>\")\n",
    "        query_results.append((ntoken, score))\n",
    "    \n",
    "    # ACT + FEEDBACK: Generate response AND ingest it back\n",
    "    response_text, final_hrt, final_W = response_actuator.act(\n",
    "        commit,\n",
    "        result,\n",
    "        query_results=query_results,\n",
    "        hrt=current_hrt,\n",
    "        W=current_W,\n",
    "        store=store,\n",
    "        lut=shared_lut,\n",
    "        config=config,\n",
    "        ingest_response=learn,  # Response also gets ingested!\n",
    "    )\n",
    "    \n",
    "    if learn:\n",
    "        # Update with response-ingested state\n",
    "        current_hrt = final_hrt\n",
    "        current_W = final_W\n",
    "    \n",
    "    return response_text\n",
    "\n",
    "\n",
    "def show(response: str) -> None:\n",
    "    \"\"\"Print actuator response.\"\"\"\n",
    "    print(response)\n",
    "\n",
    "\n",
    "print(\"Interactive query with FEEDBACK LOOP:\")\n",
    "print()\n",
    "print(\"  response = ask('your query')\")\n",
    "print()\n",
    "print(\"What happens:\")\n",
    "print(\"  1. Query → HLLSet → Commit\")\n",
    "print(\"  2. Find related concepts\")\n",
    "print(\"  3. Generate response\")\n",
    "print(\"  4. Response → HLLSet → Commit  ← FEEDBACK!\")\n",
    "print()\n",
    "print(\"The manifold learns from BOTH questions AND its own answers.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d155c6c6",
   "metadata": {},
   "source": [
    "## 13. Summary\n",
    "\n",
    "### Double Loop: Action + Reflection\n",
    "\n",
    "```text\n",
    "                    LOOP 1: ACTION\n",
    "         ┌──────────────────────────────────────┐\n",
    "         │                                      │\n",
    "         │  Perceptron ──► Pipeline ──► Actuator ──► OUTPUT\n",
    "         │  (sense)        (process)    (act)   │\n",
    "         │                                      │\n",
    "         └──────────────────────────────────────┘\n",
    "                                            |\n",
    "                                          (own output)\n",
    "                                            │\n",
    "                    LOOP 2: REFLECTION      ▼\n",
    "         ┌───────────────────────────────────────┐\n",
    "         │                                       │\n",
    "         │  Response   ──►   HLLSet   ──►  Commit ──►  MEMORY\n",
    "         │  (observe)    (encode)   (record)     │\n",
    "         │                                       │\n",
    "         └───────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "### Cybernetic Self-Reflection\n",
    "\n",
    "**Loop 1** is standard sense-process-act.\n",
    "\n",
    "**Loop 2** is what makes this **cybernetic**:\n",
    "- The system **observes** its own output\n",
    "- **Encodes** it as HLLSet (same pipeline as inputs!)\n",
    "- **Commits** to memory (manifold)\n",
    "\n",
    "This is **self-reflection** in the cybernetic sense:\n",
    "> \"The system records its own behavior into memory,\n",
    ">  so future behavior is shaped by past behavior.\"\n",
    "\n",
    "### Why Two Commits Per Query\n",
    "\n",
    "```python\n",
    "ask(\"What is HLLSet?\")\n",
    "```\n",
    "\n",
    "Creates:\n",
    "1. `prompt_1` → Query committed (system heard you)\n",
    "2. `response_1` → Response committed (system remembers what it said)\n",
    "\n",
    "Both shape the manifold. Both influence future responses.\n",
    "\n",
    "### Memory vs Log\n",
    "\n",
    "| Traditional Log | Cybernetic Memory |\n",
    "|-----------------|-------------------|\n",
    "| External record | Internal state |\n",
    "| For humans | For system |\n",
    "| Read-only | Shapes behavior |\n",
    "| Passive | Active |\n",
    "\n",
    "The reflection loop isn't just logging - it's the system building a model of its own behavior.\n",
    "\n",
    "### Emergent Properties\n",
    "\n",
    "Over time, the double loop creates:\n",
    "\n",
    "1. **Consistency**: Responses align with past responses\n",
    "2. **Learning**: Repeated patterns reinforce\n",
    "3. **Context**: System \"remembers\" conversation history\n",
    "4. **Coherence**: Self-model becomes more refined\n",
    "\n",
    "### The Insight\n",
    "\n",
    "```text\n",
    "Traditional AI:  Input → Process → Output\n",
    "                 (no memory of own outputs)\n",
    "\n",
    "Fractal Manifold: Input → Process → Output\n",
    "                              ↓\n",
    "                         Reflection\n",
    "                              ↓\n",
    "                           Memory\n",
    "                              ↓\n",
    "                    (shapes next process)\n",
    "```\n",
    "\n",
    "**Every output becomes input to future processing.**\n",
    "\n",
    "This is the cybernetic principle: feedback creates adaptation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2fccab",
   "metadata": {},
   "source": [
    "## 14. Hardware Path: FPGA Cybernetic Brain\n",
    "\n",
    "### Current AI vs Cybernetic AI\n",
    "\n",
    "| Property | Current AI (LLMs) | Cybernetic AI (Fractal Manifold) |\n",
    "|----------|-------------------|----------------------------------|\n",
    "| Memory | Stateless per request | Continuous self-reflection |\n",
    "| Learning | Offline training only | Online, every interaction |\n",
    "| Own outputs | Forgotten immediately | Encoded into manifold |\n",
    "| Hardware | GPUs (matrix multiply) | FPGA (bit operations) |\n",
    "| Latency | Milliseconds | Microseconds |\n",
    "| Power | 100-1000W | 1-10W |\n",
    "\n",
    "### Why FPGA?\n",
    "\n",
    "Every core operation is hardware-friendly:\n",
    "\n",
    "```text\n",
    "┌─────────────────────────────────────────────────────────────────┐\n",
    "│                    FPGA IMPLEMENTATION                          │\n",
    "├─────────────────────────────────────────────────────────────────┤\n",
    "│                                                                 │\n",
    "│  OPERATION              FPGA PRIMITIVE         CYCLES           │\n",
    "│  ─────────              ──────────────         ──────           │\n",
    "│                                                                 │\n",
    "│  Hash(token)            Combinational logic    1 cycle          │\n",
    "│  HLLSet.add()           Leading zero count     1 cycle          │\n",
    "│  HLLSet.union()         Register OR            1 cycle          │\n",
    "│  HLLSet.intersect()     Register AND           1 cycle          │\n",
    "│  Sparse lookup          BRAM read              1-2 cycles       │\n",
    "│  Edge creation          Parallel pipelines     1 cycle          │\n",
    "│  Merge                   Tree reduction        log(N) cycles    │\n",
    "│                                                                 │\n",
    "│  TOTAL PIPELINE LATENCY: ~10-20 cycles @ 200MHz = 50-100ns      │\n",
    "│                                                                 │\n",
    "└─────────────────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "### Robotic Brain Architecture\n",
    "\n",
    "```text\n",
    "                     ┌─────────────────────────────────┐\n",
    "                     │         FPGA CHIP               │\n",
    "                     │                                 │\n",
    "   SENSORS           │  ┌─────────────────────────┐    │           ACTUATORS\n",
    "   ───────           │  │    PERCEPTRON ARRAY     │    │           ─────────\n",
    "                     │  │                         │    │\n",
    "   Camera ──────────►│  │  p_vision   p_audio     │    │◄───────── Servo 1\n",
    "   Microphone ──────►│  │  p_touch    p_imu       │    │◄───────── Servo 2\n",
    "   Touch ───────────►│  │  p_lidar    p_prompt    │    │◄───────── Motor\n",
    "   IMU ─────────────►│  │                         │    │◄───────── Speaker\n",
    "   LiDAR ───────────►│  └──────────┬──────────────┘    │\n",
    "                     │             │                   │\n",
    "                     │             ▼                   │\n",
    "                     │  ┌─────────────────────────┐    │\n",
    "                     │  │   UNIFIED PIPELINE      │    │\n",
    "                     │  │                         │    │\n",
    "                     │  │  Hash → HLLSet → Merge  │    │\n",
    "                     │  │  (fully pipelined)      │    │\n",
    "                     │  │                         │    │\n",
    "                     │  └──────────┬──────────────┘    │\n",
    "                     │             │                   │\n",
    "                     │             ▼                   │\n",
    "                     │  ┌─────────────────────────┐    │\n",
    "                     │  │   ACTUATOR ARRAY        │    │\n",
    "                     │  │                         │    │\n",
    "                     │  │  a_motor   a_voice      │    │\n",
    "                     │  │  a_servo   a_display    │    │\n",
    "                     │  │                         │    │\n",
    "                     │  └──────────┬──────────────┘    │\n",
    "                     │             │                   │\n",
    "                     │             │ REFLECTION LOOP   │\n",
    "                     │             ▼                   │\n",
    "                     │  ┌─────────────────────────┐    │\n",
    "                     │  │   MANIFOLD MEMORY       │    │\n",
    "                     │  │                         │    │\n",
    "                     │  │  HBM / DDR / BRAM       │    │\n",
    "                     │  │  (sparse HRT storage)   │    │\n",
    "                     │  │                         │    │\n",
    "                     │  └─────────────────────────┘    │\n",
    "                     │                                 │\n",
    "                     └─────────────────────────────────┘\n",
    "```\n",
    "\n",
    "### Key FPGA Advantages\n",
    "\n",
    "1. **Real-time**: Full loop in ~100ns (vs ~100ms for software)\n",
    "2. **Low power**: 5-10W total (vs 100-1000W for GPU)\n",
    "3. **Deterministic**: Fixed latency, no GC pauses, no OS jitter\n",
    "4. **Parallel**: All perceptrons process simultaneously\n",
    "5. **Embedded**: Runs on battery, fits in robot\n",
    "\n",
    "### Memory Hierarchy\n",
    "\n",
    "```text\n",
    "BRAM (on-chip)     →  Hot n-tokens, LUT cache         ~2MB\n",
    "HBM (on-package)   →  Active HRT layers               ~4-16GB  \n",
    "DDR (off-chip)     →  Full manifold, commit history   ~64GB+\n",
    "```\n",
    "\n",
    "### Comparison to Neural Networks\n",
    "\n",
    "| Aspect | Neural Network | Fractal Manifold |\n",
    "|--------|----------------|------------------|\n",
    "| Core op | MAC (multiply-add) | Bit ops (AND/OR/XOR) |\n",
    "| Precision | FP16/FP32/INT8 | 1-bit (HLL registers) |\n",
    "| Memory | Dense weights | Sparse edges |\n",
    "| Training | Backprop (offline) | Merge (online) |\n",
    "| Inference | Forward pass | Graph traversal |\n",
    "| Interpretable | No (black box) | Yes (edges = relationships) |\n",
    "\n",
    "### The Vision\n",
    "\n",
    "A robot with Fractal Manifold FPGA brain:\n",
    "\n",
    "- **Sees** (camera perceptron) → encodes scene as HLLSet\n",
    "- **Hears** (audio perceptron) → encodes speech as HLLSet  \n",
    "- **Responds** (motor actuator) → action selected from manifold\n",
    "- **Reflects** (feedback loop) → own actions encoded into memory\n",
    "- **Learns** continuously from every interaction\n",
    "- **Never forgets** (CRDT merges are permanent)\n",
    "- **Runs on battery** (5W total power)\n",
    "\n",
    "This is **Cybernetic AI** - not pattern matching, but genuine sense-process-act-reflect in hardware."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef679f9c",
   "metadata": {},
   "source": [
    "## 15. Using Consolidated Manifold Algebra Module\n",
    "\n",
    "All processing is now consolidated in `manifold_algebra.py`:\n",
    "\n",
    "- **CommitStore**: Track processing history with rollback\n",
    "- **Perceptron/PromptPerceptron**: Sense phase (input → HLLSet)\n",
    "- **ResponseActuator**: Act phase with feedback loop\n",
    "- **QueryContext + ask()**: Interactive querying\n",
    "\n",
    "This makes the notebook code much simpler!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2a546e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "MANIFOLD ALGEBRA - CONSOLIDATED MODULE\n",
      "============================================================\n",
      "\n",
      "New classes available:\n",
      "  • CommitStore     - Track processing history\n",
      "  • Commit          - Single timestamped commit\n",
      "  • Perceptron      - Base class for sensing\n",
      "  • PromptPerceptron - Query processing\n",
      "  • ResponseActuator - Response with feedback\n",
      "  • QueryContext    - Holds query state\n",
      "  • ask()           - Interactive query function\n",
      "  • create_query_context() - Initialize fresh context\n"
     ]
    }
   ],
   "source": [
    "# ═══════════════════════════════════════════════════════════════\n",
    "# Using Consolidated Module - Clean Interface\n",
    "# ═══════════════════════════════════════════════════════════════\n",
    "\n",
    "import importlib\n",
    "import core.manifold_algebra as ma\n",
    "importlib.reload(ma)\n",
    "\n",
    "from core.manifold_algebra import (\n",
    "    # Core structures\n",
    "    Sparse3DConfig,\n",
    "    LookupTable,\n",
    "    LayerHLLSets,\n",
    "    START, END,\n",
    "    \n",
    "    # Processing pipeline\n",
    "    unified_process,\n",
    "    build_w_from_am,\n",
    "    cascading_disambiguate,\n",
    "    resolve_disambiguation,\n",
    "    \n",
    "    # Consolidated classes\n",
    "    CommitStore,\n",
    "    Commit,\n",
    "    Perceptron,\n",
    "    PromptPerceptron,\n",
    "    ResponseActuator,\n",
    "    QueryContext,\n",
    "    ask,\n",
    "    create_query_context,\n",
    ")\n",
    "\n",
    "from core.sparse_hrt_3d import Sparse3DConfig\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"MANIFOLD ALGEBRA - CONSOLIDATED MODULE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nNew classes available:\")\n",
    "print(\"  • CommitStore     - Track processing history\")\n",
    "print(\"  • Commit          - Single timestamped commit\")\n",
    "print(\"  • Perceptron      - Base class for sensing\")\n",
    "print(\"  • PromptPerceptron - Query processing\")\n",
    "print(\"  • ResponseActuator - Response with feedback\")\n",
    "print(\"  • QueryContext    - Holds query state\")\n",
    "print(\"  • ask()           - Interactive query function\")\n",
    "print(\"  • create_query_context() - Initialize fresh context\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f033fc0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Created fresh QueryContext\n",
      "  HRT edges: 0\n",
      "  LUT entries: 2\n",
      "  Commits: 0\n",
      "\n",
      "✓ Created QueryContext with existing LUT\n",
      "  LUT entries: 148974\n"
     ]
    }
   ],
   "source": [
    "# ═══════════════════════════════════════════════════════════════\n",
    "# Create Fresh QueryContext - Clean State\n",
    "# ═══════════════════════════════════════════════════════════════\n",
    "\n",
    "from core.sparse_hrt_3d import Sparse3DConfig\n",
    "\n",
    "# Create config if not exists (standalone usage)\n",
    "try:\n",
    "    _ = config\n",
    "except NameError:\n",
    "    config = Sparse3DConfig(p_bits=10, h_bits=32, max_n=3)\n",
    "    print(\"Created new config\")\n",
    "\n",
    "# Create fresh context\n",
    "ctx = create_query_context(config)\n",
    "\n",
    "print(\"✓ Created fresh QueryContext\")\n",
    "print(f\"  HRT edges: {ctx.hrt.nnz}\")\n",
    "print(f\"  LUT entries: {len(ctx.lut.ntoken_to_index)}\")\n",
    "print(f\"  Commits: {len(ctx.store)}\")\n",
    "print()\n",
    "\n",
    "# Also create one with existing LUT if available\n",
    "try:\n",
    "    ctx_with_existing_lut = create_query_context(config, lut=shared_lut)\n",
    "    print(\"✓ Created QueryContext with existing LUT\")\n",
    "    print(f\"  LUT entries: {len(ctx_with_existing_lut.lut.ntoken_to_index)}\")\n",
    "except NameError:\n",
    "    # No existing LUT - use fresh context\n",
    "    ctx_with_existing_lut = ctx\n",
    "    print(\"(Using fresh context - no existing LUT found)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e17cabbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using fresh state (no prior processing)\n",
      "============================================================\n",
      "INTERACTIVE QUERY via ask()\n",
      "============================================================\n",
      "\n",
      "Response:\n",
      "Query: prompt_1\n",
      "Commit: 277db1e6\n",
      "Results (5 found):\n",
      "   1. [ 97.0] ('recompiling\",', 'name);', 'return')\n",
      "   2. [ 87.0] ('argnames,', 'kwds2,', 'values,')\n",
      "   3. [ 79.0] ('1;', 'if', '(likely((padding_length')\n",
      "   4. [ 69.0] ('py_none', '#')\n",
      "   5. [ 65.0] ('class', 'hllcore:')\n",
      "\n",
      "Disambiguation results: 5 items\n",
      "Commits after query: 2\n",
      "\n",
      "Resolved tokens (sample):\n",
      "  [2466]: ['{(2, (\\'suboffset\\', \\'in\\', \\'suboffsets[:ndim]:\\')), (2, (\\'return\\', \\'__pyx_r;\\', \\'}\\')), (1, (\\'/*\\', \\'\"../../../../.cache/uv/builds-v0/.tmpvvcwqg/lib/python3.13/site-packages/numpy/__init__.cython-30.pxd\":790\\')), (1, (\\'xor\\', \\'(a\\')), (1, (\\'\"bird\"],\\', \\'[\"red\",\\')), (1, (\\'whose\\', \\'morphisms\\')), (2, (\\'}\\', \\'/*\\', \\'\"view.memoryview\":896\\')), (1, (\\'__pyx_v_itemp\\', \\'=\\')), (2, (\\'values,\\', \\'kwd_pos_args,\\', \\'__pyx_kwds_len,\\')), (1, (\\'new\\', \\'is\\')), (1, (\\'for\\', \\'(i=code_cache->count;\\')), (1, (\\'py_xincref(module);\\', \\'return\\')), (1, (\"@cname(\\'__pyx_fill_contig_strides_array\\')\", \\'#\\')), (2, (\\'refactoring\\', \\'succeeded\\', \\'automatically.\\')), (1, (\\'#\\', \\'1.\\')), (1, (\\'pyobject\\', \\'*__pyx_getprop___pyx_memoryview_itemsize(pyobject\\')), (0, (\\'cached_type))\\',)), (1, (\\'}\\', \\'__pyx_pycode_new_function_description;\\')), (2, (\\'#endif\\', \\'py_xdecref(reduce);\\', \\'py_xdecref(reduce_ex);\\')), (1, (\\'ulength);\\', \\'#else\\')), (2, (\\'data);\\', \\'#else\\', \\'__pyx_modulestatelookup_data\\')), (1, (\\'if\\', \\'(unlikely(!shape_tuple))\\')), (2, (\\'%d.%d\",\\', \\'(int)\\', \\'(ct_version\\')), (2, (\\'1\\', \\'||\\\\\\\\\\', \\'(__gnuc_minor__\\')), (2, (\\'(1)\\', \\'{\\', \\'__pyx_t_1\\')), (2, (\\'cython_meth_fastcall\\', \\'switch\\', \\'(ml->ml_flags\\')), (2, (\\'only\\', \\'be\\', \\'loaded\\')), (1, (\\'cython_unused_var(__pyx_mstate);\\', \\'__pyx_refnannysetupcontext(\"__pyx_modinit_global_init_code\",\\')), (2, (\\'*wrapper\\', \\'=\\', \\'pyobject_getattrstring((pyobject\\')), (0, (\\'.deprecated.hrt\\',)), (1, (\\'digit;\\', \\'if\\')), (2, (\\'lower_bound\\', \\'=\\', \\'__pyx_state_findmodulestatelookuptablelowerbound(\\')), (2, (\\'**6\\', \\'files**\\', \\'refactored\\')), (1, (\\'=\\', \\'pool.map(process_batch,\\')), (2, (\\'/*tp_finalize*/\\', \\'#else\\', \\'null,\\')), (1, (\\'-\\', \\'element\\')), (2, (\\'0;\\', \\'found\\', \\'|=\\')), (1, (\\'char\\', \\'*__pyx_f_5numpy_7ndarray_4data_data(pyarrayobject\\')), (0, (\\'noether,\\',)), (1, (\\'{&__pyx_mstate_global->__pyx_n_u_p_bits,0};\\', \\'const\\')), (1, (\\'idempotence\\', \\'===\")\\'))}']\n",
      "  [13621]: ['{(2, (\\'from\\', \\'libc.stdint\\', \\'cimport\\')), (2, (\\'750,\\', \\'__pyx_l1_error)\\', \\'__pyx_v_cindex\\')), (2, (\\'/*\\', \\'\"view.memoryview\":944\\', \\'*\\')), (2, (\\'cdef\\', \\'py_ssize_t\\', \\'src_extent\\')), (2, (\\'py_ssize_t\\', \\'shape,\\', \\'stride,\\')), (1, (\\'__pyx_pytuple_fromarray(pyobject\\', \\'*const\\')), (0, (\\'\"view.memoryview\":682\\',)), (2, (\\'=\\', \\'pythread_allocate_lock();\\', \\'__pyx_t_7[7]\\')), (2, (\\'#define\\', \\'__pyx_pyerr_givenexceptionmatches(err,\\', \\'type)\\')), (2, (\\'}\\', \\'#endif\\', \\'name++;\\')), (2, (\\'#else\\', \\'__pyx_t_1\\', \\'=\\')), (2, (\\'#if\\', \\'cython_compiling_in_cpython\\', \\'value\\')), (1, (\\'return\\', \\'pydict_setitem(builder,\\')), (0, (\\'\\\\\\\\bigcap_\\\\\\\\alpha\\',)), (1, (\\'-1;\\', \\'py_status\\')), (2, (\\'{\\', \"__pyx_buffmt_raiseunexpectedchar(\\'z\\');\", \\'return\\')), (2, (\\'expected,\\', \\'desired)\\', \\'std::atomic_compare_exchange_strong(value,\\')), (2, (\\'__pyx_v_have_slices\\', \\'=\\', \\'__pyx_t_2;\\')), (1, (\\'#\\', \\'fractal\\')), (1, (\\'removed\\', \\'at\\')), (1, (\\'if\\', \\'(__pyx_v_direct_copy)\\')), (2, (\\'=\\', \\'width;\\', \\'}\\')), (0, (\\'seed\\',)), (1, (\\'=\\', \\'next;\\')), (0, (\"\\'cumulative_card\\':\",)), (2, (\\'x\\', \\'(immutable)\\', \\'-\\')), (2, (\\'*)__pyx_v_self);\\', \\'__pyx_r\\', \\'=\\')), (1, (\\'null;\\', \\'__pyx_t_10.data\\')), (2, (\\'cython_unused_var(__pyx_decompressstring);\\', \\'#endif\\', \\'pyobject\\')), (0, (\\'__pyx_div_py_ssize_t(__pyx_v_self->len,\\',)), (1, (\\'again\\', \\'next\\')), (2, (\\'__pyx_lineno\\', \\'=\\', \\'__pyx_t_4;\\')), (2, (\\'goto\\', \\'bad;\\', \\'py_py_line\\')), (2, (\"linestyle=\\'--\\',\", \\'alpha=0.7,\\', \"label=f\\'ideal\")), (2, (\\'just\\', \\'8\\', \\'unions.\\')), (1, (\\'time:\\', \\'{df_v2[\\\\\\'ingest_time_ms\\\\\\'].mean():.1f}ms\")\\')), (1, (\\'self.dtype_is_object:\\', \\'*\\')), (2, (\\'__stdcall\\', \\'#define\\', \\'__stdcall\\')), (0, (\\'(long)digits[2])\\',)), (2, (\\'pydict_size(kwds2);\\', \\'if\\', \\'(len\\')), (2, (\\'__pyx_v_dtype_is_object)\\', \\'{\\', \\'void\\')), (2, (\"\\'b\\':\", \\'case\\', \"\\'h\\':\")), (2, (\\'(pyfloat_checkexact(x)\\', \\'?\\', \\'pyfloat_as_double(x)\\')), (2, (\\')$\\', \\'-\\', \\'a\\')), (2, (\\'/*\\', \\'\"view.memoryview\":230\\', \\'*\\')), (1, (\\'=\\', \\'__pyx_cyfunction_get_name(func,\\')), (2, (\\'__pyx_mstate->__pyx_kp_u_core_hll_core_pyx,\\', \\'__pyx_mstate->__pyx_n_u_cardinality,\\', \\'__pyx_mstate->__pyx_kp_b_iso88591_a_q_d_8_t_t_0_c_1_2s_a_s_a_s_a_a,\\')), (2, (\\'\\\\\\\\)\\', \\'that\\', \\'produce\\')), (2, (\\'__pyx_memoryview_obj\\', \\'*)__pyx_v_memviewslice.memview)->flags\\', \\'&\\')), (1, (\\'cython_compiling_in_limited_api\\', \\'||\\')), (2, (\\'(__pyx_v_new_shape\\', \\'<\\', \\'0);\\')), (2, (\\'py_decref(old_tp);\\', \\'}\\', \\'return\\')), (2, (\\'\"6061626364656667\"\\', \\'\"7071727374757677\"\\', \\'};\\')), (1, (\\'mtx_lock(&__pyx_modulestatelookup_mutex)\\', \\'#define\\')), (2, (\\'as\\', \\'$(\\', \\'n\\')), (1, (\\'__pyx_t_14;\\', \\'py_ssize_t\\')), (1, (\\'&\\', \\'(<uint32_t>1\\')), (1, (\\'#define\\', \\'__pyx_pyunicode_data(u)\\')), (0, (\\'__pyx_pyobject_getattrstr(obj,\\',)), (1, (\"\\'l\\':\", \\'return\\')), (0, (\\'\"view.memoryview\":543\\',)), (1, (\\'=\\', \\'pynumber_and(stepval,\\')), (2, (\\'have:\\', \\'```math\\', \\'d_i\\')), (2, (\\'}\\', \\'}\\', \\'*module\\')), (1, (\\'__pyx_memoryviewslice_obj),\\', \\'0,\\')), (2, (\\'\"core/hll_core.pyx\":494\\', \\'*\\', \\'return\\')), (2, (\\'0,\\', \\'/*tp_iternext*/\\', \\'__pyx_methods__memoryviewslice,\\')), (2, (\\'__pyx_l1_error)\\', \\'/*\\', \\'\"view.memoryview\":559\\')), (2, (\\'self.get_registers_roaring()\\', \\'cdef\\', \\'int\\')), (2, (\\'pythread_allocate_lock()\\', \\'#\\', \\'<<<<<<<<<<<<<<\\')), (2, (\\'a\\', \\'**one-way\\', \\'injection**\\')), (2, (\\'|\\', \\'`a\\', \\'&\\')), (0, (\\'(__pyx_pytuple_set_item(__pyx_t_5,\\',)), (1, (\\'=\\', \\'merge(b,\\')), (2, (\\'__pyx_pyexc_indexerror_check(obj)\\', \\'__pyx_typecheck(obj,\\', \\'pyexc_indexerror)\\'))}', '{(1, (\\'__pyx_cyfunction_raise_argument_count_error(__pyx_cyfunctionobject\\', \\'*func,\\')), (1, (\\'/*proto*/\\', \\'pydoc_strvar(__pyx_doc_4core_8hll_core_7hllcore_6compute_reg_zeros_batch,\\')), (1, (\\'context)`\\', \\'|\\')), (2, (\\'prior](https://medium.com/@swarnenduiitb2020/the-man-who-solved-learning-in-1964-and-why-we-ignored-him-for-60-years-602a23ddf956)\\', \\'2.\\', \\'**crdts**:\\')), (2, (\\'pydatatype_elsize(self)\\', \\'*\\', \\'*\\')), (2, (\\'void\\', \\'__pyx_raiseneedmorevalueserror(py_ssize_t\\', \\'index);\\')), (1, (\\'pyobject\\', \\'*type,\\')), (1, (\\'\"view.memoryview\":980\\', \\'*\\')), (1, (\\'__pyx_getsets_memoryview,\\', \\'/*tp_getset*/\\')), (2, (\\'32\\', \\'+\\', \\'bit_index\\')), (1, (\\'__pyx_err(1,\\', \\'432,\\')), (2, (\\'}\\', \\'/*\\', \\'owneddictnext\\')), (1, (\\'>\\', \\'0x19000000\\')), (1, (\\'image\\', \\'$(\\')), (0, (\\'__pyx_tp_clear__memoryviewslice(pyobject\\',)), (1, (\\'stop\\', \\'=\\')), (1, (\\'5,\\', \\'__pyx_l1_error);\\')), (1, (\\'llabs(value)\\', \\'#elif\\')), (2, (\\'/*\\', \\'cmodulepreamble\\', \\'*/\\')), (0, (\\'defined(pybytearray_get_size)))\\',)), (1, (\\'fixed-size\\', \\'vector\\')), (2, (\\'*self,\\', \\'pyobject\\', \\'*arg1,\\')), (0, (\\'(__pyx_v_src_shape[0]);\\',)), (0, (\\'(__pyx_fix_up_extension_type_from_spec(&__pyx_type___pyx_memviewenum_spec,\\',)), (1, (\\'\"\"\"store\\', \\'immutable\\')), (2, (\\'$(\\', \\'p:\\', \\'h_i\\')), (2, (\\'break;\\', \\'digit\\', \\'=\\')), (2, (\\'*\\', \\'1_000_000\\', \\'print(f\"query\\')), (1, (\\'import\\', \\'kernel\\')), (2, (\\'cython_inline\\', \\'__pyx_t_float_complex\\', \\'__pyx_c_diff_float(__pyx_t_float_complex,\\')), (1, (\\'return\\', \\'hypotf(z.real,\\')), (2, (\\'from\\', \\'core\\', \\'import\\')), (2, (\\'if\\', \\'(c_or_f_flag\\', \\'&\\')), (0, (\\'*tstate);\\',)), (0, (\\'kernel\\',)), (2, (\\'(100\\', \\'from_batch\\', \\'+\\')), (1, (\\'/*\\', \\'parsekeywordsimpl\\')), (1, (\\'expected\\', \\'\\\\\\')\\\\\\'\");\\')), (2, (\\'case\\', \\'meth_method\\', \\'|\\')), (2, (\\')$\\', \\'of\\', \\'the\\')), (0, (\\'(__pyx_nargs)\\',)), (2, (\\'are\\', \\'lattice-isomorphic\\', \\'to\\')), (2, (\\'__pyx_pysequence_item(__pyx_t_2,\\', \\'__pyx_t_3);\\', \\'#endif\\')), (1, (\\'__pyx_raiseunexpectedtypeerror(const\\', \\'char\\')), (2, (\\'__pyx_pybool_fromlong(is_coroutine);\\', \\'}\\', \\'static\\')), (0, (\\'main_method\\',)), (2, (\\'py_ssize_t\\', \\'__pyx_v_src_stride;\\', \\'py_ssize_t\\')), (0, (\\'/*normal\\',)), (2, (\\'__pyx_structfield\\', \\'*field_b\\', \\'=\\')), (2, (\\'+\\', \\'1,\\', \\'strides\\')), (2, (\\')$\\', \\'(since\\', \\'a\\')), (0, (\\'(likely(local_value))\\',)), (1, (\\'from\\', \\'.sparse_hrt_3d\\')), (1, (\\'if\\', \\'(unlikely(!__pyx_mstate_global->__pyx_codeobj_tab[5]))\\')), (1, (\\'-\\', \\'**sheaf\\')), (0, (\\'precisions\\',)), (1, (\\'0x050b0000\\', \\'sizeof(pyarraymultiiterobject),\\')), (2, (\\'__pyx_xdecref(__pyx_r);\\', \\'{\\', \\'/*\\')), (2, (\\'__pyx_f_5numpy_7ndarray_4ndim_ndim(pyarrayobject\\', \\'*__pyx_v_self);\\', \\'/*\\')), (2, (\\'$(\\', \\'h:\\', \\'t\\')), (2, (\\'practical\\', \\'programming\\', \\'decisions\\')), (1, (\\'__pyx_mstate->__pyx_n_u_copy,\\', \\'__pyx_mstate->__pyx_kp_b_iso88591_a_gqd_j_d_q,\\')), (0, (\\'((__pyx_v_ndim\\',)), (2, (\\'}\\', \\'__pyx_gotref(array_obj);\\', \\'memview_obj\\')), (1, (\\'meth_method\\', \\'|\\')), (0, (\\'__pyx__getexception(pythreadstate\\',)), (1, (\\'deterministic\\', \\'function:\\')), (2, (\\'=\\', \\'result\\', \\'#\\')), (1, (\\'the\\', \\'dtype\\')), (0, (\\'identification.\\',)), (2, (\\'(uint32_t)\\', \\'((((((uint32_t)digits[1])\\', \\'<<\\')), (2, (\\'__pyx_t_3\\', \\'=\\', \\'__pyx_pyobject_fastcallmethod((pyobject*)__pyx_mstate_global->__pyx_n_u_union,\\')), (2, (\\'*typeinfo\\', \\'*\\', \\'*\\')), (2, (\\'__pyx_t_6,\\', \\'__pyx_referencesharing_ownstrongreference);\\', \\'++__pyx_t_6;\\')), (1, (\\'2^p_bits\\', \\'*\\')), (2, (\\'coo)\\', \"\\'immutablesparsetensor\\',\", \"\\'get_device\\',\")), (1, (\\'{\\', \\'pyerr_format(pyexc_typeerror,\\')), (2, (\\'__pyx_mstate->__pyx_n_u_raw_sum,\\', \\'__pyx_mstate->__pyx_n_u_m,\\', \\'__pyx_mstate->__pyx_n_u_alpha,\\')), (1, (\\'t\\', \\'\\\\\\\\leftarrow\\')), (2, (\\'}\\', \\'py_clear(p->from_object);\\', \\'pyobject_gc_track(o);\\')), (2, (\\'intersect\\', \\'hlls\\', \\'with\\'))}', '{(0, (\\'__pyx_typecheck(__pyx_v_o,\\',)), (0, (\\'format\\',)), (0, (\\'__pyx_incref(__pyx_v_bytesvalue);\\',)), (0, (\\'incompatible\\',)), (2, (\\'__pyx_err(0,\\', \\'669,\\', \\'__pyx_l1_error)\\')), (0, (\\'__pyx_cyfunction_vectorcall_o;\\',)), (1, (\\'=\\', \\'__pyx_nargs;\\')), (0, (\\'unexpected\\',)), (1, (\\'case\\', \"\\'s\\':\")), (0, (\\'*__pyx_v_attr)\\',)), (2, (\"\\'{\\')\", \\'{\\', \\'pyerr_setstring(pyexc_valueerror,\\')), (2, (\\'as_c_int\\', \\'=\\', \\'pylong_aslonglong(current);\\')), (2, (\\'yield\\', \\'conservation\\', \\'laws.\\')), (2, (\\'7.\\', \\'persistence\\', \\'-\\')), (1, (\\'4))\\', \\'#\\')), (0, (\\'__pyx_type___pyx_memviewenum_slots[]\\',)), (2, (\\'*\\', \\'*/\\', \\'struct\\')), (2, (\\'#define\\', \\'pyobject_realloc(p)\\', \\'pymem_realloc(p)\\')), (1, (\\'pybytes_fromstringandsize(null,\\', \\'code_len);\\')), (2, (\\'op;\\', \\'}\\', \\'static\\')), (2, (\\'v)\\', \\'(pylist_set_item(o,\\', \\'i,\\')), (1, (\\'py_clear(m->func_doc);\\', \\'py_clear(m->func_globals);\\')), (1, (\\'==\\', \\'py_false\\')), (1, (\\'they\\', \\'may\\')), (2, (\\'__pyx_v_item,\\', \\'__pyx_v_self->dtype_is_object);\\', \\'}\\')), (0, (\\'32k\\',)), (2, (\\'#undef\\', \\'cython_use_freelists\\', \\'#define\\')), (2, (\\'*/\\', \\'goto\\', \\'__pyx_l7;\\')), (2, (\\'self.registers\\', \\'*/\\', \\'__pyx_v_self->m\\')), (2, (\\'tstate->curexc_value\\', \\'=\\', \\'0;\\')), (2, (\\'exc_info->exc_value\\', \\'=\\', \\'local_value;\\')), (2, (\\'|\\', \\'|\\', \\'0.6.0\\')), (2, (\\'p\\', \\')$).\\', \\'indeed,\\')), (2, (\\'\\\\\\\\boxed{\\\\\\\\mathcal{t}(t+1)\\', \\'=\\', \\'\\\\\\\\mathcal{t}(t)\\')), (1, (\\'projection\\', \\'sets.\\')), (2, (\\'*__pyx_f_5numpy_7ndarray_5descr_descr(pyarrayobject\\', \\'*__pyx_v_self);\\', \\'/*\\')), (2, (\\'=\\', \\'__pyx_t_3;\\', \\'/*\\')), (2, (\\'cython_compiling_in_cpython_freethreading\\', \\'&&\\', \\'py_version_hex\\')), (1, (\\')$\\', \\'land\\')), (0, (\\'\"core/hll_core.pyx\":212\\',)), (2, (\\'#define\\', \\'__pyx_pyexc_memoryerror_check(obj)\\', \\'__pyx_typecheck(obj,\\')), (2, (\\'n,\\', \\'v,\\', \\'fn,\\')), (1, (\\'(kwds2)\\', \\'return\\')), (2, (\\'-\\', \\'property-based\\', \\'testing\\')), (2, (\\'__pyx_incref(((pyobject\\', \\'*)__pyx_t_1));\\', \\'__pyx_r\\')), (0, (\\'(unlikely(op->func_name\\',)), (2, (\\'__pyx_v_reg_idx;\\', \\'*((uint32_t\\', \\'*)\\')), (1, (\\'conservation\\', \\'law?\\')), (1, (\\'pyerr_format(pyexc_valueerror,\\\\\\\\\\', \\'\"does\\')), (2, (\\'bijection\\', \\'$(\\', \\'s\\')), (2, (\\'pop\\', \\'#endif\\', \\'const\\')), (1, (\\'\"core/hll_core.pyx\":229\\', \\'*\\')), (2, (\"can\\'t\", \\'be\\', \\'modified\\')), (1, (\\'canonical\\', \\'topology\\')), (0, (\\'meth_keywords)\\',)), (1, (\\'__pyx_string_tab[145]\\', \\'#define\\')), (1, (\\'null);\\', \\'else\\')), (2, (\\'(unlikely(!__pyx_t_2))\\', \\'__pyx_err(0,\\', \\'390,\\')), (2, (\\'(*ts\\', \\'!=\\', \"\\'{\\')\")), (2, (\\'(__pyx_pytuple_set_item(__pyx_t_2,\\', \\'0,\\', \\'__pyx_t_1)\\')), (1, (\\'**result**:\\', \\'all\\')), (2, (\\'__pyx_t_5;\\', \\'/*\\', \\'\"view.memoryview\":1289\\')), (1, (\\'refcount_objects_in_slice(self.data,\\', \\'self._shape,\\')), (1, (\\'__pyx_t_9;\\', \\'}\\')), (2, (\\'py_clear(p->_format);\\', \\'pytypeobject\\', \\'*tp\\')), (2, (\\'__pyx_memviewslice\\', \\'*__pyx_memoryview_get_slice_from_memoryview(struct\\', \\'__pyx_memoryview_obj\\')), (1, (\\'the\\', \\'information-theoretic\\')), (0, (\"\\'extract_entanglement\\',\",)), (0, (\\'*clear_module_state\\',)), (2, (\\'then\\', \\'one\\', \\'from_batch()\\')), (2, (\\'visualize\\', \\'throughput\\', \\'vs\\')), (2, (\\'1);\\', \\'if\\', \\'(!cython_assume_safe_macros\\')), (2, (\\'cython_unused\\', \\'pyobject\\', \\'**args,\\')), (2, (\\'}\\', \\'/*\\', \\'\"view.memoryview\":691\\')), (1, (\\'/*\\', \\'\"view.memoryview\":899\\'))}']\n",
      "  [7547]: ['{(2, (\\'char*.\\', \\'*/\\', \\'/*\\')), (1, (\\'}\\', \\'__pyx_buf_diminfo;\\')), (1, (\\'/*\\', \\'\"view.memoryview\":1133\\')), (2, (\\'return\\', \\'kwvalues[i];\\', \\'}\\')), (1, (\\'__pyx_refnannysetupcontext(\"is_f_contig\",\\', \\'0);\\')), (2, (\\'julia\\', \\'equivalent\\', \\'(set_comp):\\')), (1, (\\'sizeof_size_t\\', \\'#define\\')), (2, (\\'p\\', \\')$.\\', \\'because\\'))}', '{(1, (\\'__pyx_err(0,\\', \\'171,\\')), (2, (\\'{\"__setstate__\",\\', \\'(pycfunction)(void(*)(void))(__pyx_pycfunction_fastcallwithkeywords)__pyx_pw_4core_8hll_core_7hllcore_41__setstate__,\\', \\'__pyx_meth_fastcall|meth_keywords,\\')), (1, (\\'with\\', \\'hllset.add()\\')), (1, (\\'{cumulative_hll.cardinality():,.0f}\")\\', \\'print(f\"cardinality\\')), (2, (\\'<<<<<<<<<<<<<<\\', \\'*\\', \"\\'non_zero_registers\\':\")), (1, (\\'*\\', \\'for\\')), (0, (\\'valid\\',)), (2, (\\'(1-d)\\', \\'index\\', \\'into\\')), (1, (\\'engine**\\', \\'for\\'))}', '{(2, (\\'=\\', \\'(__pyx_v_total_bits\\', \\'+\\')), (1, (\\'cython_avoid_thread_unsafe_borrowed_refs))\\', \\'{\\')), (2, (\\'void\\', \\'__pyx_inc_memview(__pyx_memviewslice\\', \\'*,\\')), (1, (\\'register\\', \\'(equivalent\\')), (2, (\\'=\\', \\'__pyx_pylong_as_uint32_t(values[1]);\\', \\'if\\')), (1, (\\'uint64_t\\', \\'__pyx_t_1;\\')), (2, (\\'__pyx_fetchcommontypefromspec(\\', \\'mstate->__pyx_commontypesmetaclasstype,\\', \\'module,\\')), (2, (\\'#define\\', \\'__pyx_pytype_getslot(type,\\', \\'name,\\')), (1, (\\'__pyx_mstate->__pyx_memviewenum_type)\\', \\'<\\')), (0, (\\'__pyx_c_conj_double(__pyx_t_double_complex\\',)), (1, (\\'digit_pairs_8[2*8*8+1]\\', \\'=\\')), (2, (\\'__pyx_r\\', \\'=\\', \\'__pyx_pf_4core_8hll_core_7hllcore_32set_registers_roaring(((struct\\')), (1, (\\'int)(co_optimized|co_newlocals),\\', \\'677};\\')), (1, (\\'1),\\', \\'__pyx_v_itemsize,\\')), (1, (\\'95)))\\', \\'#define\\')), (2, (\\'if\\', \\'(__pyx_pyobject_getslot(o,\\', \\'tp_dealloc,\\')), (2, (\\'**coarsened**\\', \\'(moving\\', \\'down).\\')), (2, (\\'(*v)(p->from_object,\\', \\'a);\\', \\'if\\')), (0, (\\'\"core.hll_core.\"\"array\",\\',)), (2, (\\'*\\', \\'py_incref(py_none)\\', \\'*\\')), (2, (\\'import\\', \\'warnings\\', \\'#\\')), (0, (\\'unlikely(__pyx_kwds)\\',)), (2, (\\'compatibility\\', \\'in\\', \\'one\\')), (2, (\\'(batch_idx,\\', \\'batch_size,\\', \\'seed)\\')), (2, (\"va=\\'bottom\\',\", \\'fontsize=11,\\', \"fontweight=\\'bold\\')\")), (0, (\\'read<end;\\',)), (0, (\"ax2.scatter(df[\\'size\\'],\",)), (2, (\\'be\\', \\'repeated\\', \\'safely\\')), (1, (\\'sum:\\', \\'2^(-highest_set_bit(register[i]))\\')), (0, (\\'cfunc->method_name;\\',)), (1, (\\'size\\', \\'=\\')), (1, (\\'__pyx_tp_as_mapping_memoryview\\', \\'=\\')), (2, (\\'((int)-1)))\\', \\'__pyx_err(1,\\', \\'751,\\')), (1, (\\'sizes\\', \\'(log-uniform\\')), (1, (\\'clineintraceback.proto\\', \\'(used\\')), (1, (\\'||\\', \\'err\\')), (2, (\\'pyobject\\', \\'*args[1]\\', \\'=\\')), (2, (\\'//\\', \\'3.13+\\', \\'i\\')), (1, (\\'*__pyx_v_value);\\', \\'/*proto*/\\')), (1, (\\'__pyx_gotref(__pyx_t_5);\\', \\'__pyx_decref(__pyx_t_3);\\')), (1, (\\'symmetric_difference(self,\\', \\'hllcore\\')), (0, (\\'(pycfunction)__pyx_array___getattr__,\\',)), (0, (\\'__pyx_xdecref(__pyx_t_2);\\',)), (0, (\\'t->tp_flags\\',)), (1, (\\'|\\', \\'(uint32_t)digits[1])\\')), (1, (\\'|\\', \\'(1*__pyx_py_vectorcall_arguments_offset),\\')), (2, (\\'*string\\', \\'=\\', \\'pybytes_fromstringandsize(bytes\\')), (1, (\\'entries\\', \\'===\")\\')), (2, (\\'(unlikely(!module_name))\\', \\'{\\', \\'goto\\')), (2, (\\'/*\\', \\'\"view.memoryview\":528\\', \\'*\\')), (2, (\\'__pyx_refnannysetupcontext(\"pybuffer_index\",\\', \\'0);\\', \\'/*\\')), (2, (\\'__pyx_kp_u_got_differing_extents_in_dimensi\\', \\'__pyx_string_tab[41]\\', \\'#define\\')), (1, (\\'merge_times_all\\', \\'=\\')), (0, (\\'__pyx_v_have_start\\',)), (2, (\\'*)__pyx_cyfunction_repr},\\', \\'{py_tp_call,\\', \\'(void\\')), (1, (\\'/*\\', \\'pyobjectvectorcallkwbuilder.proto\\')), (1, (\\'\"view.memoryview\":517\\', \\'*\\')), (0, (\\'__pyx_v_memview->view.ndim,\\',)), (1, (\\'*\\', \\'dst.memview\\')), (2, (\\'#define\\', \\'__pyx_n_u_i\\', \\'__pyx_string_tab[139]\\')), (1, (\\'memview.view.strides\\', \\'*\\')), (2, (\\'}\\', \\'/*\\', \\'swapexception\\')), (2, (\\'py_xdecref(values[__pyx_temp]);\\', \\'}\\', \\'__pyx_addtraceback(\"view.memoryview.array.__setstate_cython__\",\\')), (2, (\\'#else\\', \\'int\\', \\'one\\')), (2, (\\'cython_inline\\', \\'__pyx_t_double_complex\\', \\'__pyx_c_quot_double(__pyx_t_double_complex\\')), (1, (\\'__pyx_v_obj\\', \\'=\\')), (1, (\\'int\\', \\'__pyx_f_5numpy_7ndarray_4ndim_ndim(pyarrayobject\\')), (1, (\\'*__pyx_ptype_5numpy_ufunc;\\', \\'pyobject\\')), (0, (\\'checkunpicklechecksum.proto\\',)), (2, (\\'i,\\', \\'temp_int)\\', \\'<\\')), (1, (\\'case\\', \\'0:\\')), (2, (\\'<<\\', \\'tz)\\', \\'#\\')), (1, (\\'===\")\\', \\'print(f\"merged\\')), (1, (\\'the\\', \\'int64\\')), (1, (\\'export\\', \\'code\\')), (1, (\\'0x030d0000\\', \\'if\\')), (2, (\\'__pyx_tp_traverse_4core_8hll_core_hllcore(pyobject\\', \\'*o,\\', \\'visitproc\\')), (2, (\\'b\\', \\'+\\', \\'d\\')), (2, (\\'*o,\\', \\'pyobject\\', \\'*n,\\')), (2, (\\'(getset\\', \\'&&\\', \\'getset->name)\\')), (1, (\\'0;\\', \\'__pyx_v_card_union\\')), (2, (\\'__pyx_t_1\\', \\'=\\', \\'__pyx_pyunicode_from_int(__pyx_v_i,\\')), (1, (\\'int\\', \\'__pyx_lineno\\')), (2, (\\'*itemp):\\', \\'*/\\', \\'__pyx_xclear_memview((&__pyx_v_self->from_slice),\\'))}', \"{(2, ('<', 'sizeof(py_ssize_t))', '||\\\\\\\\')), (1, ('=', '100')), (0, ('hasattr.proto',)), (2, ('dst_ndim,', 'src_ndim)', '#')), (2, ('{__pyx_mstate_global->__pyx_n_u_estimate_bias};', '__pyx_t_2', '=')), (2, ('total_parallel_time,', 'total_optimized_time]', 'colors')), (1, ('//', '2):')), (1, ('n);', '}')), (0, ('pynumber_long(x))',))}\", '{(2, (\\'element\\', \\'$(\\', \\'\\\\\\\\hat{1}\\')), (1, (\\'bitmaps.\\', \\'*/\\')), (2, (\\'i<251;\\', \\'++i)\\', \\'{\\')), (0, (\\'\"view.memoryview\":1166\\',)), (2, (\\'print(f\"head\\', \\'match:\\', \\'{mos2.head.name\\')), (2, (\\'int\\', \\'flags;\\', \\'}\\')), (1, (\\'!defined(ms_windows)\\', \\'#ifndef\\')), (1, (\\'lut\\', \\'entries:\\')), (0, (\\'\\\\\\\\mathcal{e}(2,3)\\',)), (2, (\\'#endif\\', \\'#if\\', \\'defined(__clang__)\\')), (1, (\\'&__pyx_t_7)\\', \\'<\\')), (1, (\\'5,\\', \\'__pyx_nargs);\\')), (0, (\\'*__pyx_array_get_memview(struct\\',)), (2, (\\'lattice,\\', \\'config)\\', \\'|\\')), (2, (\\'__pyx_l6_error:;\\', \\'/*exception\\', \\'exit:*/{\\')), (0, (\\'65536.0)\\',)), (2, (\\'&&\\', \\'!cython_atomics\\', \\'(void)__pyx__find_code_object;\\')), (2, (\\'{\\', \\'if\\', \\'(sizeof(py_hash_t)\\')), (2, (\\'**7.\\', \\'the\\', \\'entanglement\\')), (1, (\\'{\\', \\'if\\')), (2, (\\'*__pyx_pw_15view_dot_memoryview_10memoryview_4ndim_1__get__(pyobject\\', \\'*__pyx_v_self)\\', \\'{\\')), (1, (\\'edges)\\', \\'|\\')), (2, (\\'#define\\', \\'__pyx_pyobject_delslice(obj,\\', \\'cstart,\\')), (2, (\\'__pyx_refnannysetupcontext(\"memoryview_copy\",\\', \\'0);\\', \\'/*\\')), (0, (\\'pydict_setitemstring(builder,\\',)), (2, (\\'=\\', \\'[(i,\\', \\'worker_batches[i],\\')), (2, (\\'__pyx_l6_skip;\\', \\'__pyx_l5_argtuple_error:;\\', \\'__pyx_raiseargtupleinvalid(\"add_from_hashes\",\\')), (2, (\\'}\\', \\'__pyx_l22:;\\', \\'/*\\')), (2, (\\'all\\', \\'tokens\\', \\'3.\\')), (1, (\\'likely(!__pyx_mstate->__pyx_ptype_4core_8hll_core_hllcore->tp_dictoffset\\', \\'&&\\')), (0, (\\'lock\\',)), (0, (\\'__pyx_xdecref(__pyx_t_12);\\',)), (2, (\\'__pyx_mstate_global->__pyx_n_u_dtype);\\', \\'if\\', \\'(unlikely(!__pyx_t_1))\\')), (1, (\\'\\\\\\\\preceq\\', \"q\\'\")), (1, (\\'three-way\\', \\'comparison\\'))}', '{(2, (\\'n-token\\', \\'scales\\', \\'correlate,\\')), (1, (\\'range(nblocks):\\', \\'*\\')), (1, (\\'100_000\\', \\'edges\\')), (2, (\\'if\\', \\'arg\\', \\'<\\')), (2, (\\'without\\', \\'modifying\\', \\'state.\\\\\\\\n\\\\\\\\n\\')), (2, (\\'(pycfunction)(void(*)(void))(__pyx_pycfunction_fastcallwithkeywords)__pyx_pw_4core_8hll_core_7hllcore_3add_token,\\', \\'__pyx_meth_fastcall|meth_keywords,\\', \\'__pyx_doc_4core_8hll_core_7hllcore_2add_token},\\')), (1, (\\'through\\', \\'the\\')), (1, (\\'3.\\', \\'updates\\')), (1, (\\'{large_hrt.nnz:,}\\', \\'edges\")\\')), (2, (\\'n(t+1))\\', \\'\\\\\\\\setminus\\', \\'d(t)\\')), (2, (\\'pyimport_importmodule(__pyx_builtin_module_name);\\', \\'if\\', \\'(unlikely(!__pyx_t_1))\\')), (1, (\\'defined(have_stdarg_prototypes)\\', \\'va_start(vargs,\\')), (2, (\\'515,\\', \\'__pyx_l1_error)\\', \\'__pyx_gotref(__pyx_t_4);\\')), (1, (\\'*descr;\\', \\'descrgetfunc\\')), (1, (\\'return\\', \\'result\\')), (1, (\\'*\\', \\'a.imag;\\')), (2, (\\'0,\\', \\'0)\\', \\'#define\\')), (2, (\\'(likely(pydict_checkexact(dict)))\\', \\'{\\', \\'result\\')), (2, (\\'sets\\', \\'$(\\', \\'p\\')), (1, (\\'ellipsis:\\', \\'*\\')), (1, (\\'0\\', \\'},\\')), (1, (\\'range(num_workers)]\\', \\'print(f\"\\\\\\\\n🚀\\')), (2, (\\'stride\\', \\'*/\\', \\'/*else*/\\')), (2, (\\'cython_inline\\', \\'int\\', \\'__pyx_parsekeywords(\\')), (2, (\\'your\\', \\'8\\', \\'cores\\')), (0, (\\'pylong_fromlong((1l\\',)), (0, (\\'*),\\',)), (2, (\\'n-chain\\', \\'2.\\', \\'**measurement\\')), (1, (\\'=\\', \\'{\"get_registers_roaring\",\\')), (0, (\\'__pyx_memoryview_copy_new_contig((&__pyx_v_src),\\',)), (1, (\\'return\\', \\'64\\')), (2, (\\'cython_unused\\', \\'pyobject\\', \\'*__pyx_v___pyx_state\\')), (1, (\\'\\\\\\\\to\\', \\'p\\')), (1, (\\'maps\\', \\'$(\\')), (1, (\\'wraparound);\\', \\'/*\\')), (2, (\\'worker\\', \\'hllsets...\")\\', \\'merge_opt_start\\')), (1, (\\'int\\', \\'type_num\\')), (2, (\\'meth_found\\', \\'=\\', \\'1;\\')), (0, (\\'cython_unused_var(\\',)), (2, (\\'scope\\', \\'*/\\', \\'__pyx_t_5\\')), (0, (\\'invalid_keyword_type:\\',)), (1, (\\'=\\', \\'pyobject_callmethod(module,\\')), (2, (\\'(unlikely(!__pyx_mstate_global->__pyx_codeobj_tab[18]))\\', \\'goto\\', \\'bad;\\')), (2, (\\'|\\\\\\\\{3,4\\\\\\\\}|/4\\', \\'=\\', \\'0.5\\')), (1, (\\'0;\\', \\'__pyx_refnannysetupcontext(\"memoryview_copy_from_slice\",\\')), (1, (\\'(__pyx_pyunicode_equals(__pyx_v_self->mode,\\', \\'__pyx_mstate_global->__pyx_n_u_fortran,\\')), (1, (\\'guarantees.\\', \\'*/\\')), (1, (\\'columns\\', \\'transpose_3d(am)\\')), (2, (\\'is\\', \\'reminiscent\\', \\'of\\')), (2, (\\'to:\\', \\'{lattice.col_connections(400)}\")\\', \\'print()\\')), (2, (\\'views\\', \\'are\\', \\'needed\\')), (1, (\\'!cython_assume_safe_size\\', \\'if\\')), (2, (\\'py_long_long\\', \\'#define\\', \\'py_long_long\\')), (2, (\\'return\\', \\'h\\', \\'cdef\\')), (1, (\\'{\"add_token\",\\', \\'(pycfunction)(void(*)(void))(__pyx_pycfunction_fastcallwithkeywords)__pyx_pw_4core_8hll_core_7hllcore_3add_token,\\')), (1, (\\'(-1))\\', \\'goto\\')), (2, (\\'-1;\\', \\'/*\\', \\'\"view.memoryview\":720\\')), (1, (\"\\'\", \"\\':\")), (1, (\\'#define\\', \\'__pyx_pytype_frommoduleandspec(m,\\'))}', '{(2, (\\'in\\', \\'range(n):\\', \\'*/\\')), (2, (\\'__pyx_r;\\', \\'/*\\', \\'\"../../../../.cache/uv/builds-v0/.tmpvvcwqg/lib/python3.13/site-packages/numpy/__init__.cython-30.pxd\":1070\\')), (2, (\\'const\\', \\'char\\', \\'digit_pairs_10[2*10*10+1]\\')), (1, (\\'contains:\\', \\'#\\')), (1, (\\'has\\', \\'objects\\')), (2, (\\'simplicial\\', \\'structure**\\', \\'this\\')), (2, (\\'pylong_shift)\\', \\'|\\', \\'(unsigned\\')), (2, (\\'?\\', \\'-value\\', \\':\\')), (1, (\\'def\\', \\'__reduce_cython__(self):\\')), (1, (\"\\'manifoldiicaconfig\\',\", \"\\'create_manifold_iica\\',\")), (1, (\\'hrt\\', \\'dimension)\\')), (2, (\\'len\\', \\'=\\', \\'py_size(list);\\')), (2, (\\'struct\\', \\'__pyx_vtabstruct_4core_8hll_core_hllcore\\', \\'__pyx_vtable_4core_8hll_core_hllcore;\\')), (1, (\\'clength,\\', \\'int\\')), (2, (\\'b)\\', \\'{\\', \\'if\\')), (2, (\\'69.0]\\', \"(\\'py_none\\',\", \"\\'#\\')\")), (2, (\\'#endif\\', \\'#define\\', \\'__pyx_pyunicode_read_char(u,\\')), (0, (\\'__pyx_v_result->__pyx_base.view.buf\\',)), (2, (\\'__pyx_vtabstruct_4core_8hll_core_hllcore\\', \\'__pyx_vtable_4core_8hll_core_hllcore;\\', \\'static\\')), (1, (\\'we\\', \\'need\\')), (1, (\\'pyobject\\', \\'*__pyx_pf_15view_dot_memoryview_10memoryview_4base___get__(struct\\')), (2, (\\'=\\', \\'__pyx_pf_4core_8hll_core_7hllcore_14intersect(((struct\\', \\'__pyx_obj_4core_8hll_core_hllcore\\')), (2, (\\'return\\', \\'0;\\', \\'__pyx_l1_error:;\\')), (2, (\\'key\\', \\'point:\\', \\'the\\')), (1, (\\'modified\\', \\'in\\')), (2, (\\'__pyx_set_size(obj,\\', \\'size)\\', \\'py_set_size(obj,\\')), (1, (\\'(__pyx_is_uniquely_referenced(o,\\', \\'unsafe_shared)\\')), (2, (\\'(new)\\', \\'and\\', \\'uint8\\')), (2, (\\'&&\\', \\'defined(__gnuc__)\\', \\'#undef\\')), (1, (\\'__pyx_pyexc_indexerror_check(obj)\\', \\'__pyx_typecheck(obj,\\')), (2, (\\'adding\\', \\'to\\', \\'registers.\\\\\\\\n\\\\\\\\n\\')), (1, (\\'__pyx_modinit_type_import_code(__pyx_mstatetype\\', \\'*__pyx_mstate);\\')), (1, (\\'}\\', \\'__pyx_l6_break:;\\')), (2, (\\'(axis\\', \\'%d)\",\\', \\'dim)\\')), (1, (\\'__pyx_getbuiltinname(name))\\', \\':\\\\\\\\\\')), (1, (\\'mslice.shape[i]\\', \\'>\\')), (2, (\\'__pyx_t_double_complex\\', \\'__pyx_c_diff_double(__pyx_t_double_complex,\\', \\'__pyx_t_double_complex);\\')), (2, (\\'cythonfunction\\', \\'*/\\', \\'static\\')), (2, (\\'with\\', \\'ai**\\', \\'maintaining\\')), (2, (\"x\\'\", \\'\\\\\\\\xrightarrow{p}\\', \"y\\'\")), (1, (\\'cython_vectorcall\\', \\'__pyx_vectorcallfunc\\')), (2, (\\'=\\', \\'pytuple_new((py_ssize_t)nargs);\\', \\'if\\')), (1, (\\'(int)\\', \\'((((((((int)digits[2])\\')), (2, (\\'(value\\', \\'&\\', \\'0x07));\\')), (2, (\\'pyunicode_asunicode\\', \\'static\\', \\'cython_inline\\')), (2, (\"there\\'s\", \\'a\\', \\'more\\')), (1, (\\'int\\', \\'memview_flags\\')), (2, (\\'#\\', \\'result.input_hllset\\', \\'-\\')), (0, (\\'\"../../../../.cache/uv/builds-v0/.tmpvvcwqg/lib/python3.13/site-packages/numpy/__init__.cython-30.pxd\":781\\',)), (2, (\\'(round-robin\\', \\'for\\', \\'load\\')), (2, (\\'start\\', \\'print(f\"numpy\\', \\'bulk_union:\\')), (2, (\\'=\\', \\'struct.pack(self.view.format,\\', \\'*value)\\')), (1, (\\'*\\', \\'itemp\\')), (1, (\\'__pyx_sst_abs(value)\\', \\'((py_ssize_t)_abs64(value))\\')), (2, (\\'are\\', \\'the\\', \\'**stalks**\\')), (1, (\\'cython_inline\\', \\'#endif\\')), (1, (\\'if\\', \\'(!(likely(((__pyx_t_2)\\')), (2, (\\'g\\', \\'\\\\\\\\)\\', \\'on\\')), (1, (\\'\"view.memoryview\":257\\', \\'*\\')), (2, (\\'{0};\\', \\'#endif\\', \\'static\\')), (1, (\\'d_1,\\', \\'d_2,\\')), (2, (\\'=\\', \\'pymethod_get_function(attr);\\', \\'py_incref(function);\\')), (1, (\\'=\\', \\'((pyobject*)p->name);\\'))}', '{(2, (\\'=\\', \\'values[0];\\', \\'__pyx_v___pyx_checksum\\')), (2, (\\'pylong_shift)\\', \\'|\\', \\'(size_t)digits[2])\\')), (1, (\\'void\\', \\'__pyx_memoryviewslice___dealloc__(pyobject\\')), (1, (\\'__pyx_pyobject_fromcstring(s)\\', \\'__pyx_pyobject_fromstring((const\\')), (1, (\\'why\\', \\'it\\')), (1, (\\'char*,\\', \\'py_ssize_t,\\')), (1, (\\'1_000_000\\', \\'print(f\"query\\')), (0, (\\'pytuple_new(value_count);\\',))}', '{(1, (\\'__pyx_l21:;\\', \\'/*\\')), (1, (\\'pyobject\\', \\'*__pyx_f_5numpy_get_array_base(pyarrayobject\\')), (2, (\\'}\\', \\'res\\', \\'=\\')), (2, (\\'#else\\', \\'#undef\\', \\'cython_atomics\\')), (1, (\\'__pyx_err(1,\\', \\'782,\\')), (1, (\\'py_visit(obj)\\', \\'#else\\')), (0, (\\'__pyx_clineno\\',)), (1, (\\'#define\\', \\'__pyx_n_u_class_getitem\\')), (2, (\\'src_ndim:\\', \\'#\\', \\'<<<<<<<<<<<<<<\\')), (2, (\\'*\\', \\'raise\\', \\'typeerror,\\')), (2, (\\'print()\\', \\'#\\', \\'actual\\')), (1, (\\'\"c\"\\', \\'#endif\\')), (2, (\\'raise_neg_overflow;\\', \\'}\\', \\'#else\\')), (1, (\\'long,\\', \\'1,\\')), (2, (\\'#define\\', \\'__pyx_assertions_enabled()\\', \\'(__pyx_assertions_enabled_flag)\\')), (2, (\\'(unlikely(!module_found\\', \\'||\\', \\'module_found\\')), (1, (\\'single\\', \\'token\\')), (2, (\\'};\\', \\'#ifdef\\', \\'__cplusplus\\')), (2, (\\'mos_a.ingest([\"alpha\",\\', \\'\"beta\"])\\', \\'hrt_a\\')), (2, (\\'\\\\\\\\in\\', \\'p\\', \\'\\\\\\\\text{\\')), (1, (\\'object_reduce\\', \\'||\\')), (0, (\\'*src,\\',)), (2, (\\'hllset\\', \\'→\\', \\'[sub-hrt]\\')), (1, (\\'so\\', \\'to\\')), (2, (\\'*_format;\\', \\'void\\', \\'(*callback_free_data)(void\\')), (2, (\\'\"deletion\");\\', \\'__pyx_decref_typename(obj_type_name);\\', \\'bad:\\')), (2, (\\'#define\\', \\'__pyx_begin_critical_section\\', \\'py_begin_critical_section\\')), (2, (\\'int\\', \\'__pyx_memoryview_thread_locks_used\\', \\'=\\')), (2, (\"noether\\'s\", \\'theorem\\', \\'states:\\')), (2, (\\'is\\', \\'enabled\\', \\'with\\'))}', '{(2, (\\'__pyx_n_u_test\\', \\'__pyx_string_tab[211]\\', \\'#define\\')), (0, (\\'kept\\',)), (2, (\\'edgesignature,\\', \\'nedgepath,\\', \\'edgelut,\\')), (2, (\\'\"\"\"\\', \\'*\\', \\'intersection:\\')), (2, (\\'stride\\', \\'*\\', \\'step\\')), (2, (\\'__pyx_n_u_struct\\', \\'__pyx_string_tab[209]\\', \\'#define\\')), (1, (\\'=\\', \\'b.real\\')), (2, (\\'pyobject*\\', \\'__pyx_pyobject_formatanddecref(pyobject*\\', \\'s,\\')), (2, (\\'(unlikely(!ob))\\', \\'goto\\', \\'bad;\\')), (2, (\\'cython_fallthrough;\\', \\'case\\', \\'4:\\')), (2, (\\'\\\\\\\\circ\\', \\'f\\', \\'=\\')), (1, (\\'beyond\\', \\'noether,\\')), (1, (\\'__pyx_v_i\\', \\'=\\')), (2, (\\'=\\', \\'ulength\\', \\'-\\')), (1, (\\'#endif\\', \\'reduce_ex\\')), (1, (\\'(*acquisition_count)++;\\', \\'pythread_release_lock(lock);\\')), (1, (\\'kwvalues,\\', \\'argnames,\\')), (0, (\\'__pyx_refnannysetupcontext(\"__getitem__\",\\',)), (1, (\\'\"core/hll_core.pyx\":482\\', \\'*\\')), (1, (\\'#define\\', \\'__pyx_pyobject_getslot(obj,\\')), (0, (\\'__pyx_pygilstate_release(__pyx_gilstate_save);\\',)), (1, (\\'(4\\', \\'workers)\\')), (1, (\\'=\\', \\'x_\\\\\\\\alpha\\')), (1, (\\'__pyx_c_prod_float(z,\\', \\'z);\\')), (2, (\\'(__pyx_fix_up_extension_type_from_spec(&__pyx_type_4core_8hll_core_hllcore_spec,\\', \\'__pyx_mstate->__pyx_ptype_4core_8hll_core_hllcore)\\', \\'<\\')), (1, (\\'__pyx_vtable_array;\\', \\'static\\')), (2, (\\'print(f\"starting\\', \\'optimized\\', \\'parallel\\')), (2, (\\'of\\', \\'new\\', \\'token\\')), (2, (\\'pybuf_any_contiguous\\', \\'*/\\', \\'__pyx_t_1\\')), (2, (\\'\\\\\\\\uparrow\\', \\'x\\', \\'=\\')), (2, (\\'null;\\', \\'#else\\', \\'((pycmethodobject*)op)->mm_class\\')), (2, (\\'__pyx_addtraceback(\"core.hll_core.hllcore.set_registers\",\\', \\'__pyx_clineno,\\', \\'__pyx_lineno,\\')), (2, (\\'the\\', \\'\"triangulation\"\\', \\'idea\\')), (2, (\\'break;\\', \\'}\\', \\'__pyx_t_4\\')), (2, (\\'*\\', \\'nslices\\', \\'=\\')), (0, (\\'\\\\\\\\bigoplus_{i_0\\',)), (0, (\\'(pytuple_set_item(o,\\',)), (2, (\\'cython_compiling_in_limited_api\\', \\'sizeof(pyufuncobject),\\', \\'__pyx_get_struct_alignment_3_2_4(pyufuncobject),\\')), (2, (\\'is\\', \\'not\\', \\'none:\\')), (2, (\\'fail;\\', \\'}\\', \\'else\\')), (0, (\\'co_optimized\\',)), (1, (\\'corresponding\\', \\'permutations\\')), (1, (\\'__pyx_err(0,\\', \\'624,\\')), (2, (\\'__pyx_mstate->__pyx_umethod_pydict_type_items.type\\', \\'=\\', \\'(pyobject*)&pydict_type;\\')), (2, (\\'__pyx_state,\\', \\'1)\\', \\'*/\\')), (0, (\\'__pyx_pytype_frommetaclass(pytypeobject\\',)), (1, (\\'s1.name}\\', \\'✓\")\\')), (1, (\\'should\\', \\'also\\')), (2, (\\'owneddictnext.proto\\', \\'(used\\', \\'by\\')), (2, (\\'slot->pfunc;\\', \\'while\\', \\'(memb\\')), (0, (\\'object_name\\',)), (0, (\\'cryptography.\\',)), (2, (\\'>\\', \\'__pyx_t_double_complex;\\', \\'#else\\')), (2, (\\'merge\\', \\'is:\\', \\'-\\')), (2, (\\'(pycfunction)(void(*)(void))(__pyx_pycfunction_fastcallwithkeywords)__pyx_pw_4core_8hll_core_7hllcore_25cosine_similarity,\\', \\'__pyx_meth_fastcall|meth_keywords,\\', \\'__pyx_doc_4core_8hll_core_7hllcore_24cosine_similarity};\\')), (2, (\\'<<<<<<<<<<<<<<\\', \\'*\\', \\'_err_dim(pyexc_valueerror,\\')), (2, (\\'++field;\\', \\'if\\', \\'(field->type\\')), (2, (\\'only\\', \\'on\\', \\'$(\\')), (0, (\\'verification\\',)), (1, (\\'(for\\', \\'retrieval)\\')), (2, (\\'null;\\', \\'}\\', \\'__pyx_v_info->shape\\')), (2, (\\'an\\', \\'argument\",\\', \\'cyfunc->func_qualname);\\')), (0, (\\'meaning**\\',)), (2, (\\'does\\', \\'it\\', \\'fit\\'))}', '{(2, (\\'__pyx_modulestatelookupdata\\', \\'*old_data\\', \\'=\\')), (2, (\\'py_decref(basei);\\', \\'#endif\\', \\'}\\')), (1, (\\'vs\\', \"sequential\\')\")), (2, (\\'*dict,\\', \\'pyobject\\', \\'*key,\\')), (1, (\\'*\\', \\'not\\')), (2, (\"\\'c\\';\", \\'/*\\', \\'\"view.memoryview\":165\\')), (1, (\\'0x07031100)\\', \\'#endif\\')), (0, (\\'*tp)\\',)), (2, (\\'\"view.memoryview\":1397\\', \\'*\\', \\'refcount_copying(dst,\\')), (1, (\\'pyobject\\', \\'*__pyx_self,\\')), (0, (\\'__pyx_memview_direct)\\',)), (1, (\\'pyobject*\\', \\'__pyx_cyfunction_repr(__pyx_cyfunctionobject\\')), (1, (\\'__pyx_string_tab[179]\\', \\'#define\\')), (1, (\\'/*\\', \\'\"view.memoryview\":198\\')), (1, (\\'pyerr_occurred())\\', \\'goto\\')), (1, (\\'#define\\', \\'__pyx_n_u_m\\')), (1, (\\'__pyx_l1_error)\\', \\'__pyx_decref(__pyx_t_6);\\')), (2, (\\'if\\', \\'(__pyx_setitemontypedict(__pyx_mstate_global->__pyx_ptype_4core_8hll_core_hllcore,\\', \\'__pyx_mstate_global->__pyx_n_u_add_batch,\\')), (2, (\\'(is_complex\\', \\'?\\', \\'16\\')), (2, (\\'__pyx_update_dict_cache(dict,\\', \\'value,\\', \\'cache_var,\\')), (2, (\\'=\\', \\'time.perf_counter()\\', \\'for\\')), (1, (\\'__pyx_string_tab[27]\\', \\'#define\\')), (0, (\\'modbad:\\',)), (2, (\\'prepend_sign);\\', \\'py_decref(padding);\\', \\'padding\\')), (0, (\\'set_item_result\\',)), (2, (\\'itemsize\\', \\'=\\', \\'((pytypeobject\\')), (0, (\\'ax3.axhline(y=num_workers,\\',)), (0, (\\'__pyx_l0:;\\',)), (1, (\\'__pyx_v_suboffset;\\', \\'}\\')), (2, (\\'defined(__gnuc__)\\', \\'&&\\', \\'(__gnuc__\\')), (2, (\\'tests\\', \\'###\\', \\'for\\')), (1, (\\'typesmodule\\', \\'=\\')), (1, (\\'{\\', \\'py_xdecref(data);\\')), (1, (\\'>=\\', \\'0x030c0000)\\')), (2, (\\'pyroaring\\', \\'import\\', \\'bitmap\\')), (1, (\\'py_xdecref(empty_dict);\\', \\'return\\')), (1, (\\'0.0,\\', \"\\'non_zero_registers\\':\")), (2, (\\'needs\\', \\'its\\', \\'own\\')), (0, (\\'has_gil,\\',)), (2, (\\')$\\', \\'iff\\', \\'$(\\')), (2, (\\'return\\', \\'__pyx__callunboundcmethod2(&tmp_cfunc,\\', \\'self,\\')), (2, (\\'=\\', \\'0;\\', \\'uint64_t\\')), (1, (\\'a)`\\', \\'(commutative)\\')), (1, (\\'<\\', \\'0x030b0000\\')), (0, (\\'execution\\',)), (0, (\\'(unlikely(!__pyx_mstate_global->__pyx_tuple[0]))\\',)), (1, (\\'b->arraysize[i])\\', \\'return\\')), (1, (\\'__pyx_st_longlong;\\', \\'static\\')), (1, (\\'pyerr_occurred())))\\', \\'{\\')), (2, (\\'__pyx_v_suboffset\\', \\'=\\', \\'(__pyx_v_view->suboffsets[__pyx_v_dim]);\\')), (2, (\\'\\\\\\\\in\\', \\'\\\\\\\\mathcal{t}(t)}\\', \\'\\\\\\\\theta(p)\\')), (2, (\\'((py_buffer\\', \\'*)__pyx_v_info),\\', \\'((int)__pyx_v_flags));\\')), (0, (\\'unpack\\',)), (1, (\\'module\\', \\'restructuring\\')), (2, (\\'if\\', \\'(unlikely(!value))\\', \\'goto\\')), (2, (\\'2025](https://x.com/karpathy/status/1886192184808149383)\\', \\'##\\', \\'the\\')), (1, (\\'__pyx_v_dst_ndim,\\', \\'__pyx_v_src_ndim);\\')), (2, (\\'null;\\', \\'#if\\', \\'cython_compiling_in_limited_api\\')), (2, (\\'pyobject\\', \\'*__pyx_memoryview_assign_item_from_object(struct\\', \\'__pyx_memoryview_obj\\')), (0, (\\'__pyx_f_4core_8hll_core_murmur_hash64(__pyx_v_data,\\',)), (2, (\\'__pyx_l1_error)\\', \\'__pyx_v_hash_val\\', \\'=\\')), (0, (\\'(object_getstate\\',)), (2, (\\'&\\', \\'likely(len\\', \\'>\\')), (2, (\\'range\"),\\', \\'(pyobject*)null))\\', \\'#else\\')), (0, (\\'*t,\\',)), (1, (\\'0x030c0000)\\', \\'#define\\')), (1, (\\'*__pyx_pf___pyx_memviewenum___reduce_cython__(struct\\', \\'__pyx_memviewenum_obj\\')), (2, (\\'=\\', \\'{__pyx_t_5,\\', \\'__pyx_mstate_global->__pyx_kp_u_contiguous_and_direct};\\')), (2, (\\'py_ssize_t\\', \\'length\\', \\'=\\')), (2, (\"\\'queryresult\\',\", \"\\'columnprofile\\',\", \"\\'tableprofile\\',\")), (1, (\\'same\\', \\'n-token\\')), (2, (\\'is\\', \\'the\\', \\'angular\\')), (0, (\\'enables\\',)), (2, (\\'__pyx_v_token\\', \\'=\\', \\'((pyobject*)values[0]);\\')), (1, (\\'sparse_bytes\\', \\'print(f\"memory\\')), (2, (\\'__pyx_t_2\\', \\'=\\', \\'(__pyx_v_have_step\\')), (1, (\\'*__pyx_v_have_slices\\', \\'=\\')), (2, (\\'7.\\', \\'**hrt\\', \\'stack**\\')), (2, (\\'manifoldos\\', \\'iica\\', \"\\'manifoldos_iica\\',\")), (2, (\\'return\\', \\'(a.real\\', \\'==\\'))}', '{(0, (\\'p->from_object\\',)), (1, (\\'q)\\', \\'+\\')), (0, (\\'maintains**\\',)), (2, (\\'__pyx_l8_try_end;\\', \\'__pyx_l3_error:;\\', \\'/*\\')), (2, (\\'=\\', \\'0;\\', \\'__pyx_xgotref(__pyx_collections_abc_sequence);\\')), (1, (\\'*)(((pytypeobject*)pyexc_valueerror))),\\', \\'__pyx_mstate_global->__pyx_kp_u_buffer_view_does_not_expose_stri,\\')), (2, (\\'not\\', \\'stored\\', \\'-\\')), (2, (\\'(unlikely(!__pyx_t_3))\\', \\'__pyx_err(1,\\', \\'678,\\')), (1, (\\'*pickle_error\\', \\'=\\')), (1, (\\'\\\\\\\\{a,\\', \\'b,\\')), (2, (\\'constants\\', \\'for\\', \\'bias\\')), (1, (\\'__cinit__\"\\', \\'*\\')), (2, (\\'kwds2,\\', \\'values,\\', \\'num_pos_args,\\')), (2, (\\'cython_use_pylong_internals\\', \\'if\\', \\'(unlikely(__pyx_pylong_isneg(x)))\\')), (2, (\\'__pyx_l1_error:;\\', \\'__pyx_xdecref(__pyx_t_1);\\', \\'__pyx_addtraceback(\"view.memoryview.array.__setitem__\",\\')), (1, (\\'complete\\', \\'documentation\\')), (2, (\\'{\\', \\'i\\', \\'+=\\')), (1, (\\'pkey\\', \\'?\\')), (2, (\\'\"view.memoryview\":444\\', \\'*\\', \\'return\\')), (1, (\\'self._shape:\\', \\'*/\\')), (1, (\\'r\\', \\'=\\')), (1, (\\'((pyobject\\', \\'*)__pyx_mstate_global->__pyx_codeobj_tab[4]));\\')), (2, (\\'*dict;\\', \\'int\\', \\'meth_found\\')), (1, (\\'__pyx_t_double_complex\\', \\'__pyx_c_diff_double(__pyx_t_double_complex\\')), (1, (\\'<\\', \\'0x030900b1\\')), (1, (\\'__pyx_get_cython_compiling_in_cpython_freethreading()\\', \\'cython_compiling_in_cpython_freethreading\\')), (1, (\\'it\\', \\'means\\')), (2, (\\'py_long_long)))\\', \\'{\\', \\'__pyx_verify_return_int_exc(uint32_t,\\')), (2, (\\'#endif\\', \\'/*\\', \\'memviewslicecopy\\')), (1, (\\'=\\', \\'tp->tp_as_sequence;\\')), (0, (\\'\"%s\\',)), (1, (\\'==\\', \\'sequential\\')), (1, (\\'/*\\', \\'\"view.memoryview\":1228\\')), (2, (\\'info.readonly\\', \\'=\\', \\'0\\')), (1, (\\'pyobject\\', \\'*(*__pyx_t_14)(pyobject\\')), (2, (\\'###\\', \\'filter\\', \\'(σ)\\')), (2, (\\'*\\', \\'*\\', \\'transpose_memslice(&src)\\')), (1, (\\'mathematical\\', \\'formulation\\')), (1, (\\'i;\\', \\'__pyx_memviewslice\\')), (2, (\\'*)\\', \\'__pyx_memoryview_new(\\', \\'original_obj,\\')), (2, (\\'0\\', \\'#undef\\', \\'cython_fast_thread_state\\')), (2, (\\'0,\\', \\'0,\\', \\'{\\')), (0, (\\'1.0)\\',)), (2, (\\'ndim,\\', \\'order)\\', \\'#\\')), (1, (\"\\'%s\\'\", \\'(%\"\\')), (0, (\\'pylong_fromssize_t(i));\\',)), (0, (\\'_pythreadstate_uncheckedget()\\',)), (2, (\\'\"view.memoryview\":303\\', \\'*\\', \\'cdef\\')), (2, (\\'=\\', \\'pytuple_new(nkw);\\', \\'if\\')), (1, (\\'__pyx_v_encoded\\', \\'=\\')), (1, (\\'*/\\', \\'__pyx_v_4core_8hll_core_alpha_16\\')), (1, (\\'getmoduleglobalname.proto\\', \\'*/\\')), (1, (\\'#\\', \\'time\\')), (1, (\\'__pyx_refnannysetupcontext(\"assign_item_from_object\",\\', \\'0);\\')), (2, (\\'(py_size(x)\\', \\'==\\', \\'0)\\')), (1, (\\'__pyx_string_tab[61]\\', \\'#define\\')), (0, (\\'pytype_slot\\',)), (1, (\\'argnames);\\', \\'return\\')), (2, (\\'__pyx_xgotref(__pyx_t_2);\\', \\'__pyx_xgotref(__pyx_t_3);\\', \\'__pyx_xgotref(__pyx_t_4);\\')), (1, (\\'basicsize)\\', \\'<\\')), (0, (\\'\"core/hll_core.pyx\":184\\',)), (2, (\\'*\\', \\'__pyx_v_new_shape))\\', \\'!=\\')), (2, (\\'(new):\\', \"b\\'hll2\\'\", \\'prefix,\\')), (2, (\\'\"core/hll_core.pyx\":177\\', \\'*\\', \\'#\\')), (1, (\\'1),\\', \\'(__pyx_v_dst_shape\\')), (2, (\\'if\\', \\'(__pyx_fix_up_extension_type_from_spec(&__pyx_type___pyx_memoryview_spec,\\', \\'__pyx_mstate->__pyx_memoryview_type)\\')), (1, (\\'int\\', \\'p_bits\\')), (2, (\\'p\\', \\'\\\\\\\\to\\', \\'\\\\\\\\mathcal{p}(h)\\')), (2, (\\'cython_inline\\', \\'npy_intp\\', \\'__pyx_f_5numpy_9broadcast_5index_index(pyarraymultiiterobject\\')), (2, (\\'>=\\', \\'code_cache->count)\\', \\'||\\')), (1, (\\'pyunicode_fromstring(name);\\', \\'if\\')), (1, (\\'h_1(t),\\', \\'r_2\\')), (2, (\\'return\\', \\'sizeof(__pyx_pad_long)\\', \\'-\\')), (2, (\\'(unlikely(!values[i]))\\', \\'{\\', \\'__pyx_raiseargtupleinvalid(\"compute_reg_zeros_batch\",\\')), (1, (\\'content\\', \\'addressable)\\')), (1, (\\'pyobject*\\', \\'__pyx_pytuple_fromarray(pyobject\\')), (1, (\\'new_data->allocated)\\', \\'{\\')), (1, (\\')$\\', \\'now\\')), (1, (\\'/*\\', \\'\"view.memoryview\":651\\')), (1, (\\'fixed\\', \\'$(\\')), (2, (\\'if\\', \\'(get_item_ref_result\\', \\'==\\'))}', '{(0, (\\'__pyx_pyobject_callmethod0(pyobject*\\',)), (2, (\\'8,\\', \\'__pyx_l1_error);\\', \\'__pyx_t_4\\')), (2, (\\'*__pyx_v_src)\\', \\'{\\', \\'__pyx_memviewslice\\')), (2, (\\'=\\', \\'pyexception_gettraceback(local_value);\\', \\'}\\')), (2, (\\'__pyx_v_i;\\', \\'pyobject\\', \\'**__pyx_v_p;\\')), (2, (\\'-\\', \\'__pyx_v_idx);\\', \\'/*\\')), (1, (\\'time.perf_counter()\\', \\'uuid_tokens\\')), (1, (\\'__pyx_l1_error;\\', \\'__pyx_l6_except_return:;\\')), (2, (\\'|d(t)|\\', \\'```\\', \\'this\\')), (1, (\\'\\\\\\\\to\\', \\'\\\\\\\\mathbf{lattice}\\')), (2, (\\'1))\\', \\'{\\', \\'__pyx_cyfunction_raise_type_error(\\')), (1, (\\'__pyx_pytype_getsubslot(py_type(obj),\\', \\'sub,\\')), (1, (\\'v);\\', \\'if\\')), (0, (\\'(dictptr\\',)), (1, (\\'goto\\', \\'__pyx_l11;\\')), (2, (\\'then\\', \\'set\\', \\'the\\')), (2, (\\'(__pyx_setitemontypedict(__pyx_mstate_global->__pyx_ptype_4core_8hll_core_hllcore,\\', \\'__pyx_mstate_global->__pyx_n_u_get_registers,\\', \\'__pyx_t_4)\\')), (2, (\\'<\\', \\'1}\")\\', \\'def\\')), (2, (\\'base\\', \\'=\\', \\'pyarray_base(arr)\\')), (2, (\\'(size_t)\\', \\'(name\\', \\'-\\')), (2, (\\'__pyx_pf_15view_dot_memoryview_10memoryview_6nbytes___get__(((struct\\', \\'__pyx_memoryview_obj\\', \\'*)__pyx_v_self));\\')), (1, (\\'pyobject\\', \\'*))__pyx_memoryview_setitem_slice_assign_scalar;\\')), (0, (\\'__pyx_pyobject_fastcall_fallback(pyobject\\',)), (1, (\\'char\\', \\'*__pyx_typename;\\')), (1, (\\'ndim,\\', \\'bint\\')), (1, (\\'msg\\', \\'%\\')), (1, (\\'pyobject*\\', \\'result;\\')), (2, (\\'void\\', \\'*result_udata;\\', \\'if\\')), (0, (\\'__pyx_v_negative_step\\',)), (1, (\\'mvs,\\', \\'char\\')), (2, (\\'__pyx_v_self->dtype_is_object);\\', \\'}\\', \\'/*\\')), (1, (\\'/*\\', \\'\"view.memoryview\":1119\\')), (2, (\\'0:\\', \\'*\\', \\'non_zero\\')), (2, (\\'+\\', \\'a.imag\\', \\'*\\')), (1, (\\'==\\', \\'py_none))))\\')), (2, (\\'int\\', \\'*write_to)\\', \\'{\\')), (1, (\\'#\\', \\'cross-structure\\')), (2, (\\'=\\', \\'{__pyx_t_5,\\', \\'__pyx_mstate_global->__pyx_n_u_ascii};\\')), (0, (\\'(target_type)\\',)), (2, (\\'-1,\\', \\'-1):\\', \\'#\\'))}']\n",
      "  [7550]: ['{(1, (\\'category\\', \\'$(\\\\\\\\mathbf{data})$\\')), (1, (\\'i,\\', \\'c\\')), (2, (\\'fragment)\":1\\', \\'*\\', \\'def\\')), (2, (\\'id(self))\\', \\'*/\\', \\'/*\\')), (1, (\\'((void)u,\\', \\'(0))\\')), (0, (\\'__pyx_mstate_global->__pyx_n_u_intersect_cardinality,\\',)), (2, (\\'\"\"\"\\', \\'set\\', \\'registers\\')), (2, (\\'*/\\', \\'#define\\', \\'__pyx_pyobject_delslice(obj,\\')), (2, (\\'{\\', \\'case\\', \\'2:\\')), (0, (\\'[\"dog\",\\',)), (2, (\\'evolution:\\', \\'```math\\', \\'\\\\\\\\mathcal{t}(t+1)\\')), (2, (\\'__pyx_l1_error)\\', \\'__pyx_gotref(__pyx_t_1);\\', \\'__pyx_incref(__pyx_v__dict);\\')), (1, (\\'an\\', \\'algebra\\')), (0, (\\'defined(ms_windows)\\',)), (0, (\\'behave\\',)), (1, (\\'error:\\', \\'py_decref(imported_module);\\')), (1, (\\'7);\\', \\'if\\')), (1, (\\'(__pyx_vectorcallbuilder_addarg(__pyx_mstate_global->__pyx_n_u_stacklevel,\\', \\'__pyx_mstate_global->__pyx_int_3,\\')), (1, (\\'(pycfunction_check(func))\\', \\'{\\')), (2, (\\'hllset()\\', \\'hll\\', \\'=\\')), (0, (\\'item)[0]\\',)), (2, (\\'*__pyx_v_self,\\', \\'pyobject\\', \\'*__pyx_v_obj,\\')), (1, (\\'(struct_alignment)\\', \\'ctx->struct_alignment\\')), (1, (\\'pyobject\\', \\'*__pyx_pw_4core_8hll_core_7hllcore_37copy(pyobject\\')), (2, (\\'empty\\', \\'sparsehrt\\', \\'===\")\\')), (1, (\\'*/\\', \\'((py_buffer\\')), (1, (\\'&writer,\\', \\'obj,\\')), (1, (\\'__pyx_imported_names[]\\', \\'=\\')), (1, (\\'=\\', \"\\'x\\';\")), (2, (\\'*lnos)\\', \\'{\\', \\'pyobject\\')), (2, (\\'end1);\\', \\'}\\', \\'/*\\')), (0, (\\'4;\\',)), (2, (\\'tuple\\', \\'pydatatype_shape(dtype\\', \\'d):\\')), (2, (\\'=\\', \\'_import_array();\\', \\'if\\')), (2, (\\'int\\', \\'(*to_dtype_func)(char\\', \\'*,\\')), (0, (\\'__pyx_incref(__pyx__function);\\',))}', '{(1, (\\'(long\\', \\'double)(1.0)\\')), (2, (\\'1);\\', \\'result\\', \\'=\\')), (2, (\\'if\\', \\'slice_is_contig(src,\\', \"\\'c\\',\")), (1, (\\'n)\\', \\'pyobject_hasattrwitherror(o,\\')), (2, (\\'`from_batch`,\\', \\'`to_bytes`\\', \\'→\\')), (0, (\\'__pyx_decref(__pyx_v___pyx_result->name);\\',)), (2, (\\'__pyx_xdecref(__pyx_t_2);\\', \\'__pyx_xdecref(__pyx_t_6);\\', \\'__pyx_addtraceback(\"view.memoryview.memoryview.suboffsets.__get__\",\\')), (2, (\\'bint\\', \\'dtype_is_object=false):\\', \\'#\\')), (2, (\\'karoubi\\', \\'envelope,\\', \\'čech\\')), (2, (\\'src_shape[0]\\', \\'*\\', \\'cdef\\')), (2, (\\'__pyx_array___setitem__(pyobject\\', \\'*__pyx_v_self,\\', \\'pyobject\\')), (2, (\\'=\\', \\'values[3];\\', \\'if\\')), (2, (\\'*__pyx_pf_4core_8hll_core_7hllcore_34get_compression_stats(struct\\', \\'__pyx_obj_4core_8hll_core_hllcore\\', \\'*__pyx_v_self);\\')), (2, (\\'py_ssize_t\\', \\'q\\', \\'=\\')), (2, (\\'(num_kwargs\\', \\'>\\', \\'extracted)\\')), (1, (\\'#define\\', \\'cython_unpack_methods\\')), (2, (\\'char\\', \\'*get_item_pointer(memoryview\\', \\'self,\\')), (2, (\\'*defaults;\\', \\'int\\', \\'flags;\\'))}']\n",
      "  [10495]: ['{(2, (\\'return\\', \\'tuple([stride\\', \\'for\\')), (2, (\\'unsigned\\', \\'int\\', \\'argcount\\')), (2, (\\'8!\\', \\'\"\"\"\\', \\'worker_id,\\')), (0, (\\'a->is_unsigned\\',)), (1, (\"\\'filter_threshold\\',\", \"\\'filter_predicate\\',\")), (2, (\\'1;\\', \\'#if\\', \\'cython_unpack_methods\\')), (1, (\\'}\\', \\'tmp_value\\')), (0, (\\'pyobject_callmethodobjargs((pyobject\\',)), (2, (\"\\'default_tau\\',\", \"\\'default_rho\\',\", \"\\'default_n_token_sizes\\',\")), (1, (\\'by\\', \\'cordinaltopyunicode)\\')), (2, (\\'shared_seed,\\', \\'hash_func,\\', \\'default_tau,\\')), (2, (\\'q\\', \\'\\\\\\\\quad\\', \\'\\\\\\\\text{iff}\\')), (1, (\\'__pyx_argtypetest(obj,\\', \\'type,\\')), (2, (\\'<=\\', \\'start\\', \\'<\\')), (2, (\\'val\\', \\'|=\\', \\'((char)\\'))}']\n"
     ]
    }
   ],
   "source": [
    "# ═══════════════════════════════════════════════════════════════\n",
    "# Interactive Querying with ask() - Simplified Interface\n",
    "# ═══════════════════════════════════════════════════════════════\n",
    "\n",
    "# Use the context we have (either fresh or with existing LUT)\n",
    "query_ctx = ctx_with_existing_lut\n",
    "\n",
    "# Populate with existing state if available\n",
    "try:\n",
    "    query_ctx.hrt = current_hrt\n",
    "    query_ctx.W = current_W\n",
    "    query_ctx.layer_hllsets = prod_layers\n",
    "    print(\"Using existing HRT/W state from notebook\")\n",
    "except NameError:\n",
    "    print(\"Using fresh state (no prior processing)\")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"INTERACTIVE QUERY via ask()\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Single-line query!\n",
    "response, disamb_results = ask(\n",
    "    \"def hello_world(): print('hello')\",\n",
    "    query_ctx,\n",
    "    top_k=5,\n",
    "    learn=True  # Feedback loop enabled\n",
    ")\n",
    "\n",
    "print(\"\\nResponse:\")\n",
    "print(response)\n",
    "print()\n",
    "print(f\"Disambiguation results: {len(disamb_results)} items\")\n",
    "print(f\"Commits after query: {len(query_ctx.store)}\")\n",
    "\n",
    "# Resolve tokens from disambiguation\n",
    "if disamb_results:\n",
    "    resolved = resolve_disambiguation(disamb_results, query_ctx.lut)\n",
    "    print(\"\\nResolved tokens (sample):\")\n",
    "    for idx, tokens in list(resolved.items())[:5]:\n",
    "        print(f\"  [{idx}]: {tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50412742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "SEQUENTIAL QUERIES - MANIFOLD LEARNS\n",
      "============================================================\n",
      "\n",
      "Query: 'import numpy as np'\n",
      "  Edges: 194389 → 194428 (+39)\n",
      "  Results: 3 disambiguation items\n",
      "\n",
      "Query: 'class FractalManifold:'\n",
      "  Edges: 194428 → 194473 (+45)\n",
      "  Results: 3 disambiguation items\n",
      "\n",
      "Query: 'def process_file(path):'\n",
      "  Edges: 194473 → 194490 (+17)\n",
      "  Results: 3 disambiguation items\n",
      "\n",
      "Query: 'HLLSet.union(other)'\n",
      "  Edges: 194490 → 194504 (+14)\n",
      "  Results: 3 disambiguation items\n",
      "\n",
      "Query: 'cascading_disambiguate(query_indices)'\n",
      "  Edges: 194504 → 194517 (+13)\n",
      "  Results: 2 disambiguation items\n",
      "\n",
      "============================================================\n",
      "COMMIT HISTORY (12 commits)\n",
      "============================================================\n",
      "  [15:34:19] p_prompt: prompt_3\n",
      "  [15:34:23] a_response: response_3\n",
      "  [15:34:26] p_prompt: prompt_4\n",
      "  [15:34:30] a_response: response_4\n",
      "  [15:34:33] p_prompt: prompt_5\n",
      "  [15:34:37] a_response: response_5\n",
      "  [15:34:39] p_prompt: prompt_6\n",
      "  [15:34:43] a_response: response_6\n"
     ]
    }
   ],
   "source": [
    "# ═══════════════════════════════════════════════════════════════\n",
    "# Multiple Queries - Manifold Learns from Each\n",
    "# ═══════════════════════════════════════════════════════════════\n",
    "\n",
    "test_queries = [\n",
    "    \"import numpy as np\",\n",
    "    \"class FractalManifold:\",\n",
    "    \"def process_file(path):\",\n",
    "    \"HLLSet.union(other)\",\n",
    "    \"cascading_disambiguate(query_indices)\",\n",
    "]\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"SEQUENTIAL QUERIES - MANIFOLD LEARNS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for q in test_queries:\n",
    "    edges_before = query_ctx.hrt.nnz\n",
    "    \n",
    "    response, results = ask(q, query_ctx, top_k=3, learn=True)\n",
    "    \n",
    "    edges_after = query_ctx.hrt.nnz\n",
    "    \n",
    "    print(f\"\\nQuery: '{q}'\")\n",
    "    print(f\"  Edges: {edges_before} → {edges_after} (+{edges_after - edges_before})\")\n",
    "    print(f\"  Results: {len(results)} disambiguation items\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(f\"COMMIT HISTORY ({len(query_ctx.store)} commits)\")\n",
    "print(\"=\" * 60)\n",
    "from datetime import datetime\n",
    "for commit in query_ctx.store.log(limit=8):\n",
    "    ts = datetime.fromtimestamp(commit.timestamp).strftime(\"%H:%M:%S\")\n",
    "    source_preview = commit.source[:35] + \"...\" if len(commit.source) > 35 else commit.source\n",
    "    print(f\"  [{ts}] {commit.perceptron}: {source_preview}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d90e32c",
   "metadata": {},
   "source": [
    "## Summary: Consolidated Manifold Algebra\n",
    "\n",
    "All processing logic is now in `core/manifold_algebra.py`:\n",
    "\n",
    "```python\n",
    "# Before (notebook code):\n",
    "new_hrt, new_W, commit = prompt_perceptron.process_prompt(...)\n",
    "response, final_hrt, final_W = response_actuator.act(...)\n",
    "# ... 50+ lines of wiring code\n",
    "\n",
    "# After (using module):\n",
    "from core.manifold_algebra import ask, create_query_context\n",
    "\n",
    "ctx = create_query_context(config)\n",
    "response, results = ask(\"your query\", ctx)\n",
    "```\n",
    "\n",
    "### Key Classes Added to `manifold_algebra.py`:\n",
    "\n",
    "| Class | Purpose |\n",
    "|-------|---------|\n",
    "| `CommitStore` | Track processing history with rollback |\n",
    "| `Commit` | Single timestamped processing step |\n",
    "| `Perceptron` | Base class for sensing (file/prompt → HLLSet) |\n",
    "| `PromptPerceptron` | Process user queries |\n",
    "| `Actuator` | Base class for actions |\n",
    "| `ResponseActuator` | Generate response + feedback loop |\n",
    "| `QueryContext` | Mutable state for queries |\n",
    "| `ask()` | One-line interactive query |\n",
    "| `create_query_context()` | Initialize fresh context |\n",
    "\n",
    "### Benefits:\n",
    "\n",
    "1. **Cleaner notebook code** - Just import and use\n",
    "2. **Reusable across notebooks** - Same module works everywhere\n",
    "3. **Testable** - Module can be unit tested\n",
    "4. **Documented** - Docstrings in one place\n",
    "5. **Evolvable** - Improve tokenization without changing notebooks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fractal_manifold",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
