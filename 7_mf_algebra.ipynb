{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9d34707",
   "metadata": {},
   "source": [
    "# Manifold Algebra + Manifold OS Integration\n",
    "\n",
    "## Goals\n",
    "\n",
    "1. **Sync mf_algebra and mf_os**: Create a unified architecture where:\n",
    "   - `ManifoldOS` is the orchestration layer (git-like operations, persistence)\n",
    "   - `mf_algebra` provides the algebraic operations on HRT structures\n",
    "\n",
    "2. **DuckDB Backend**: Use DuckDB as the persistent store for:\n",
    "   - HRT state (AM, Lattice)\n",
    "   - LUT (Lookup Table)\n",
    "   - Commits (versioning)\n",
    "\n",
    "3. **Simple .txt Input**: Work with normal text documents\n",
    "\n",
    "## Architecture\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────────────────┐\n",
    "│                          ManifoldOS (mf_os)                             │\n",
    "│   - Git-like operations: commit, push, pull, rollback                   │\n",
    "│   - Orchestrates processing pipeline                                    │\n",
    "│   - Manages DuckDB persistence                                          │\n",
    "├─────────────────────────────────────────────────────────────────────────┤\n",
    "│                       ManifoldAlgebra (mf_algebra)                      │\n",
    "│   - SparseHRT3D (AM + Lattice + LUT)                                    │\n",
    "│   - Unified Processing Pipeline                                         │\n",
    "│   - Perceptrons & Actuators                                             │\n",
    "│   - QueryContext & ask()                                                │\n",
    "├─────────────────────────────────────────────────────────────────────────┤\n",
    "│                        DuckDB Store Layer                               │\n",
    "│   - Tables: commits, blobs, lut_entries, refs                           │\n",
    "│   - Content-addressed storage                                           │\n",
    "│   - Efficient querying                                                  │\n",
    "└─────────────────────────────────────────────────────────────────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c3eb7d",
   "metadata": {},
   "source": [
    "## 1. Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4607668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /home/alexmy/SGS/SGS_lib/fractal_manifold/fractal_manifold\n",
      "DuckDB version: 1.4.4\n",
      "Core modules reloaded\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import importlib\n",
    "\n",
    "# Ensure core is importable\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n",
    "\n",
    "# Check DuckDB availability\n",
    "try:\n",
    "    import duckdb\n",
    "    print(f\"DuckDB version: {duckdb.__version__}\")\n",
    "except ImportError:\n",
    "    print(\"Installing DuckDB...\")\n",
    "    !pip install duckdb\n",
    "    import duckdb\n",
    "    print(f\"DuckDB version: {duckdb.__version__}\")\n",
    "\n",
    "# Reload core modules to pick up any changes\n",
    "import core.mf_algebra\n",
    "import core.mf_os\n",
    "importlib.reload(core.mf_algebra)\n",
    "importlib.reload(core.mf_os)\n",
    "print(\"Core modules reloaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ba727c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Core modules imported successfully\n",
      "Default hash config: HashConfig(hash_type=<HashType.MURMUR3: 'murmur3'>, p_bits=10, seed=42, h_bits=64)\n",
      "Register dtype: <class 'numpy.uint32'>\n"
     ]
    }
   ],
   "source": [
    "# Import core modules\n",
    "from core.sparse_hrt_3d import (\n",
    "    Sparse3DConfig,\n",
    "    SparseHRT3D,\n",
    "    SparseAM3D,\n",
    "    SparseLattice3D,\n",
    "    Edge3D,\n",
    ")\n",
    "from core.mf_algebra import (\n",
    "    # LUT\n",
    "    LookupTable,\n",
    "    START, END,\n",
    "    \n",
    "    # Processing pipeline\n",
    "    unified_process,\n",
    "    build_w_from_am,\n",
    "    tokenize,\n",
    "    generate_ntokens,\n",
    "    \n",
    "    # Query interface\n",
    "    QueryContext,\n",
    "    create_query_context,\n",
    "    ask,\n",
    "    \n",
    "    # Perceptrons & Actuators\n",
    "    Perceptron,\n",
    "    PromptPerceptron,\n",
    "    ResponseActuator,\n",
    "    \n",
    "    # Commit store\n",
    "    Commit,\n",
    "    CommitStore,\n",
    ")\n",
    "from core.hllset import HLLSet, DEFAULT_HASH_CONFIG, REGISTER_DTYPE\n",
    "from core.duckdb_store import DuckDBStore\n",
    "from core.constants import P_BITS\n",
    "\n",
    "print(\"Core modules imported successfully\")\n",
    "print(f\"Default hash config: {DEFAULT_HASH_CONFIG}\")\n",
    "print(f\"Register dtype: {REGISTER_DTYPE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e15dce",
   "metadata": {},
   "source": [
    "## 2. Test DuckDB Store (from core.duckdb_store)\n",
    "\n",
    "The `DuckDBStore` is now imported from `core/duckdb_store.py`. Let's test it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3e2ae66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DuckDB store initialized: {'commits': 0, 'blobs': 0, 'lut_entries': 0, 'refs': 0, 'blob_types': {}, 'db_path': ':memory:'}\n",
      "\n",
      "DuckDBStore methods:\n",
      "  - checkout\n",
      "  - close\n",
      "  - commit\n",
      "  - conn\n",
      "  - create_branch\n",
      "  - db_path\n",
      "  - delete_branch\n",
      "  - delete_ref\n",
      "  - export_commits\n",
      "  - export_lut\n",
      "  - fetch_blob\n",
      "  - fetch_hrt\n",
      "  - fetch_layer_hllsets\n",
      "  - fetch_w\n",
      "  - find_commits_by_source\n",
      "  - find_common_ancestor\n",
      "  - get_branch_commit\n",
      "  - get_commit\n",
      "  - get_commits_since\n",
      "  - get_current_branch\n",
      "  - get_head\n",
      "  - get_ntoken_index\n",
      "  - get_ntokens_at_index\n",
      "  - get_ref\n",
      "  - has_blob\n",
      "  - has_commit\n",
      "  - import_commits\n",
      "  - import_lut\n",
      "  - list_branches\n",
      "  - list_refs\n",
      "  - load_lut_to_memory\n",
      "  - log\n",
      "  - lut_count\n",
      "  - merge_branch\n",
      "  - merge_hrts\n",
      "  - merge_layer_hllsets\n",
      "  - merge_w_matrices\n",
      "  - set_ref\n",
      "  - stats\n",
      "  - store_blob\n",
      "  - store_hrt\n",
      "  - store_layer_hllsets\n",
      "  - store_lut_entry\n",
      "  - store_w\n",
      "  - switch_branch\n",
      "  - sync_from\n",
      "  - sync_lut_from_memory\n",
      "  - sync_to\n",
      "  - vacuum\n"
     ]
    }
   ],
   "source": [
    "# Test DuckDB store (imported from core.duckdb_store)\n",
    "store = DuckDBStore(\":memory:\")\n",
    "print(f\"DuckDB store initialized: {store.stats()}\")\n",
    "\n",
    "# Show available methods\n",
    "print(\"\\nDuckDBStore methods:\")\n",
    "for method in dir(store):\n",
    "    if not method.startswith('_'):\n",
    "        print(f\"  - {method}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d81b72",
   "metadata": {},
   "source": [
    "## 3. Text File Perceptron\n",
    "\n",
    "A perceptron for processing plain .txt files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98729901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TextFilePerceptron initialized: p_text\n",
      "Extensions: ['.txt']\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from typing import Iterator\n",
    "\n",
    "\n",
    "class TextFilePerceptron(Perceptron):\n",
    "    \"\"\"\n",
    "    Perceptron for plain text files (.txt).\n",
    "    \n",
    "    Simple and effective for normal documents.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config: Sparse3DConfig):\n",
    "        super().__init__(\"p_text\", [\".txt\"], config)\n",
    "    \n",
    "    def extract_text(self, path: Path) -> str:\n",
    "        \"\"\"Read text file content.\"\"\"\n",
    "        try:\n",
    "            return path.read_text(encoding='utf-8')\n",
    "        except UnicodeDecodeError:\n",
    "            # Fallback to latin-1 if UTF-8 fails\n",
    "            return path.read_text(encoding='latin-1')\n",
    "\n",
    "\n",
    "# Test\n",
    "config = Sparse3DConfig(p_bits=P_BITS, h_bits=32, max_n=3)\n",
    "text_perceptron = TextFilePerceptron(config)\n",
    "print(f\"TextFilePerceptron initialized: {text_perceptron.name}\")\n",
    "print(f\"Extensions: {text_perceptron.extensions}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40a2ecc",
   "metadata": {},
   "source": [
    "## 4. ManifoldOS with DuckDB Backend\n",
    "\n",
    "The orchestration layer that combines mf_algebra with DuckDB persistence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea687c91",
   "metadata": {},
   "source": [
    "## 5. Test with Sample Text\n",
    "\n",
    "Let's test the integrated system with some sample text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9ca4eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingested sample 1: commit 9bf2a9e0\n",
      "Ingested sample 2: commit 931d3cdf\n",
      "Ingested sample 3: commit fc90c87d\n",
      "\n",
      "Status after ingestion: {'step': 3, 'edges': 215, 'lut_entries': 206, 'layer_hllsets': {'L0': 132, 'L1': 131, 'L2': 134, 'START': 2}, 'head_commit': 'fc90c87d6052849684e8b56c5d6465e0a95952e6', 'current_branch': None, 'store_stats': {'commits': 3, 'blobs': 9, 'lut_entries': 206, 'refs': 1, 'blob_types': {'w_matrix': {'count': 3, 'bytes': 7957}, 'hrt': {'count': 3, 'bytes': 9156}, 'layer_hllsets': {'count': 3, 'bytes': 49494}}, 'db_path': ':memory:'}}\n"
     ]
    }
   ],
   "source": [
    "# Sample text for testing\n",
    "sample_texts = [\n",
    "    \"\"\"\n",
    "    The quick brown fox jumps over the lazy dog.\n",
    "    This sentence contains every letter of the alphabet.\n",
    "    It is often used for testing fonts and keyboards.\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "    Machine learning is a subset of artificial intelligence.\n",
    "    It enables computers to learn from data without explicit programming.\n",
    "    Deep learning uses neural networks with many layers.\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "    The fractal manifold represents knowledge as a geometric structure.\n",
    "    HyperLogLog sets provide efficient cardinality estimation.\n",
    "    The adjacency matrix captures relationships between concepts.\n",
    "    \"\"\"\n",
    "]\n",
    "\n",
    "# Ingest all samples\n",
    "for i, text in enumerate(sample_texts):\n",
    "    commit_id = mos.ingest(text, f\"sample_{i+1}\")\n",
    "    print(f\"Ingested sample {i+1}: commit {commit_id[:8]}\")\n",
    "\n",
    "print(f\"\\nStatus after ingestion: {mos.status()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e250c4b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Query: What is machine learning?\n",
      "Results (5 found):\n",
      "  [  6.7] ('the',)\n",
      "  [  3.0] ('learning', 'is', 'a')\n",
      "  [  2.0] ('layers.',)\n",
      "  [  2.0] ('concepts.',)\n",
      "  [  2.0] ('keyboards.',)\n",
      "\n",
      "============================================================\n",
      "Query: Tell me about the fox\n",
      "Results (5 found):\n",
      "  [  2.9] ('machine',)\n",
      "  [  2.0] ('layers.',)\n",
      "  [  2.0] ('learning?',)\n",
      "  [  2.0] ('concepts.',)\n",
      "  [  2.0] ('keyboards.',)\n",
      "\n",
      "============================================================\n",
      "Query: fractal geometry\n",
      "Results (5 found):\n",
      "  [  8.8] ('the',)\n",
      "  [  3.1] ('machine',)\n",
      "  [  3.0] ('fox',)\n",
      "  [  2.0] ('layers.',)\n",
      "  [  2.0] ('learning?',)\n"
     ]
    }
   ],
   "source": [
    "# Test queries\n",
    "queries = [\n",
    "    \"What is machine learning?\",\n",
    "    \"Tell me about the fox\",\n",
    "    \"fractal geometry\"\n",
    "]\n",
    "\n",
    "for q in queries:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Query: {q}\")\n",
    "    result = mos.query(q, top_k=5, learn=True)\n",
    "    print(f\"Results ({len(result['results'])} found):\")\n",
    "    for r in result['results']:\n",
    "        print(f\"  [{r['score']:5.1f}] {r['tokens']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e03a358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commit History:\n",
      "------------------------------------------------------------\n",
      "ac845a1e | 13:58:12 | step   6 | query:fractal geometry\n",
      "414ee230 | 13:58:12 | step   5 | query:Tell me about the fox\n",
      "a282c21b | 13:58:11 | step   4 | query:What is machine learning?\n",
      "fc90c87d | 13:58:11 | step   3 | sample_3\n",
      "931d3cdf | 13:58:11 | step   2 | sample_2\n",
      "9bf2a9e0 | 13:58:11 | step   1 | sample_1\n"
     ]
    }
   ],
   "source": [
    "# View commit history\n",
    "print(\"Commit History:\")\n",
    "print(\"-\" * 60)\n",
    "for commit in mos.log(10):\n",
    "    from datetime import datetime\n",
    "    ts = datetime.fromtimestamp(commit['timestamp']).strftime('%H:%M:%S')\n",
    "    print(f\"{commit['commit_id'][:8]} | {ts} | step {commit['step_number']:3d} | {commit['source'][:40]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "836885f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Store Statistics:\n",
      "  commits: 6\n",
      "  blobs: 15\n",
      "  lut_entries: 225\n",
      "  refs: 1\n",
      "  blob_types: {'hrt': {'count': 6, 'bytes': 23550}, 'w_matrix': {'count': 6, 'bytes': 20468}, 'layer_hllsets': {'count': 3, 'bytes': 49494}}\n",
      "  db_path: :memory:\n"
     ]
    }
   ],
   "source": [
    "# Store stats\n",
    "print(f\"\\nStore Statistics:\")\n",
    "stats = mos.store.stats()\n",
    "for k, v in stats.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab64d9d",
   "metadata": {},
   "source": [
    "## 6. File-Based Persistence Test\n",
    "\n",
    "Test with a file-based DuckDB database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12dfb3e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating persistent store at: /home/alexmy/SGS/SGS_lib/fractal_manifold/fractal_manifold/data/manifold.duckdb\n",
      "Status: {'step': 2, 'edges': 152, 'lut_entries': 146, 'layer_hllsets': {'L0': 100, 'L1': 93, 'L2': 96, 'START': 2}, 'head_commit': 'd26e14bbac04fb9e4dfee0f3a70b7f2d1bd284a3', 'current_branch': None, 'store_stats': {'commits': 2, 'blobs': 6, 'lut_entries': 146, 'refs': 1, 'blob_types': {'layer_hllsets': {'count': 2, 'bytes': 32996}, 'w_matrix': {'count': 2, 'bytes': 4118}, 'hrt': {'count': 2, 'bytes': 4758}}, 'db_path': '/home/alexmy/SGS/SGS_lib/fractal_manifold/fractal_manifold/data/manifold.duckdb'}}\n",
      "\n",
      "Closed store. HEAD was: d26e14bb\n"
     ]
    }
   ],
   "source": [
    "# Create a file-based store\n",
    "db_file = PROJECT_ROOT / \"data\" / \"manifold.duckdb\"\n",
    "db_file.parent.mkdir(exist_ok=True)\n",
    "\n",
    "# Remove if exists (fresh start)\n",
    "if db_file.exists():\n",
    "    db_file.unlink()\n",
    "\n",
    "print(f\"Creating persistent store at: {db_file}\")\n",
    "\n",
    "# Create ManifoldOS with file store\n",
    "mos_persistent = ManifoldOS(str(db_file))\n",
    "\n",
    "# Ingest sample data\n",
    "mos_persistent.ingest(sample_texts[0], \"sample_1\")\n",
    "mos_persistent.ingest(sample_texts[1], \"sample_2\")\n",
    "\n",
    "print(f\"Status: {mos_persistent.status()}\")\n",
    "\n",
    "# Close and reopen to test persistence\n",
    "head_before = mos_persistent._head_commit_id\n",
    "mos_persistent.close()\n",
    "print(f\"\\nClosed store. HEAD was: {head_before[:8]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "962d8e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reopened store. Status: {'step': 2, 'edges': 152, 'lut_entries': 146, 'layer_hllsets': {'L0': 100, 'L1': 93, 'L2': 96, 'START': 2}, 'head_commit': None, 'current_branch': None, 'store_stats': {'commits': 2, 'blobs': 6, 'lut_entries': 146, 'refs': 1, 'blob_types': {'hrt': {'count': 2, 'bytes': 4758}, 'w_matrix': {'count': 2, 'bytes': 4118}, 'layer_hllsets': {'count': 2, 'bytes': 32996}}, 'db_path': '/home/alexmy/SGS/SGS_lib/fractal_manifold/fractal_manifold/data/manifold.duckdb'}}\n",
      "\n",
      "LUT entries loaded: 146\n",
      "\n",
      "Query results: [{'index': 22081, 'tokens': ('the',), 'score': 4.666666746139526}, {'index': 1104, 'tokens': ('layers.',), 'score': 2.0}, {'index': 23230, 'tokens': ('keyboards.',), 'score': 2.0}]\n"
     ]
    }
   ],
   "source": [
    "# Reopen and verify state\n",
    "mos_reload = ManifoldOS(str(db_file))\n",
    "print(f\"Reopened store. Status: {mos_reload.status()}\")\n",
    "\n",
    "# Verify LUT was persisted\n",
    "print(f\"\\nLUT entries loaded: {len(mos_reload.lut.ntoken_to_index)}\")\n",
    "\n",
    "# Query to verify data integrity\n",
    "result = mos_reload.query(\"machine learning\", top_k=3, learn=False)\n",
    "print(f\"\\nQuery results: {result['results']}\")\n",
    "\n",
    "mos_reload.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961ed615",
   "metadata": {},
   "source": [
    "## 7. Summary\n",
    "\n",
    "We've successfully synced `mf_algebra` and `mf_os` with the following architecture:\n",
    "\n",
    "1. **DuckDBStore**: Persistent storage backend\n",
    "   - Content-addressed blob storage (deduplicated)\n",
    "   - Commit history with parent tracking\n",
    "   - LUT persistence\n",
    "   - Ref management (HEAD, branches)\n",
    "\n",
    "2. **ManifoldOS**: Orchestration layer\n",
    "   - Uses `unified_process` from `mf_algebra`\n",
    "   - Git-like versioning (commit, checkout, rollback)\n",
    "   - Query interface with co-adaptive learning\n",
    "   - File ingestion via Perceptrons\n",
    "\n",
    "3. **TextFilePerceptron**: Simple .txt file processing\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- [ ] Move DuckDBStore to `core/duckdb_store.py`\n",
    "- [ ] Update `manifold_os_iica.py` to use new architecture (or replace)\n",
    "- [ ] Add branch operations\n",
    "- [ ] Add merge operations for parallel ingestion\n",
    "- [ ] Performance optimization for large documents"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fractal_manifold",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
