{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e1499db",
   "metadata": {},
   "source": [
    "# Playground for testing random ideas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef923091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Non-Zero Registers vs Cardinality Analysis\n",
      "============================================================\n",
      "\n",
      "HLLSet configuration:\n",
      "  p_bits = 10\n",
      "  m = 2^10 = 1024 registers\n",
      "\n",
      "n (elements)    E[filled]    Actual     Error %   \n",
      "--------------------------------------------------\n",
      "10              10.0         10         0.44      \n",
      "50              48.8         49         0.36      \n",
      "100             95.3         94         1.38      \n",
      "500             395.7        400        1.08      \n",
      "1000            638.5        627        1.81      \n",
      "2000            878.9        885        0.69      \n",
      "5000            1016.3       1020       0.37      \n",
      "10000           1023.9       1024       0.01      \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Non-Zero Registers vs Cardinality in HLLSet\n",
    "============================================\n",
    "\n",
    "The relationship follows the \"Coupon Collector\" problem from probability theory.\n",
    "\n",
    "Given:\n",
    "- m = 2^p registers (e.g., 2^10 = 1024 for p_bits=10)\n",
    "- n = number of distinct elements inserted\n",
    "\n",
    "Expected number of non-zero (filled) registers:\n",
    "\n",
    "    E[filled] = m * (1 - (1 - 1/m)^n)\n",
    "    \n",
    "For large m, using (1 - 1/m)^n ≈ e^(-n/m):\n",
    "\n",
    "    E[filled] ≈ m * (1 - e^(-n/m))\n",
    "\n",
    "Inverse (estimate n from filled registers):\n",
    "\n",
    "    n ≈ -m * ln(1 - filled/m)\n",
    "\n",
    "This is related to the \"Linear Counting\" cardinality estimator!\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Setup path\n",
    "sys.path.insert(0, str(Path('.').absolute()))\n",
    "from core.hllset import HLLSet, DEFAULT_HASH_CONFIG\n",
    "\n",
    "def expected_filled_registers(n: int, m: int) -> float:\n",
    "    \"\"\"\n",
    "    Expected number of non-zero registers after inserting n elements.\n",
    "    \n",
    "    Uses the coupon collector formula:\n",
    "        E[filled] = m * (1 - (1 - 1/m)^n)\n",
    "    \"\"\"\n",
    "    if n == 0:\n",
    "        return 0.0\n",
    "    # Use log to avoid numerical issues for large n\n",
    "    # (1 - 1/m)^n = exp(n * log(1 - 1/m))\n",
    "    log_term = n * np.log1p(-1/m)  # log1p(x) = log(1+x), more accurate for small x\n",
    "    return m * (1 - np.exp(log_term))\n",
    "\n",
    "\n",
    "def estimate_cardinality_from_filled(filled: int, m: int) -> float:\n",
    "    \"\"\"\n",
    "    Estimate cardinality from number of filled registers.\n",
    "    \n",
    "    This is the \"Linear Counting\" formula:\n",
    "        n ≈ -m * ln(1 - filled/m)\n",
    "    \"\"\"\n",
    "    if filled >= m:\n",
    "        return float('inf')  # All registers filled\n",
    "    if filled == 0:\n",
    "        return 0.0\n",
    "    return -m * np.log(1 - filled/m)\n",
    "\n",
    "\n",
    "def count_nonzero_registers(hll: HLLSet) -> int:\n",
    "    \"\"\"Count non-zero registers in an HLLSet.\"\"\"\n",
    "    registers = hll.dump_numpy()\n",
    "    return np.count_nonzero(registers)\n",
    "\n",
    "\n",
    "# Test the theory\n",
    "print(\"=\"*60)\n",
    "print(\"Non-Zero Registers vs Cardinality Analysis\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "m = 1 << DEFAULT_HASH_CONFIG.p_bits  # 2^p_bits registers\n",
    "print(f\"\\nHLLSet configuration:\")\n",
    "print(f\"  p_bits = {DEFAULT_HASH_CONFIG.p_bits}\")\n",
    "print(f\"  m = 2^{DEFAULT_HASH_CONFIG.p_bits} = {m} registers\")\n",
    "\n",
    "print(f\"\\n{'n (elements)':<15} {'E[filled]':<12} {'Actual':<10} {'Error %':<10}\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "test_sizes = [10, 50, 100, 500, 1000, 2000, 5000, 10000]\n",
    "\n",
    "for n in test_sizes:\n",
    "    # Create HLLSet from batch of n tokens\n",
    "    tokens = [f\"token_{i}\" for i in range(n)]\n",
    "    hll = HLLSet.from_batch(tokens)\n",
    "    \n",
    "    expected = expected_filled_registers(n, m)\n",
    "    actual = count_nonzero_registers(hll)\n",
    "    error = 100 * abs(expected - actual) / max(expected, 1)\n",
    "    \n",
    "    print(f\"{n:<15} {expected:<12.1f} {actual:<10} {error:<10.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "edeea05c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Inverse: Estimating Cardinality from Filled Registers\n",
      "============================================================\n",
      "\n",
      "Using Linear Counting formula: n ≈ -m * ln(1 - filled/m)\n",
      "\n",
      "Actual n     Filled     Est. n       HLL Est.     LC Error% \n",
      "------------------------------------------------------------\n",
      "10           10         10.0         12.0         0.49      \n",
      "50           49         50.2         55.0         0.42      \n",
      "100          94         98.6         106.0        1.40      \n",
      "500          400        507.2        514.0        1.44      \n",
      "1000         627        970.3        995.0        2.97      \n",
      "2000         885        2044.9       2126.0       2.25      \n",
      "5000         1020       5678.3       5442.0       13.57     \n",
      "10000        1024       inf          10211.0      inf       \n",
      "\n",
      "============================================================\n",
      "KEY FORMULAS\n",
      "============================================================\n",
      "\n",
      "Given m = 2^p registers:\n",
      "\n",
      "1. FILLED FROM CARDINALITY (Coupon Collector):\n",
      "\n",
      "   filled(n) = m × (1 - e^(-n/m))\n",
      "\n",
      "2. CARDINALITY FROM FILLED (Linear Counting):\n",
      "\n",
      "   n(filled) = -m × ln(1 - filled/m)\n",
      "\n",
      "3. SATURATION POINT:\n",
      "   - At n = m: ~63.2% of registers filled\n",
      "   - At n = 3m: ~95% of registers filled\n",
      "   - At n = 5m: ~99.3% of registers filled\n",
      "\n",
      "4. PRACTICAL LIMITS:\n",
      "   - For accurate Linear Counting: filled < 0.7m\n",
      "   - When filled ≈ m: switch to HLL estimator\n",
      "\n",
      "\n",
      "============================================================\n",
      "Saturation Analysis\n",
      "============================================================\n",
      "\n",
      "m = 1024 registers\n",
      "\n",
      "n/m ratio    n          E[filled]    % filled  \n",
      "---------------------------------------------\n",
      "0.1          102        97.1         9.5       %\n",
      "0.5          512        403.1        39.4      %\n",
      "1.0          1024       647.5        63.2      %\n",
      "2.0          2048       885.6        86.5      %\n",
      "3.0          3072       973.1        95.0      %\n",
      "5.0          5120       1017.1       99.3      %\n",
      "10.0         10240      1024.0       100.0     %\n"
     ]
    }
   ],
   "source": [
    "# Inverse: Estimate cardinality from filled registers\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Inverse: Estimating Cardinality from Filled Registers\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nUsing Linear Counting formula: n ≈ -m * ln(1 - filled/m)\")\n",
    "\n",
    "print(f\"\\n{'Actual n':<12} {'Filled':<10} {'Est. n':<12} {'HLL Est.':<12} {'LC Error%':<10}\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "for n in test_sizes:\n",
    "    tokens = [f\"token_{i}\" for i in range(n)]\n",
    "    hll = HLLSet.from_batch(tokens)\n",
    "    \n",
    "    filled = count_nonzero_registers(hll)\n",
    "    est_from_filled = estimate_cardinality_from_filled(filled, m)\n",
    "    hll_estimate = hll.cardinality()  # HLL's own estimate\n",
    "    \n",
    "    lc_error = 100 * abs(est_from_filled - n) / n\n",
    "    \n",
    "    print(f\"{n:<12} {filled:<10} {est_from_filled:<12.1f} {hll_estimate:<12.1f} {lc_error:<10.2f}\")\n",
    "\n",
    "# Key insight\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"KEY FORMULAS\")\n",
    "print(\"=\"*60)\n",
    "print(\"\"\"\n",
    "Given m = 2^p registers:\n",
    "\n",
    "1. FILLED FROM CARDINALITY (Coupon Collector):\n",
    "   \n",
    "   filled(n) = m × (1 - e^(-n/m))\n",
    "   \n",
    "2. CARDINALITY FROM FILLED (Linear Counting):\n",
    "   \n",
    "   n(filled) = -m × ln(1 - filled/m)\n",
    "\n",
    "3. SATURATION POINT:\n",
    "   - At n = m: ~63.2% of registers filled\n",
    "   - At n = 3m: ~95% of registers filled\n",
    "   - At n = 5m: ~99.3% of registers filled\n",
    "\n",
    "4. PRACTICAL LIMITS:\n",
    "   - For accurate Linear Counting: filled < 0.7m\n",
    "   - When filled ≈ m: switch to HLL estimator\n",
    "\"\"\")\n",
    "\n",
    "# Demonstrate saturation\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Saturation Analysis\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nm = {m} registers\")\n",
    "print(f\"\\n{'n/m ratio':<12} {'n':<10} {'E[filled]':<12} {'% filled':<10}\")\n",
    "print(\"-\"*45)\n",
    "\n",
    "for ratio in [0.1, 0.5, 1.0, 2.0, 3.0, 5.0, 10.0]:\n",
    "    n = int(m * ratio)\n",
    "    expected = expected_filled_registers(n, m)\n",
    "    pct = 100 * expected / m\n",
    "    print(f\"{ratio:<12} {n:<10} {expected:<12.1f} {pct:<10.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fa61c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Non-Zero BITS in HLLSet Registers\n",
      "======================================================================\n",
      "\n",
      "m = 1024 registers, max register value ≈ 31 (5 bits each)\n",
      "Theoretical max total bits = 1024 × 5 = 5120\n",
      "\n",
      "n          Filled   Σvalues    Σ1-bits    Σbitwidth  avg_val  max_val \n",
      "----------------------------------------------------------------------\n",
      "10         10       119        10         30         11.90    64      \n",
      "50         49       435        50         124        8.88     128     \n",
      "100        94       557        99         215        5.93     128     \n",
      "500        400      2500       467        878        6.25     516     \n",
      "1000       627      5280       862        1479       8.42     1024    \n",
      "2000       885      12149      1519       2446       13.73    2051    \n",
      "5000       1020     35761      2730       3788       35.06    4119    \n",
      "10000      1024     72351      3723       4738       70.66    16399   \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Non-Zero BITS in HLLSet Registers\n",
    "=================================\n",
    "\n",
    "Each register stores max(ρ) where ρ = trailing_zeros + 1.\n",
    "Register values range from 0 to ~31 (for 64-bit hash with p_bits=10).\n",
    "\n",
    "Two metrics:\n",
    "1. Total 1-bits (popcount): sum of popcount(register_i) for all i\n",
    "2. Total bit-width: sum of bit_length(register_i) for all i\n",
    "\n",
    "Theory:\n",
    "- Expected max ρ for a register with k elements: E[max] ≈ log₂(k) + γ/ln(2)\n",
    "  where γ ≈ 0.5772 (Euler's constant)\n",
    "- For n total elements, k ≈ n/m elements per register (on average)\n",
    "\"\"\"\n",
    "\n",
    "def count_total_bits(hll: HLLSet) -> dict:\n",
    "    \"\"\"Count various bit metrics in HLLSet registers.\"\"\"\n",
    "    registers = hll.dump_numpy()\n",
    "    \n",
    "    # Total 1-bits (popcount across all registers)\n",
    "    total_ones = sum(bin(int(r)).count('1') for r in registers)\n",
    "    \n",
    "    # Total bit-width (bits needed to represent each value)\n",
    "    total_bitwidth = sum(int(r).bit_length() for r in registers)\n",
    "    \n",
    "    # Sum of register values\n",
    "    total_value = int(registers.sum())\n",
    "    \n",
    "    # Max register value\n",
    "    max_value = int(registers.max())\n",
    "    \n",
    "    # Non-zero registers\n",
    "    nonzero_regs = np.count_nonzero(registers)\n",
    "    \n",
    "    return {\n",
    "        'total_ones': total_ones,        # Sum of popcount\n",
    "        'total_bitwidth': total_bitwidth, # Sum of bit_length\n",
    "        'total_value': total_value,       # Sum of values\n",
    "        'max_value': max_value,           # Max single value\n",
    "        'nonzero_regs': nonzero_regs,\n",
    "        'avg_value': total_value / max(nonzero_regs, 1),\n",
    "    }\n",
    "\n",
    "\n",
    "def expected_register_value(k: float) -> float:\n",
    "    \"\"\"\n",
    "    Expected max trailing zeros for a register with k elements.\n",
    "    \n",
    "    For k iid draws from geometric(1/2), the expected max is:\n",
    "        E[max] ≈ log₂(k) + γ/ln(2) ≈ log₂(k) + 0.8327\n",
    "    \"\"\"\n",
    "    if k <= 0:\n",
    "        return 0.0\n",
    "    gamma = 0.5772156649  # Euler-Mascheroni constant\n",
    "    return np.log2(k) + gamma / np.log(2)\n",
    "\n",
    "\n",
    "def expected_total_bits(n: int, m: int) -> dict:\n",
    "    \"\"\"\n",
    "    Estimate total bits given n elements and m registers.\n",
    "    \"\"\"\n",
    "    if n == 0:\n",
    "        return {'total_ones': 0, 'total_bitwidth': 0, 'total_value': 0}\n",
    "    \n",
    "    # Expected elements per register\n",
    "    k_avg = n / m\n",
    "    \n",
    "    # Expected filled registers\n",
    "    filled = m * (1 - np.exp(-n/m))\n",
    "    \n",
    "    # Expected value per filled register\n",
    "    avg_value = expected_register_value(k_avg)\n",
    "    \n",
    "    # Total value across all registers\n",
    "    total_value = filled * avg_value\n",
    "    \n",
    "    # Approximate bit-width: for value v, bit_length = floor(log2(v)) + 1\n",
    "    avg_bitwidth = max(1, int(np.log2(max(avg_value, 1)))) + 1\n",
    "    total_bitwidth = filled * avg_bitwidth\n",
    "    \n",
    "    # 1-bits: approximately half of the bit positions are 1\n",
    "    total_ones = total_bitwidth * 0.5\n",
    "    \n",
    "    return {\n",
    "        'total_ones': total_ones,\n",
    "        'total_bitwidth': total_bitwidth,\n",
    "        'total_value': total_value,\n",
    "        'avg_value': avg_value,\n",
    "        'filled': filled,\n",
    "    }\n",
    "\n",
    "\n",
    "# Test bit analysis\n",
    "print(\"=\"*70)\n",
    "print(\"Non-Zero BITS in HLLSet Registers\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nm = {m} registers, max register value ≈ 31 (5 bits each)\")\n",
    "print(f\"Theoretical max total bits = {m} × 5 = {m * 5}\")\n",
    "\n",
    "print(f\"\\n{'n':<10} {'Filled':<8} {'Σvalues':<10} {'Σ1-bits':<10} {'Σbitwidth':<10} {'avg_val':<8} {'max_val':<8}\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "for n in test_sizes:\n",
    "    tokens = [f\"token_{i}\" for i in range(n)]\n",
    "    hll = HLLSet.from_batch(tokens)\n",
    "    \n",
    "    bits = count_total_bits(hll)\n",
    "    \n",
    "    print(f\"{n:<10} {bits['nonzero_regs']:<8} {bits['total_value']:<10} \"\n",
    "          f\"{bits['total_ones']:<10} {bits['total_bitwidth']:<10} \"\n",
    "          f\"{bits['avg_value']:<8.2f} {bits['max_value']:<8}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7bc0d82e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "Comparison: Actual vs Expected (Theory)\n",
      "======================================================================\n",
      "\n",
      "n          Act.Σval     Exp.Σval     Act.bits   Exp.bits   Err%    \n",
      "-----------------------------------------------------------------\n",
      "10         119          -58          10         10         17716.9 \n",
      "50         435          -172         50         49         60693.8 \n",
      "100        557          -240         99         95         79741.0 \n",
      "500        2500         -80          467        396        257970.0\n",
      "1000       5280         510          862        638        935.8   \n",
      "2000       12149        1580         1519       879        668.7   \n",
      "5000       35761        3171         2730       1016       1027.7  \n",
      "10000      72351        4219         3723       1536       1614.8  \n",
      "\n",
      "======================================================================\n",
      "KEY FORMULAS FOR NON-ZERO BITS\n",
      "======================================================================\n",
      "\n",
      "Given m = 2^p registers, n elements:\n",
      "\n",
      "1. EXPECTED REGISTER VALUE (Extreme Value Theory):\n",
      "\n",
      "   For k elements in a register:\n",
      "   E[max(ρ₁, ρ₂, ..., ρₖ)] ≈ log₂(k) + γ/ln(2) ≈ log₂(k) + 0.833\n",
      "\n",
      "   where γ = 0.5772 (Euler's constant)\n",
      "\n",
      "2. TOTAL REGISTER VALUES:\n",
      "\n",
      "   Σvalues ≈ filled × E[max(ρ)] \n",
      "          ≈ m(1 - e^(-n/m)) × (log₂(n/m) + 0.833)\n",
      "\n",
      "3. TOTAL 1-BITS (popcount):\n",
      "\n",
      "   Σ1-bits ≈ Σbitwidth × 0.5\n",
      "           ≈ filled × (log₂(avg_value) + 1) × 0.5\n",
      "\n",
      "4. SCALING BEHAVIOR:\n",
      "   - Small n (n << m): Linear with n\n",
      "   - Large n (n >> m): Logarithmic with n (registers saturate)\n",
      "\n",
      "5. MAXIMUM POSSIBLE:\n",
      "   - Max register value: ~31 (5 bits for 64-bit hash)\n",
      "   - Max total bits: m × 5 = 5120\n",
      "   - Max 1-bits: m × 5 × 0.5 ≈ 2560\n",
      "\n",
      "======================================================================\n",
      "Bit Saturation Analysis\n",
      "======================================================================\n",
      "\n",
      "n/m        n          Σvalues      Σ1-bits    bits/reg  \n",
      "-------------------------------------------------------\n",
      "0.1        102        560          101        0.10      \n",
      "0.5        512        2523         479        0.47      \n",
      "1          1024       5414         877        0.86      \n",
      "2          2048       12397        1546       1.51      \n",
      "5          5120       35990        2761       2.70      \n",
      "10         10240      72743        3756       3.67      \n",
      "50         51200      361944       6186       6.04      \n",
      "100        102400     925728       7157       6.99      \n"
     ]
    }
   ],
   "source": [
    "# Compare actual vs expected\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Comparison: Actual vs Expected (Theory)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\n{'n':<10} {'Act.Σval':<12} {'Exp.Σval':<12} {'Act.bits':<10} {'Exp.bits':<10} {'Err%':<8}\")\n",
    "print(\"-\"*65)\n",
    "\n",
    "for n in test_sizes:\n",
    "    tokens = [f\"token_{i}\" for i in range(n)]\n",
    "    hll = HLLSet.from_batch(tokens)\n",
    "    \n",
    "    actual = count_total_bits(hll)\n",
    "    expected = expected_total_bits(n, m)\n",
    "    \n",
    "    val_err = 100 * abs(actual['total_value'] - expected['total_value']) / max(expected['total_value'], 1)\n",
    "    \n",
    "    print(f\"{n:<10} {actual['total_value']:<12} {expected['total_value']:<12.0f} \"\n",
    "          f\"{actual['total_ones']:<10} {expected['total_ones']:<10.0f} {val_err:<8.1f}\")\n",
    "\n",
    "# Key formulas\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"KEY FORMULAS FOR NON-ZERO BITS\")\n",
    "print(\"=\"*70)\n",
    "print(\"\"\"\n",
    "Given m = 2^p registers, n elements:\n",
    "\n",
    "1. EXPECTED REGISTER VALUE (Extreme Value Theory):\n",
    "   \n",
    "   For k elements in a register:\n",
    "   E[max(ρ₁, ρ₂, ..., ρₖ)] ≈ log₂(k) + γ/ln(2) ≈ log₂(k) + 0.833\n",
    "   \n",
    "   where γ = 0.5772 (Euler's constant)\n",
    "\n",
    "2. TOTAL REGISTER VALUES:\n",
    "   \n",
    "   Σvalues ≈ filled × E[max(ρ)] \n",
    "          ≈ m(1 - e^(-n/m)) × (log₂(n/m) + 0.833)\n",
    "\n",
    "3. TOTAL 1-BITS (popcount):\n",
    "   \n",
    "   Σ1-bits ≈ Σbitwidth × 0.5\n",
    "           ≈ filled × (log₂(avg_value) + 1) × 0.5\n",
    "\n",
    "4. SCALING BEHAVIOR:\n",
    "   - Small n (n << m): Linear with n\n",
    "   - Large n (n >> m): Logarithmic with n (registers saturate)\n",
    "   \n",
    "5. MAXIMUM POSSIBLE:\n",
    "   - Max register value: ~31 (5 bits for 64-bit hash)\n",
    "   - Max total bits: m × 5 = {0}\n",
    "   - Max 1-bits: m × 5 × 0.5 ≈ {1}\n",
    "\"\"\".format(m * 5, m * 5 // 2))\n",
    "\n",
    "# Show saturation behavior\n",
    "print(\"=\"*70)\n",
    "print(\"Bit Saturation Analysis\")  \n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\n{'n/m':<10} {'n':<10} {'Σvalues':<12} {'Σ1-bits':<10} {'bits/reg':<10}\")\n",
    "print(\"-\"*55)\n",
    "\n",
    "for ratio in [0.1, 0.5, 1, 2, 5, 10, 50, 100]:\n",
    "    n = int(m * ratio)\n",
    "    tokens = [f\"token_{i}\" for i in range(n)]\n",
    "    hll = HLLSet.from_batch(tokens)\n",
    "    bits = count_total_bits(hll)\n",
    "    \n",
    "    bits_per_reg = bits['total_ones'] / m\n",
    "    print(f\"{ratio:<10} {n:<10} {bits['total_value']:<12} {bits['total_ones']:<10} {bits_per_reg:<10.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da26889d",
   "metadata": {},
   "source": [
    "# Entanglement as Graph Isomorphism\n",
    "\n",
    "## The Discovery\n",
    "\n",
    "Given the **same dataset** processed through HLLSets with **different seeds**:\n",
    "- Group 1: `HLLSet(data, seed=42)` → Graph G₁\n",
    "- Group 2: `HLLSet(data, seed=137)` → Graph G₂\n",
    "\n",
    "**Key observation**: G₁ and G₂ are **isomorphic** despite having completely different bit representations!\n",
    "\n",
    "## Node Tuple Fingerprint\n",
    "\n",
    "Each node is uniquely characterized by:\n",
    "```\n",
    "node = (cardinality, in_edges[(τ₁,ρ₁), (τ₂,ρ₂), ...], out_edges[(τ₁,ρ₁), (τ₂,ρ₂), ...])\n",
    "```\n",
    "\n",
    "Where:\n",
    "- `cardinality` = |HLLSet|\n",
    "- `τ` (tau) = **BSS similarity** = intersection(A,B) / cardinality(A)\n",
    "- `ρ` (rho) = **BSS dissimilarity** = cardinality({aᵢ ≠ bᵢ}) / cardinality(A)\n",
    "\n",
    "**Note**: τ and ρ together provide **two-sided bounds** on similarity between HLLSets A and B (Bell State Similarity).\n",
    "\n",
    "**Perfect entanglement**: Matching nodes have identical tuples.\n",
    "**Approximate entanglement**: Matching nodes have \"close enough\" tuples.\n",
    "\n",
    "## Combinatorial Bound\n",
    "\n",
    "Total information capacity: **2^p × 32 bits** (e.g., 1024 × 32 = 32,768 bits)\n",
    "\n",
    "This bounds the number of distinguishable states, making the graph matching tractable!\n",
    "\n",
    "## NitroSAT for Graph Isomorphism\n",
    "\n",
    "The node mapping problem is naturally a SAT problem:\n",
    "- Variable `x_{i,j} = 1` means node i in G₁ maps to node j in G₂\n",
    "- Constraints ensure valid bijection\n",
    "- Soft constraints for tuple similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f65b74b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Entanglement Graph Isomorphism Demo\n",
      "======================================================================\n",
      "\n",
      "G1_seed42:\n",
      "  Node 0: card=1000, in=0, out=1\n",
      "  Node 1: card=500, in=1, out=1\n",
      "  Node 2: card=750, in=1, out=0\n",
      "\n",
      "G2_seed137:\n",
      "  Node 10: card=1005, in=0, out=1\n",
      "  Node 11: card=498, in=1, out=1\n",
      "  Node 12: card=752, in=1, out=0\n",
      "\n",
      "Compatible pairs (threshold=0.1):\n",
      "  G1[0] -> G2[10]\n",
      "  G1[1] -> G2[11]\n",
      "  G1[2] -> G2[12]\n",
      "\n",
      "SAT formulation:\n",
      "  Variables: 3\n",
      "  Clauses: 3\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Entanglement Graph Matching via NitroSAT\n",
    "=========================================\n",
    "\n",
    "Given two graphs G₁, G₂ derived from entangled HLLSets,\n",
    "find the node mapping that demonstrates isomorphism.\n",
    "\"\"\"\n",
    "\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List, Tuple, Dict, Set, Optional\n",
    "from collections import defaultdict\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class NodeTuple:\n",
    "    \"\"\"\n",
    "    Node fingerprint for entanglement detection.\n",
    "    \n",
    "    A node is characterized by:\n",
    "    - cardinality: |HLLSet| of this node\n",
    "    - in_edges: list of (edge_type, weight) for incoming edges\n",
    "    - out_edges: list of (edge_type, weight) for outgoing edges\n",
    "    \"\"\"\n",
    "    cardinality: int\n",
    "    in_degree: int\n",
    "    out_degree: int\n",
    "    # Sorted edge signatures for comparison\n",
    "    in_signature: Tuple[Tuple[str, int], ...] = ()\n",
    "    out_signature: Tuple[Tuple[str, int], ...] = ()\n",
    "    \n",
    "    def distance(self, other: 'NodeTuple') -> float:\n",
    "        \"\"\"Compute distance between node tuples.\"\"\"\n",
    "        if self.in_degree != other.in_degree or self.out_degree != other.out_degree:\n",
    "            return float('inf')  # Degree mismatch = not compatible\n",
    "        \n",
    "        # Cardinality difference (normalized)\n",
    "        card_diff = abs(self.cardinality - other.cardinality) / max(self.cardinality, other.cardinality, 1)\n",
    "        \n",
    "        # Edge signature similarity (Jaccard-like)\n",
    "        # For now, simple comparison\n",
    "        return card_diff\n",
    "    \n",
    "    def is_compatible(self, other: 'NodeTuple', threshold: float = 0.1) -> bool:\n",
    "        \"\"\"Check if two nodes could be entangled partners.\"\"\"\n",
    "        return self.distance(other) < threshold\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class EntanglementGraph:\n",
    "    \"\"\"\n",
    "    Graph representation for entanglement analysis.\n",
    "    \n",
    "    Nodes are identified by ID, with associated NodeTuple fingerprints.\n",
    "    \"\"\"\n",
    "    name: str\n",
    "    nodes: Dict[int, NodeTuple] = field(default_factory=dict)\n",
    "    edges: List[Tuple[int, int, str, int]] = field(default_factory=list)  # (src, dst, type, weight)\n",
    "    \n",
    "    def add_node(self, node_id: int, cardinality: int, \n",
    "                 in_edges: List[Tuple[str, int]] = None,\n",
    "                 out_edges: List[Tuple[str, int]] = None):\n",
    "        \"\"\"Add a node with its fingerprint.\"\"\"\n",
    "        in_edges = in_edges or []\n",
    "        out_edges = out_edges or []\n",
    "        \n",
    "        self.nodes[node_id] = NodeTuple(\n",
    "            cardinality=cardinality,\n",
    "            in_degree=len(in_edges),\n",
    "            out_degree=len(out_edges),\n",
    "            in_signature=tuple(sorted(in_edges)),\n",
    "            out_signature=tuple(sorted(out_edges)),\n",
    "        )\n",
    "    \n",
    "    def add_edge(self, src: int, dst: int, edge_type: str = \"default\", weight: int = 1):\n",
    "        \"\"\"Add an edge.\"\"\"\n",
    "        self.edges.append((src, dst, edge_type, weight))\n",
    "    \n",
    "    def degree_sequence(self) -> List[Tuple[int, int]]:\n",
    "        \"\"\"Get sorted degree sequence (in, out) for graph fingerprint.\"\"\"\n",
    "        return sorted((n.in_degree, n.out_degree) for n in self.nodes.values())\n",
    "    \n",
    "    def cardinality_sequence(self) -> List[int]:\n",
    "        \"\"\"Get sorted cardinality sequence.\"\"\"\n",
    "        return sorted(n.cardinality for n in self.nodes.values())\n",
    "\n",
    "\n",
    "def find_compatible_pairs(g1: EntanglementGraph, g2: EntanglementGraph, \n",
    "                          threshold: float = 0.1) -> Dict[int, List[int]]:\n",
    "    \"\"\"\n",
    "    Find potentially compatible node pairs between two graphs.\n",
    "    \n",
    "    Returns dict mapping g1_node_id -> list of compatible g2_node_ids.\n",
    "    \"\"\"\n",
    "    compatible = defaultdict(list)\n",
    "    \n",
    "    for id1, node1 in g1.nodes.items():\n",
    "        for id2, node2 in g2.nodes.items():\n",
    "            if node1.is_compatible(node2, threshold):\n",
    "                compatible[id1].append(id2)\n",
    "    \n",
    "    return dict(compatible)\n",
    "\n",
    "\n",
    "def entanglement_to_sat(g1: EntanglementGraph, g2: EntanglementGraph,\n",
    "                        compatible_pairs: Dict[int, List[int]]) -> Tuple[int, List[List[int]], Dict]:\n",
    "    \"\"\"\n",
    "    Convert entanglement mapping problem to SAT.\n",
    "    \n",
    "    Variables: x_{i,j} = 1 means node i in G₁ maps to node j in G₂\n",
    "    \n",
    "    Constraints:\n",
    "    1. Each node in G₁ maps to exactly one node in G₂\n",
    "    2. Each node in G₂ is mapped from at most one node in G₁\n",
    "    3. Only compatible pairs can be mapped\n",
    "    \n",
    "    Returns: (num_vars, clauses, var_mapping)\n",
    "    \"\"\"\n",
    "    # Create variable mapping\n",
    "    var_map = {}  # (id1, id2) -> var_num\n",
    "    reverse_map = {}  # var_num -> (id1, id2)\n",
    "    var_counter = 1\n",
    "    \n",
    "    for id1, compatible_ids in compatible_pairs.items():\n",
    "        for id2 in compatible_ids:\n",
    "            var_map[(id1, id2)] = var_counter\n",
    "            reverse_map[var_counter] = (id1, id2)\n",
    "            var_counter += 1\n",
    "    \n",
    "    num_vars = var_counter - 1\n",
    "    clauses = []\n",
    "    \n",
    "    # Constraint 1: Each node in G₁ maps to exactly one node in G₂\n",
    "    for id1 in g1.nodes:\n",
    "        if id1 not in compatible_pairs:\n",
    "            continue  # No compatible mapping - problem may be UNSAT\n",
    "        \n",
    "        # At-least-one: (x_{i,j1} OR x_{i,j2} OR ...)\n",
    "        vars_for_node = [var_map[(id1, id2)] for id2 in compatible_pairs[id1]]\n",
    "        if vars_for_node:\n",
    "            clauses.append(vars_for_node)\n",
    "        \n",
    "        # At-most-one: for each pair, NOT both\n",
    "        for k1 in range(len(vars_for_node)):\n",
    "            for k2 in range(k1 + 1, len(vars_for_node)):\n",
    "                clauses.append([-vars_for_node[k1], -vars_for_node[k2]])\n",
    "    \n",
    "    # Constraint 2: Each node in G₂ is mapped from at most one node in G₁\n",
    "    g2_to_vars = defaultdict(list)\n",
    "    for (id1, id2), var in var_map.items():\n",
    "        g2_to_vars[id2].append(var)\n",
    "    \n",
    "    for id2, vars_for_node in g2_to_vars.items():\n",
    "        # At-most-one\n",
    "        for k1 in range(len(vars_for_node)):\n",
    "            for k2 in range(k1 + 1, len(vars_for_node)):\n",
    "                clauses.append([-vars_for_node[k1], -vars_for_node[k2]])\n",
    "    \n",
    "    return num_vars, clauses, reverse_map\n",
    "\n",
    "\n",
    "# Demo: Create two entangled graphs\n",
    "print(\"=\"*70)\n",
    "print(\"Entanglement Graph Isomorphism Demo\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Graph 1: Original representation (seed=42)\n",
    "g1 = EntanglementGraph(name=\"G1_seed42\")\n",
    "g1.add_node(0, cardinality=1000, in_edges=[], out_edges=[(\"link\", 2)])\n",
    "g1.add_node(1, cardinality=500, in_edges=[(\"link\", 1)], out_edges=[(\"link\", 1)])\n",
    "g1.add_node(2, cardinality=750, in_edges=[(\"link\", 1)], out_edges=[])\n",
    "\n",
    "# Graph 2: Entangled representation (seed=137) - same structure, different node IDs\n",
    "g2 = EntanglementGraph(name=\"G2_seed137\")\n",
    "g2.add_node(10, cardinality=1005, in_edges=[], out_edges=[(\"link\", 2)])  # Maps to 0\n",
    "g2.add_node(11, cardinality=498, in_edges=[(\"link\", 1)], out_edges=[(\"link\", 1)])  # Maps to 1\n",
    "g2.add_node(12, cardinality=752, in_edges=[(\"link\", 1)], out_edges=[])  # Maps to 2\n",
    "\n",
    "print(f\"\\n{g1.name}:\")\n",
    "for nid, node in g1.nodes.items():\n",
    "    print(f\"  Node {nid}: card={node.cardinality}, in={node.in_degree}, out={node.out_degree}\")\n",
    "\n",
    "print(f\"\\n{g2.name}:\")\n",
    "for nid, node in g2.nodes.items():\n",
    "    print(f\"  Node {nid}: card={node.cardinality}, in={node.in_degree}, out={node.out_degree}\")\n",
    "\n",
    "# Find compatible pairs\n",
    "compatible = find_compatible_pairs(g1, g2, threshold=0.1)\n",
    "print(f\"\\nCompatible pairs (threshold=0.1):\")\n",
    "for id1, id2_list in compatible.items():\n",
    "    print(f\"  G1[{id1}] -> G2{id2_list}\")\n",
    "\n",
    "# Convert to SAT\n",
    "num_vars, clauses, var_mapping = entanglement_to_sat(g1, g2, compatible)\n",
    "print(f\"\\nSAT formulation:\")\n",
    "print(f\"  Variables: {num_vars}\")\n",
    "print(f\"  Clauses: {len(clauses)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90e28207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Solving Entanglement Mapping with NitroSAT\n",
      "======================================================================\n",
      "\n",
      "✓ Entanglement mapping found!\n",
      "\n",
      "  G1 Node  →  G2 Node\n",
      "  --------------------\n",
      "       0  →      10  (card: 1000 ↔ 1005)\n",
      "       1  →      11  (card: 500 ↔ 498)\n",
      "       2  →      12  (card: 750 ↔ 752)\n",
      "\n",
      "======================================================================\n",
      "Harder Case: Multiple Compatible Candidates\n",
      "======================================================================\n",
      "\n",
      "Compatible pairs:\n",
      "  G3[0] -> G4[20]\n",
      "  G3[1] -> G4[21, 22]\n",
      "  G3[2] -> G4[21, 22]\n",
      "  G3[3] -> G4[23, 24]\n",
      "  G3[4] -> G4[23, 24]\n",
      "\n",
      "✓ Mapping found with 5 node pairs\n",
      "  0 → 20\n",
      "  1 → 21\n",
      "  2 → 22\n",
      "  3 → 23\n",
      "  4 → 24\n"
     ]
    }
   ],
   "source": [
    "# Solve with NitroSAT\n",
    "from nitrosat import CNFFormula, NitroSatSolver\n",
    "\n",
    "def solve_entanglement_mapping(g1: EntanglementGraph, g2: EntanglementGraph,\n",
    "                                threshold: float = 0.1) -> Optional[Dict[int, int]]:\n",
    "    \"\"\"\n",
    "    Find the entanglement mapping between two graphs using NitroSAT.\n",
    "    \n",
    "    Returns: Dict mapping g1_node_id -> g2_node_id, or None if no mapping exists.\n",
    "    \"\"\"\n",
    "    # Find compatible pairs\n",
    "    compatible = find_compatible_pairs(g1, g2, threshold)\n",
    "    \n",
    "    if not compatible:\n",
    "        return None\n",
    "    \n",
    "    # Convert to SAT\n",
    "    num_vars, clauses, var_mapping = entanglement_to_sat(g1, g2, compatible)\n",
    "    \n",
    "    if num_vars == 0:\n",
    "        return None\n",
    "    \n",
    "    # Build CNF formula\n",
    "    formula = CNFFormula(num_vars=num_vars)\n",
    "    for clause in clauses:\n",
    "        formula.add_clause(*clause)\n",
    "    \n",
    "    # Solve\n",
    "    solver = NitroSatSolver(verbose=False)\n",
    "    result = solver.solve(formula)\n",
    "    \n",
    "    if not result.solved:\n",
    "        return None\n",
    "    \n",
    "    # Extract mapping\n",
    "    mapping = {}\n",
    "    for var, (id1, id2) in var_mapping.items():\n",
    "        if result.get_assignment(var) == 1:\n",
    "            mapping[id1] = id2\n",
    "    \n",
    "    return mapping\n",
    "\n",
    "\n",
    "# Solve the demo\n",
    "print(\"=\"*70)\n",
    "print(\"Solving Entanglement Mapping with NitroSAT\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "mapping = solve_entanglement_mapping(g1, g2, threshold=0.1)\n",
    "\n",
    "if mapping:\n",
    "    print(f\"\\n✓ Entanglement mapping found!\")\n",
    "    print(f\"\\n  G1 Node  →  G2 Node\")\n",
    "    print(f\"  \" + \"-\"*20)\n",
    "    for id1, id2 in sorted(mapping.items()):\n",
    "        node1 = g1.nodes[id1]\n",
    "        node2 = g2.nodes[id2]\n",
    "        print(f\"  {id1:>6}  →  {id2:>6}  (card: {node1.cardinality} ↔ {node2.cardinality})\")\n",
    "else:\n",
    "    print(\"\\n✗ No valid entanglement mapping exists\")\n",
    "\n",
    "# Now test with a harder case - more nodes, some ambiguity\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Harder Case: Multiple Compatible Candidates\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Create graphs with some structural ambiguity\n",
    "g3 = EntanglementGraph(name=\"G3\")\n",
    "g4 = EntanglementGraph(name=\"G4\")\n",
    "\n",
    "# G3: 5 nodes with some similar fingerprints\n",
    "g3.add_node(0, cardinality=1000, in_edges=[], out_edges=[(\"link\", 2)])\n",
    "g3.add_node(1, cardinality=500, in_edges=[(\"link\", 1)], out_edges=[(\"link\", 1)])\n",
    "g3.add_node(2, cardinality=502, in_edges=[(\"link\", 1)], out_edges=[(\"link\", 1)])  # Similar to 1!\n",
    "g3.add_node(3, cardinality=750, in_edges=[(\"link\", 1)], out_edges=[])\n",
    "g3.add_node(4, cardinality=748, in_edges=[(\"link\", 1)], out_edges=[])  # Similar to 3!\n",
    "\n",
    "# G4: Same structure, shuffled IDs\n",
    "g4.add_node(20, cardinality=1002, in_edges=[], out_edges=[(\"link\", 2)])\n",
    "g4.add_node(21, cardinality=501, in_edges=[(\"link\", 1)], out_edges=[(\"link\", 1)])\n",
    "g4.add_node(22, cardinality=499, in_edges=[(\"link\", 1)], out_edges=[(\"link\", 1)])\n",
    "g4.add_node(23, cardinality=751, in_edges=[(\"link\", 1)], out_edges=[])\n",
    "g4.add_node(24, cardinality=749, in_edges=[(\"link\", 1)], out_edges=[])\n",
    "\n",
    "compatible34 = find_compatible_pairs(g3, g4, threshold=0.1)\n",
    "print(f\"\\nCompatible pairs:\")\n",
    "for id1, id2_list in sorted(compatible34.items()):\n",
    "    print(f\"  G3[{id1}] -> G4{id2_list}\")\n",
    "\n",
    "mapping34 = solve_entanglement_mapping(g3, g4, threshold=0.1)\n",
    "\n",
    "if mapping34:\n",
    "    print(f\"\\n✓ Mapping found with {len(mapping34)} node pairs\")\n",
    "    for id1, id2 in sorted(mapping34.items()):\n",
    "        print(f\"  {id1} → {id2}\")\n",
    "else:\n",
    "    print(\"\\n✗ No valid mapping\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "366c9513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "Bit Capacity and Combinatorial Bounds\n",
      "======================================================================\n",
      "\n",
      "HLLSet Bit Capacity:\n",
      "  Registers: m = 2^10 = 1024\n",
      "  Bits per register: 32\n",
      "  Total bits: 32,768 (4,096 bytes)\n",
      "\n",
      "Theoretical bounds on distinguishable states:\n",
      "  Maximum HLLSets: 2^32768 (astronomical)\n",
      "\n",
      "  But practical limits are much smaller:\n",
      "  - Register values range [0, ~31] → ~5 bits effective per register\n",
      "  - Effective bits: ~5,120\n",
      "  - Non-zero registers bounded by cardinality (Coupon Collector)\n",
      "\n",
      "======================================================================\n",
      "Graph Matching Complexity with HLLSet Nodes\n",
      "======================================================================\n",
      "\n",
      "Nodes    Brute Force     Filtered        SAT Vars   Reduction   \n",
      "------------------------------------------------------------\n",
      "5        1.20e+02        32              10         3.75e+00\n",
      "10       3.63e+06        1024            20         3.54e+03\n",
      "20       2.43e+18        1048576         40         2.32e+12\n",
      "50       ∞               1125899906842624 100        inf\n",
      "100      ∞               1267650600228229401496703205376 200        inf\n",
      "1000     ∞               10715086071862673209484250490600018105614048117055336074437503883703510511249361224931983788156958581275946729175531468251871452856923140435984577574698574803934567774824230985421074605062371141877954182153046474983581941267398767559165543946077062914571196477686542167660429831652624386837205668069376 2000       inf\n",
      "\n",
      "KEY INSIGHT:\n",
      "===========\n",
      "The NodeTuple fingerprint (cardinality, in_degree, out_degree, edge_signatures)\n",
      "acts as a HASH that partitions the search space.\n",
      "\n",
      "Good fingerprints → few compatible candidates per node → tractable SAT\n",
      "Poor fingerprints → many candidates → harder SAT (but still polynomial!)\n",
      "\n",
      "NitroSAT's physics-inspired approach (spectral geometry, heat kernel, BAHA)\n",
      "exploits the structure of the compatibility graph to find solutions efficiently.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Complexity analysis: How bits bound the graph matching problem\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Bit Capacity and Combinatorial Bounds\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "p_bits = DEFAULT_HASH_CONFIG.p_bits\n",
    "m = 1 << p_bits\n",
    "bits_per_register = 32  # Using uint32\n",
    "\n",
    "total_bits = m * bits_per_register\n",
    "print(f\"\"\"\n",
    "HLLSet Bit Capacity:\n",
    "  Registers: m = 2^{p_bits} = {m}\n",
    "  Bits per register: {bits_per_register}\n",
    "  Total bits: {total_bits:,} ({total_bits // 8:,} bytes)\n",
    "\n",
    "Theoretical bounds on distinguishable states:\n",
    "  Maximum HLLSets: 2^{total_bits} (astronomical)\n",
    "  \n",
    "  But practical limits are much smaller:\n",
    "  - Register values range [0, ~31] → ~5 bits effective per register\n",
    "  - Effective bits: ~{m * 5:,}\n",
    "  - Non-zero registers bounded by cardinality (Coupon Collector)\n",
    "\"\"\")\n",
    "\n",
    "# How does this affect graph matching?\n",
    "print(\"=\"*70)\n",
    "print(\"Graph Matching Complexity with HLLSet Nodes\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "def estimate_matching_complexity(num_nodes: int, avg_compatible: float) -> dict:\n",
    "    \"\"\"\n",
    "    Estimate SAT complexity for graph matching.\n",
    "    \n",
    "    Worst case (no fingerprint filtering): n! permutations\n",
    "    With fingerprints: much smaller search space\n",
    "    \"\"\"\n",
    "    import math\n",
    "    \n",
    "    # Without filtering\n",
    "    brute_force = math.factorial(num_nodes) if num_nodes <= 20 else float('inf')\n",
    "    \n",
    "    # With fingerprint filtering (avg_compatible candidates per node)\n",
    "    filtered = avg_compatible ** num_nodes\n",
    "    \n",
    "    # SAT formulation size\n",
    "    sat_vars = int(num_nodes * avg_compatible)\n",
    "    # At-least-one: n clauses of size avg_compatible\n",
    "    # At-most-one: n * C(avg_compatible, 2) clauses\n",
    "    sat_clauses = int(num_nodes + num_nodes * avg_compatible * (avg_compatible - 1) / 2)\n",
    "    \n",
    "    return {\n",
    "        'brute_force': brute_force,\n",
    "        'filtered_search': filtered,\n",
    "        'sat_variables': sat_vars,\n",
    "        'sat_clauses': sat_clauses,\n",
    "        'complexity_reduction': brute_force / max(filtered, 1) if brute_force < float('inf') else float('inf'),\n",
    "    }\n",
    "\n",
    "print(f\"\\n{'Nodes':<8} {'Brute Force':<15} {'Filtered':<15} {'SAT Vars':<10} {'Reduction':<12}\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "for num_nodes in [5, 10, 20, 50, 100, 1000]:\n",
    "    # Assume fingerprints reduce to ~2 compatible candidates per node on average\n",
    "    stats = estimate_matching_complexity(num_nodes, avg_compatible=2.0)\n",
    "    \n",
    "    bf = stats['brute_force']\n",
    "    bf_str = f\"{bf:.2e}\" if bf < float('inf') else \"∞\"\n",
    "    \n",
    "    print(f\"{num_nodes:<8} {bf_str:<15} {stats['filtered_search']:<15.0f} \"\n",
    "          f\"{stats['sat_variables']:<10} {stats['complexity_reduction']:.2e}\")\n",
    "\n",
    "print(\"\"\"\n",
    "KEY INSIGHT:\n",
    "===========\n",
    "The NodeTuple fingerprint (cardinality, in_degree, out_degree, edge_signatures)\n",
    "acts as a HASH that partitions the search space.\n",
    "\n",
    "Good fingerprints → few compatible candidates per node → tractable SAT\n",
    "Poor fingerprints → many candidates → harder SAT (but still polynomial!)\n",
    "\n",
    "NitroSAT's physics-inspired approach (spectral geometry, heat kernel, BAHA)\n",
    "exploits the structure of the compatibility graph to find solutions efficiently.\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fractal_manifold",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
